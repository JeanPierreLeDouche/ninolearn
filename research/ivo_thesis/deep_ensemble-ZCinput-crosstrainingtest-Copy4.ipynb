{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep ensemble for ENSO-forecasting\n",
    "\n",
    "In this tutorial you learn how to use a neural network model called Deep Ensemble (DE) for the ENSO forecasting. This network architecture was initially developed [Lakshminarayanan et al. (2017)](https://papers.nips.cc/paper/7219-simple-and-scalable-predictive-uncertainty-estimation-using-deep-ensembles.pdf). \n",
    "\n",
    "DEs are feed foreword neural networks that predict the mean and the standard deviation of a Gaussian. Hence, their predicion comes with an uncertainty estimation which is a valuable feature for ENSO-forecasting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a data pipe line\n",
    "\n",
    "At first, we define a data pipeline. This is in general quite useful to keep your code clean and also to reuse the pipeline for later purpose.\n",
    "\n",
    "The data pipeline generates returns:\n",
    "\n",
    "1. The feature array\n",
    "\n",
    "2. The label array\n",
    "\n",
    "3. The time  array corresponding to the time of the label\n",
    "\n",
    "NOTE (again): Lead time is defined as the time that passed between the last observed and the first date of the target season. Hence, negative appear, e.g. if you compare the DJF season with the target season JFM, you have a lead time of -2 month (Last observed date: Feburary 28/29, First date of the target season January 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from ninolearn.IO.read_processed import data_reader\n",
    "from ninolearn.IO.read_raw import ZC_simple_read\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from ninolearn.learn.fit import n_decades, lead_times, decade_color, decade_name\n",
    "from ninolearn.learn.evaluation import evaluation_correlation, evaluation_decadal_correlation, evaluation_seasonal_correlation, evaluation_decadal_correlation_ZC\n",
    "from ninolearn.learn.fit import cross_hindcast_dem\n",
    "from ninolearn.plot.evaluation import plot_seasonal_skill_ZC\n",
    "import matplotlib.pyplot as plt\n",
    "from ninolearn.learn.fit import cross_training\n",
    "from ninolearn.learn.fit import cross_hindcast_dem\n",
    "from ninolearn.learn.models import DEM\n",
    "\n",
    "oneyear= pd.Timedelta(365, 'D')\n",
    "\n",
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tstart = 1952-04-07 14:17:30 and tend = 1994-08-26 03:33:20 (train)\n",
      "tstart = 1952-04-07 14:17:30 and tend = 1994-08-26 03:33:20 (test)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "train_version = 'de08nosc'\n",
    "test_version = 'mu28v4'\n",
    "name = 'dem' + '_'+ train_version  + '_' + test_version\n",
    "# leadtime = 12\n",
    "\n",
    "# t_start is defined using a funky timedelta because the starting date of the network analysis data is the last month\n",
    "# of its start year which is 1951-12 therefore the time must start in 1952 with some months added for values lost in \n",
    "# interpolation. TODO: fix this by backwards interpolating the first values of the year and finding out what is happening \n",
    "# with the nms\n",
    "train_times = np.unique(ZC_simple_read(train_version)['time'])\n",
    "test_times = np.unique(ZC_simple_read(test_version)['time'])\n",
    "\n",
    "train_t_start = train_times[0] + pd.Timedelta((2*365 + 90),'D')\n",
    "train_t_end = train_times[-1] - pd.Timedelta(90,'D')\n",
    "\n",
    "test_t_start = test_times[0] + pd.Timedelta((2*365 + 90),'D')\n",
    "test_t_end = test_times[-1] - pd.Timedelta(90,'D')\n",
    "\n",
    "print(f'tstart = {train_t_start} and tend = {train_t_end} (train)')\n",
    "print(f'tstart = {test_t_start} and tend = {test_t_end} (test)')\n",
    "\n",
    "t_start = train_t_start\n",
    "t_end = train_t_end\n",
    "times = train_times\n",
    "\n",
    "if train_t_end < pd.Timestamp('1990-01-01') or test_t_end < pd.Timestamp('1990-01-01'):\n",
    "    raise ValueError('one or both timeseries are too short!')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1999-01-01 00:00:00\n"
     ]
    }
   ],
   "source": [
    "time = pd.Timestamp('1999-01-01')\n",
    "print(time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using dimensions ('lat', 'lon') from data variable temperature as the horizontal dimensions for this dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ivo/anaconda3/envs/ninolearn/lib/python3.6/site-packages/xesmf/frontend.py:524: FutureWarning: ``output_sizes`` should be given in the ``dask_gufunc_kwargs`` parameter. It will be removed as direct parameter in a future version.\n",
      "  keep_attrs=keep_attrs\n",
      "/home/ivo/anaconda3/envs/ninolearn/lib/python3.6/site-packages/xesmf/smm.py:93: UserWarning: Input array is not C_CONTIGUOUS. Will affect performance.\n",
      "  warnings.warn(\"Input array is not C_CONTIGUOUS. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Read sst climatetology\n",
      "using dimensions ('lat', 'lon') from data variable temperature as the horizontal dimensions for this dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ivo/anaconda3/envs/ninolearn/lib/python3.6/site-packages/xesmf/frontend.py:524: FutureWarning: ``output_sizes`` should be given in the ``dask_gufunc_kwargs`` parameter. It will be removed as direct parameter in a future version.\n",
      "  keep_attrs=keep_attrs\n",
      "WARNING:Wrong input for computation of hamming distance.\n",
      "WARNING:Wrong input for computation of corrected hamming distance.\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "Exception ignored in: <bound method CachingFileManager.__del__ of CachingFileManager(<class 'netCDF4._netCDF4.Dataset'>, '/home/ivo/Documents/GitHub/ninolearn/research/ivo_thesis/data/processed/sst_ZC_25x25_de08nosc_anom.nc', mode='r', kwargs={'clobber': True, 'diskless': False, 'persist': False, 'format': 'NETCDF4'})>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ivo/anaconda3/envs/ninolearn/lib/python3.6/site-packages/xarray/backends/file_manager.py\", line 224, in __del__\n",
      "    def __del__(self):\n",
      "KeyboardInterrupt\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-1e667d09b4ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mZC_oni\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_version\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mprep_nms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_version\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.99\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_start\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_end\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# make plots\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/ninolearn/ninolearn/preprocess/prepare.py\u001b[0m in \u001b[0;36mprep_nms\u001b[0;34m(version, threshold_corr, tstart, tend)\u001b[0m\n\u001b[1;32m    351\u001b[0m                                 lat_min=-19, lat_max=19, verbose=2)\n\u001b[1;32m    352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m     \u001b[0mnms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomputeTimeSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m     \u001b[0mnms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/ninolearn/ninolearn/preprocess/network.py\u001b[0m in \u001b[0;36mcomputeTimeSeries\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    412\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{self.reader.startdate} till {self.reader.enddate}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m             \u001b[0mcorrcoef\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomputeCorrelationMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomputeNetworkMetrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorrcoef\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshift_window\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/ninolearn/ninolearn/preprocess/network.py\u001b[0m in \u001b[0;36mcomputeNetworkMetrics\u001b[0;34m(self, corrcoef)\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0;31m# hamming distance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhamming_distance\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msave_date\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhamming_distance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_adjacency\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m         \u001b[0;31m# corrected hamming distance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/ninolearn/ninolearn/preprocess/network.py\u001b[0m in \u001b[0;36mhamming_distance\u001b[0;34m(self, other_adjacency)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0;31m# Hamming distance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             H = np.sum(np.abs(self.adjacency_array[ui]\n\u001b[0m\u001b[1;32m    121\u001b[0m                               - other_adjacency[ui])) / binom(N, 2)\n\u001b[1;32m    122\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from ninolearn.IO.read_raw import ZC_raw, ZC_h, ZC_oni\n",
    "from ninolearn.preprocess.prepare import prep_nms\n",
    "from ninolearn.plot.ZC_dem_plots import nms_plots\n",
    "## read raw ZC data and save to 1x1 grid file in processeddir\n",
    "## also makes field of h and sst\n",
    "ZC_raw(train_version)\n",
    "\n",
    "## calculates monthly averaged (?) fields of thermocline height within region \n",
    "## of interest. cacluate ONI in region of interest. calculate network metrics \n",
    "## from sst (Henk's suggestion) or thermocline height (like Paul)\n",
    "ZC_h(train_version)\n",
    "ZC_oni(train_version)\n",
    "\n",
    "prep_nms(train_version, 0.99, t_start, t_end)\n",
    "\n",
    "# make plots\n",
    "# nms_plots(train_version)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using dimensions ('lat', 'lon') from data variable temperature as the horizontal dimensions for this dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ivo/anaconda3/envs/ninolearn/lib/python3.6/site-packages/xesmf/frontend.py:524: FutureWarning: ``output_sizes`` should be given in the ``dask_gufunc_kwargs`` parameter. It will be removed as direct parameter in a future version.\n",
      "  keep_attrs=keep_attrs\n",
      "/home/ivo/anaconda3/envs/ninolearn/lib/python3.6/site-packages/xesmf/smm.py:93: UserWarning: Input array is not C_CONTIGUOUS. Will affect performance.\n",
      "  warnings.warn(\"Input array is not C_CONTIGUOUS. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Read sst climatetology\n",
      "using dimensions ('lat', 'lon') from data variable temperature as the horizontal dimensions for this dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ivo/anaconda3/envs/ninolearn/lib/python3.6/site-packages/xesmf/frontend.py:524: FutureWarning: ``output_sizes`` should be given in the ``dask_gufunc_kwargs`` parameter. It will be removed as direct parameter in a future version.\n",
      "  keep_attrs=keep_attrs\n",
      "WARNING:Wrong input for computation of hamming distance.\n",
      "WARNING:Wrong input for computation of corrected hamming distance.\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n"
     ]
    }
   ],
   "source": [
    "ZC_raw(test_version)\n",
    "ZC_h(test_version)\n",
    "ZC_oni(test_version)\n",
    "prep_nms(test_version, 0.99, t_start, t_end)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "reader = data_reader(startdate=(t_start + pd.Timedelta(365,'D')) , enddate=(t_end - pd.Timedelta(2*365, 'D')) , lon_min = 124, lon_max = 280,\n",
    "                         lat_min = -19, lat_max = 19)\n",
    "\n",
    "oni = reader.read_csv(('oni_ZC_' +train_version))\n",
    "h = reader.read_csv(('h_mean_ZC_' + train_version))\n",
    "\n",
    "network_ssh = reader.read_statistic('network_metrics', variable='sst', dataset=('ZC_25x25_' + train_version), processed=\"anom\")\n",
    "c2 = network_ssh['fraction_clusters_size_2']\n",
    "H = network_ssh['corrected_hamming_distance']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All datasets are of equal length\n"
     ]
    }
   ],
   "source": [
    "if h.shape[0] + c2.shape[0] - H.shape[0] - oni.shape[0] == 0:\n",
    "    print('All datasets are of equal length')\n",
    "else:\n",
    "    print('warning: datasets not of equal size')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from ninolearn.utils import include_time_lag\n",
    "from ninolearn.IO.read_processed import data_reader\n",
    "\n",
    "version = train_version\n",
    "\n",
    "def train_pipeline(lead_time):\n",
    "    version = train_version\n",
    "    \"\"\"\n",
    "    Data pipeline for the processing of the data before the Deep Ensemble\n",
    "    is trained.\n",
    "\n",
    "    :type lead_time: int\n",
    "    :param lead_time: The lead time in month.\n",
    "\n",
    "    :returns: The feature \"X\" (at observation time), the label \"y\" (at lead\n",
    "    time), the target season \"timey\" (least month)\n",
    "    \"\"\"\n",
    "    timelag=False\n",
    "#     reader = data_reader(startdate='1952-01', enddate='1992-12', lon_min = 124, lon_max = 280,\n",
    "#                          lat_min = -19, lat_max = 19)\n",
    "    reader = data_reader(startdate=(t_start + oneyear), enddate=(t_end - 2*oneyear), lon_min = 124, lon_max = 280,\n",
    "                         lat_min = -19, lat_max = 19)\n",
    "\n",
    "    # indeces\n",
    "    oni = reader.read_csv(('oni_ZC_' +version))\n",
    "    h = reader.read_csv(('h_mean_ZC_' + version))\n",
    "    #IOD unavailable in ZC87 model \n",
    "    \n",
    "    # seasonal cycle\n",
    "    sc = np.cos(np.arange(len(oni))/12*2*np.pi)\n",
    "\n",
    "    # network metrics\n",
    "    network_ssh = reader.read_statistic('network_metrics', variable='sst', dataset=('ZC_25x25_'+version), processed=\"anom\")\n",
    "    c2 = network_ssh['fraction_clusters_size_2']\n",
    "    H = network_ssh['corrected_hamming_distance']\n",
    "\n",
    "    # time lag\n",
    "    time_lag = 12\n",
    "\n",
    "    # shift such that lead time corresponds to the definition of lead time\n",
    "    shift = 3\n",
    "\n",
    "    # process features\n",
    "    feature_unscaled = np.stack((oni, h,\n",
    "                                 c2, H), axis=1)\n",
    "\n",
    "    # scale each feature\n",
    "    scalerX = StandardScaler()\n",
    "    Xorg = scalerX.fit_transform(feature_unscaled)\n",
    "\n",
    "    # set nans to 0.\n",
    "    Xorg = np.nan_to_num(Xorg)\n",
    "\n",
    "    # arange the feature array\n",
    "    X = Xorg[:-lead_time-shift,:] # this chops of a bit at the end because matching labels will be offset by \n",
    "    # this amount. e.g. if our data runs until 2012 we need to remove X values for 2012 because we will use december 2011\n",
    "    # to predict december 2012 \n",
    "    \n",
    "#     X = include_time_lag(X, max_lag=time_lag)\n",
    "    X = include_time_lag(X, n_lags =time_lag)  # staggers the data with 1 month shifts so at each moment of input also\n",
    "    # nlags amount of months before is available to the AI\n",
    "        \n",
    "    # arange label\n",
    "    yorg = oni.values\n",
    "    y = yorg[lead_time + time_lag + shift:] # labels offset by lead_time to predict into the future and time_lag \n",
    "    # because the include_time_lag function shifts X values forward by an amount n_lags=time_lag\n",
    "    \n",
    "    # get the time axis of the label\n",
    "    timey = oni.index[lead_time + time_lag + shift:]\n",
    "\n",
    "    if timelag == False:\n",
    "        X = Xorg\n",
    "        y = yorg\n",
    "        timey = oni.index\n",
    "        \n",
    "    return X, y, timey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = test_version\n",
    "\n",
    "def test_pipeline(lead_time):\n",
    "    version = test_version\n",
    "\n",
    "    \"\"\"\n",
    "    Data pipeline for the processing of the data before the Deep Ensemble\n",
    "    is trained.\n",
    "\n",
    "    :type lead_time: int\n",
    "    :param lead_time: The lead time in month.\n",
    "\n",
    "    :returns: The feature \"X\" (at observation time), the label \"y\" (at lead\n",
    "    time), the target season \"timey\" (least month)\n",
    "    \"\"\"\n",
    "    timelag=False\n",
    "#     reader = data_reader(startdate='1952-01', enddate='1992-12', lon_min = 124, lon_max = 280,\n",
    "#                          lat_min = -19, lat_max = 19)\n",
    "    reader = data_reader(startdate=(t_start + oneyear), enddate=(t_end - 2*oneyear), lon_min = 124, lon_max = 280,\n",
    "                         lat_min = -19, lat_max = 19)\n",
    "\n",
    "    # indeces\n",
    "    oni = reader.read_csv(('oni_ZC_' +version))\n",
    "    h = reader.read_csv(('h_mean_ZC_' + version))\n",
    "    #IOD unavailable in ZC87 model \n",
    "    \n",
    "    # seasonal cycle\n",
    "    sc = np.cos(np.arange(len(oni))/12*2*np.pi)\n",
    "\n",
    "    # network metrics\n",
    "    network_ssh = reader.read_statistic('network_metrics', variable='sst', dataset=('ZC_25x25_'+version), processed=\"anom\")\n",
    "    c2 = network_ssh['fraction_clusters_size_2']\n",
    "    H = network_ssh['corrected_hamming_distance']\n",
    "\n",
    "    # time lag\n",
    "    time_lag = 12\n",
    "\n",
    "    # shift such that lead time corresponds to the definition of lead time\n",
    "    shift = 3\n",
    "\n",
    "    # process features\n",
    "    feature_unscaled = np.stack((oni, h,\n",
    "                                 c2, H), axis=1)\n",
    "\n",
    "    # scale each feature\n",
    "    scalerX = StandardScaler()\n",
    "    Xorg = scalerX.fit_transform(feature_unscaled)\n",
    "\n",
    "    # set nans to 0.\n",
    "    Xorg = np.nan_to_num(Xorg)\n",
    "\n",
    "    # arange the feature array\n",
    "    X = Xorg[:-lead_time-shift,:] # this chops of a bit at the end because matching labels will be offset by \n",
    "    # this amount. e.g. if our data runs until 2012 we need to remove X values for 2012 because we will use december 2011\n",
    "    # to predict december 2012 \n",
    "    \n",
    "#     X = include_time_lag(X, max_lag=time_lag)\n",
    "    X = include_time_lag(X, n_lags =time_lag)  # staggers the data with 1 month shifts so at each moment of input also\n",
    "    # nlags amount of months before is available to the AI\n",
    "        \n",
    "    # arange label\n",
    "    yorg = oni.values\n",
    "    y = yorg[lead_time + time_lag + shift:] # labels offset by lead_time to predict into the future and time_lag \n",
    "    # because the include_time_lag function shifts X values forward by an amount n_lags=time_lag\n",
    "    \n",
    "    # get the time axis of the label\n",
    "    timey = oni.index[lead_time + time_lag + shift:]\n",
    "\n",
    "    if timelag == False:\n",
    "        X = Xorg\n",
    "        y = yorg\n",
    "        timey = oni.index\n",
    "        \n",
    "    return X, y, timey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0, _, _, x3, _, _= *train_pipeline(0), *train_pipeline(3)\n",
    "if x0.shape != x3.shape:\n",
    "    print(\"WARNING: shape mismatch between inputs for different lead times (traindata)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0, _, _, x3, _, _= *test_pipeline(0), *test_pipeline(3)\n",
    "if x0.shape != x3.shape:\n",
    "    print(\"WARNING: shape mismatch between inputs for different lead times (testdata)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the data set\n",
    "\n",
    "For the training and testing of machine learning models it is crucial to split the data set into:\n",
    "\n",
    "1. __Train data set__ which is used to train the weights of the neural network\n",
    "\n",
    "2. __Validation data set__ which is used to check for overfitting (e.g. when using early stopping) and to optimize the hyperparameters \n",
    "\n",
    "3. __Test data set__ which is used to to evaluate the trained model. \n",
    "\n",
    "__NOTE:__ It is important to understand that hyperparamters must be tuned so that the result is best for the Validation data set and __not__ for the test data set. Otherwise you can not rule out the case that the specific hyperparameter setting just works good for the specific test data set but is not generally a good hyperparameter setting.\n",
    "\n",
    "In the following cell the train and the validation data set are still one data set, because this array will be later splitted into two arrays when th model is fitted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import keras.backend as K\n",
    "# from ninolearn.learn.models.dem import DEM\n",
    "\n",
    "# # clear memory from previous sessions\n",
    "# K.clear_session()\n",
    "\n",
    "# # define the lead time\n",
    "# lead_time = leadtime\n",
    "\n",
    "# # get the features (X), the label (y) and \n",
    "# # the time axis of the label (timey)\n",
    "# X, y, timey = pipeline(lead_time)\n",
    "\n",
    "# # split the data set into \n",
    "# # test_indeces = (timey>='1987-01-01') & (timey<='1993-12-01')\n",
    "# test_indeces = (timey>=t_end - pd.Timedelta(5*365, 'D')) & (timey<=t_end)\n",
    "\n",
    "# train_val_indeces = np.invert(test_indeces)\n",
    "\n",
    "# train_val_X, train_val_y, train_val_timey = X[train_val_indeces,:], y[train_val_indeces], timey[train_val_indeces]\n",
    "# testX, testy, testtimey = X[test_indeces,:], y[test_indeces], timey[test_indeces]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(y.shape, X.shape, timey.shape)\n",
    "# print('shapes of the data, labels and time axis is predictable, since there are now 4 features and 12 lags \\\n",
    "#     making for 48 columns. The labels are offset from the input data by the lead time ')\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the model\n",
    "\n",
    "Now it is time to train the model! For this a random search is used for all keyword arguments that are passed in a *list* to the DEM.set_parameters() method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # initiated an instance of the DEM (Deep Ensemble Model) class\n",
    "# model = DEM()\n",
    "\n",
    "# # Set parameters\n",
    "# model.set_hyperparameters(searchtype='linear', layers=1, neurons=16, dropout=[0.1, 0.5], noise_in=[0.1,0.5], noise_sigma=[0.1,0.5],\n",
    "#                      noise_mu=[0.1,0.5], l1_hidden=[0.0, 0.2], l2_hidden=[0., 0.2],\n",
    "#                      l1_mu=[0.0, 0.2], l2_mu=[0.0, 0.2], l1_sigma=[0.0, 0.2],\n",
    "#                      l2_sigma=[0.0, 0.2], lr=[0.0001,0.01], batch_size=100, epochs=500, n_segments=5,\n",
    "#                      n_members_segment=1, patience=30, verbose=0, pdf='normal', activation = 'relu')\n",
    "\n",
    "# # Use a random search to find the optimal hyperparameters\n",
    "\n",
    "# model.fit_RandomizedSearch(train_val_X, train_val_y, train_val_timey, n_iter=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##################################################################\n",
      "Lead time: 0 month\n",
      "##################################################################\n",
      "\n",
      "Test period: 1953-01-01 till 1961-12-01\n",
      "--------------------------------------\n",
      "Search iteration Nr 1/1\n",
      "build\n",
      "Train member Nr 1/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00031: early stopping\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1238 - nll_gaussian: -0.0299\n",
      "build\n",
      "Train member Nr 2/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00042: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -0.0543 - nll_gaussian: -0.3181\n",
      "build\n",
      "Train member Nr 3/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00071: early stopping\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.3737 - nll_gaussian: 0.0787\n",
      "build\n",
      "Train member Nr 4/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00089: early stopping\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3471 - nll_gaussian: 0.1082\n",
      "build\n",
      "Train member Nr 5/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00031: early stopping\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0190 - nll_gaussian: -0.2393\n",
      "Loss: -0.08007287681102752\n",
      "Computation time: 33.7s\n",
      "New best hyperparameters\n",
      "Mean loss: -0.08007287681102752\n",
      "{'layers': 1, 'neurons': 16, 'dropout': 0.3312092729365629, 'noise_in': 0.14963828432656207, 'noise_mu': 0.3268046478420479, 'noise_sigma': 0.32136395986169897, 'noise_alpha': 0.0, 'l1_hidden': 0.11065404100214814, 'l2_hidden': 0.08828908970347678, 'l1_mu': 0.12917397802266456, 'l2_mu': 0.0258580511021423, 'l1_sigma': 0.13890745788109143, 'l2_sigma': 0.16212499248231282, 'l1_alpha': 0.0, 'l2_alpha': 0.0, 'batch_size': 100, 'n_segments': 5, 'n_members_segment': 1, 'lr': 0.0030767858681170117, 'patience': 30, 'epochs': 500, 'verbose': 0, 'pdf': 'normal', 'activation': 'relu', 'name': 'dem_de08nosc_mu28v4', 'n_members': 5}\n",
      "Test period: 1962-01-01 till 1971-12-01\n",
      "--------------------------------------\n",
      "Search iteration Nr 1/1\n",
      "build\n",
      "Train member Nr 1/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00089: early stopping\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4880 - nll_gaussian: 0.2984\n",
      "build\n",
      "Train member Nr 2/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00031: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.1116 - nll_gaussian: -0.0583\n",
      "build\n",
      "Train member Nr 3/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00038: early stopping\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1834 - nll_gaussian: 0.0986\n",
      "build\n",
      "Train member Nr 4/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00031: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2221 - nll_gaussian: 0.0793\n",
      "build\n",
      "Train member Nr 5/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00031: early stopping\n",
      "3/3 [==============================] - 0s 4ms/step - loss: -0.1392 - nll_gaussian: -0.2430\n",
      "Loss: 0.03499589785933495\n",
      "Computation time: 27.4s\n",
      "New best hyperparameters\n",
      "Mean loss: 0.03499589785933495\n",
      "{'layers': 1, 'neurons': 16, 'dropout': 0.22315614342269174, 'noise_in': 0.4506095660150048, 'noise_mu': 0.20848354537315586, 'noise_sigma': 0.15585237466422247, 'noise_alpha': 0.0, 'l1_hidden': 0.009910873354050033, 'l2_hidden': 0.18659693703317434, 'l1_mu': 0.10381142478535516, 'l2_mu': 0.006478857370345193, 'l1_sigma': 0.09794522197981113, 'l2_sigma': 0.014358695450942795, 'l1_alpha': 0.0, 'l2_alpha': 0.0, 'batch_size': 100, 'n_segments': 5, 'n_members_segment': 1, 'lr': 0.0038288547820637623, 'patience': 30, 'epochs': 500, 'verbose': 0, 'pdf': 'normal', 'activation': 'relu', 'name': 'dem_de08nosc_mu28v4', 'n_members': 5}\n",
      "Test period: 1972-01-01 till 1981-12-01\n",
      "--------------------------------------\n",
      "Search iteration Nr 1/1\n",
      "build\n",
      "Train member Nr 1/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00062: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -0.1623 - nll_gaussian: -0.4199\n",
      "build\n",
      "Train member Nr 2/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00060: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -0.1914 - nll_gaussian: -0.5951\n",
      "build\n",
      "Train member Nr 3/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00044: early stopping\n",
      "3/3 [==============================] - 0s 5ms/step - loss: -0.0500 - nll_gaussian: -0.2658\n",
      "build\n",
      "Train member Nr 4/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00051: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -0.2275 - nll_gaussian: -0.5044\n",
      "build\n",
      "Train member Nr 5/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00117: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -0.5110 - nll_gaussian: -1.3122\n",
      "Loss: -0.6194749534130096\n",
      "Computation time: 38.7s\n",
      "New best hyperparameters\n",
      "Mean loss: -0.6194749534130096\n",
      "{'layers': 1, 'neurons': 16, 'dropout': 0.1263505035393204, 'noise_in': 0.27346082342552325, 'noise_mu': 0.1538917032997242, 'noise_sigma': 0.20399435828109552, 'noise_alpha': 0.0, 'l1_hidden': 0.0033659040107762773, 'l2_hidden': 0.09811380006277036, 'l1_mu': 0.02305199883910345, 'l2_mu': 0.17124403401944366, 'l1_sigma': 0.05590160430340825, 'l2_sigma': 0.078181444524398, 'l1_alpha': 0.0, 'l2_alpha': 0.0, 'batch_size': 100, 'n_segments': 5, 'n_members_segment': 1, 'lr': 0.009230709381722184, 'patience': 30, 'epochs': 500, 'verbose': 0, 'pdf': 'normal', 'activation': 'relu', 'name': 'dem_de08nosc_mu28v4', 'n_members': 5}\n",
      "Test period: 1982-01-01 till 1991-12-01\n",
      "--------------------------------------\n",
      "Search iteration Nr 1/1\n",
      "build\n",
      "Train member Nr 1/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00150: early stopping\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6869 - nll_gaussian: -0.1642\n",
      "build\n",
      "Train member Nr 2/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00135: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.7618 - nll_gaussian: -0.1164\n",
      "build\n",
      "Train member Nr 3/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00082: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2120 - nll_gaussian: -0.2342\n",
      "build\n",
      "Train member Nr 4/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00041: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.1269 - nll_gaussian: 0.1561\n",
      "build\n",
      "Train member Nr 5/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00061: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.3250 - nll_gaussian: -0.1404\n",
      "Loss: -0.09981236606836319\n",
      "Computation time: 51.3s\n",
      "New best hyperparameters\n",
      "Mean loss: -0.09981236606836319\n",
      "{'layers': 1, 'neurons': 16, 'dropout': 0.3845309230289916, 'noise_in': 0.2490332629822546, 'noise_mu': 0.18518867906841982, 'noise_sigma': 0.4095867873253294, 'noise_alpha': 0.0, 'l1_hidden': 0.08861271037387737, 'l2_hidden': 0.031125363973644404, 'l1_mu': 0.0808661150303419, 'l2_mu': 0.078797561294944, 'l1_sigma': 0.0370280975296335, 'l2_sigma': 0.026134355965306468, 'l1_alpha': 0.0, 'l2_alpha': 0.0, 'batch_size': 100, 'n_segments': 5, 'n_members_segment': 1, 'lr': 0.006956185550863078, 'patience': 30, 'epochs': 500, 'verbose': 0, 'pdf': 'normal', 'activation': 'relu', 'name': 'dem_de08nosc_mu28v4', 'n_members': 5}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##################################################################\n",
      "Lead time: 3 month\n",
      "##################################################################\n",
      "\n",
      "Test period: 1953-01-01 till 1961-12-01\n",
      "--------------------------------------\n",
      "Search iteration Nr 1/1\n",
      "build\n",
      "Train member Nr 1/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00044: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -0.0064 - nll_gaussian: -0.0528\n",
      "build\n",
      "Train member Nr 2/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00053: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -0.2080 - nll_gaussian: -0.3253\n",
      "build\n",
      "Train member Nr 3/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00033: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2713 - nll_gaussian: 0.0829\n",
      "build\n",
      "Train member Nr 4/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00140: early stopping\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.3898 - nll_gaussian: 0.0834\n",
      "build\n",
      "Train member Nr 5/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00093: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0188 - nll_gaussian: -0.2566\n",
      "Loss: -0.09367867931723595\n",
      "Computation time: 42.4s\n",
      "New best hyperparameters\n",
      "Mean loss: -0.09367867931723595\n",
      "{'layers': 1, 'neurons': 16, 'dropout': 0.3503362882480422, 'noise_in': 0.22321884617406226, 'noise_mu': 0.4962263140833044, 'noise_sigma': 0.3204337554045812, 'noise_alpha': 0.0, 'l1_hidden': 0.07418268553654338, 'l2_hidden': 0.07032489199773999, 'l1_mu': 0.11813515519979319, 'l2_mu': 0.17871594576855543, 'l1_sigma': 0.0016461950064116772, 'l2_sigma': 0.04477711324720508, 'l1_alpha': 0.0, 'l2_alpha': 0.0, 'batch_size': 100, 'n_segments': 5, 'n_members_segment': 1, 'lr': 0.002520938358141181, 'patience': 30, 'epochs': 500, 'verbose': 0, 'pdf': 'normal', 'activation': 'relu', 'name': 'dem_de08nosc_mu28v4', 'n_members': 5}\n",
      "Test period: 1962-01-01 till 1971-12-01\n",
      "--------------------------------------\n",
      "Search iteration Nr 1/1\n",
      "build\n",
      "Train member Nr 1/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00079: early stopping\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.5869 - nll_gaussian: 0.0579\n",
      "build\n",
      "Train member Nr 2/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00032: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.3316 - nll_gaussian: -0.0534\n",
      "build\n",
      "Train member Nr 3/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00057: early stopping\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.9848 - nll_gaussian: -0.0087\n",
      "build\n",
      "Train member Nr 4/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00044: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.8048 - nll_gaussian: 0.0446\n",
      "build\n",
      "Train member Nr 5/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00032: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0505 - nll_gaussian: -0.2539\n",
      "Loss: -0.04267070200294256\n",
      "Computation time: 32.0s\n",
      "New best hyperparameters\n",
      "Mean loss: -0.04267070200294256\n",
      "{'layers': 1, 'neurons': 16, 'dropout': 0.4426612904772259, 'noise_in': 0.36977465362513773, 'noise_mu': 0.13502074875340828, 'noise_sigma': 0.42328665845700697, 'noise_alpha': 0.0, 'l1_hidden': 0.06852080608022859, 'l2_hidden': 0.17825373488286608, 'l1_mu': 0.17648475943420597, 'l2_mu': 0.059429790119194074, 'l1_sigma': 0.1737966358893404, 'l2_sigma': 0.12329282976111258, 'l1_alpha': 0.0, 'l2_alpha': 0.0, 'batch_size': 100, 'n_segments': 5, 'n_members_segment': 1, 'lr': 0.009458880331559975, 'patience': 30, 'epochs': 500, 'verbose': 0, 'pdf': 'normal', 'activation': 'relu', 'name': 'dem_de08nosc_mu28v4', 'n_members': 5}\n",
      "Test period: 1972-01-01 till 1981-12-01\n",
      "--------------------------------------\n",
      "Search iteration Nr 1/1\n",
      "build\n",
      "Train member Nr 1/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00031: early stopping\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7311 - nll_gaussian: 0.3337\n",
      "build\n",
      "Train member Nr 2/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00031: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2901 - nll_gaussian: 0.0105\n",
      "build\n",
      "Train member Nr 3/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00031: early stopping\n",
      "3/3 [==============================] - 0s 6ms/step - loss: -0.0466 - nll_gaussian: -0.1983\n",
      "build\n",
      "Train member Nr 4/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00031: early stopping\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2878 - nll_gaussian: 0.0543\n",
      "build\n",
      "Train member Nr 5/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00031: early stopping\n",
      "3/3 [==============================] - 0s 8ms/step - loss: -0.0770 - nll_gaussian: -0.2412\n",
      "Loss: -0.008197229355573654\n",
      "Computation time: 23.7s\n",
      "New best hyperparameters\n",
      "Mean loss: -0.008197229355573654\n",
      "{'layers': 1, 'neurons': 16, 'dropout': 0.3377309229415944, 'noise_in': 0.457911872942418, 'noise_mu': 0.21081716067104506, 'noise_sigma': 0.10281753358160826, 'noise_alpha': 0.0, 'l1_hidden': 0.15242841683608543, 'l2_hidden': 0.0551047469389822, 'l1_mu': 0.06462140745502924, 'l2_mu': 0.04789204624742092, 'l1_sigma': 0.17878081683353456, 'l2_sigma': 0.15682342989003709, 'l1_alpha': 0.0, 'l2_alpha': 0.0, 'batch_size': 100, 'n_segments': 5, 'n_members_segment': 1, 'lr': 0.0062458163999596, 'patience': 30, 'epochs': 500, 'verbose': 0, 'pdf': 'normal', 'activation': 'relu', 'name': 'dem_de08nosc_mu28v4', 'n_members': 5}\n",
      "Test period: 1982-01-01 till 1991-12-01\n",
      "--------------------------------------\n",
      "Search iteration Nr 1/1\n",
      "build\n",
      "Train member Nr 1/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00096: early stopping\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4790 - nll_gaussian: 0.3041\n",
      "build\n",
      "Train member Nr 2/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00031: early stopping\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2594 - nll_gaussian: 0.0100\n",
      "build\n",
      "Train member Nr 3/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00031: early stopping\n",
      "3/3 [==============================] - 0s 1ms/step - loss: -0.0413 - nll_gaussian: -0.2004\n",
      "build\n",
      "Train member Nr 4/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00031: early stopping\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -0.0257 - nll_gaussian: 0.2153\n",
      "build\n",
      "Train member Nr 5/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00031: early stopping\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1643 - nll_gaussian: -0.0643\n",
      "Loss: 0.05295111183077097\n",
      "Computation time: 27.0s\n",
      "New best hyperparameters\n",
      "Mean loss: 0.05295111183077097\n",
      "{'layers': 1, 'neurons': 16, 'dropout': 0.11354935402258347, 'noise_in': 0.19728231957536677, 'noise_mu': 0.31397667369979054, 'noise_sigma': 0.18924194588166554, 'noise_alpha': 0.0, 'l1_hidden': 0.12214593209147324, 'l2_hidden': 0.04930465108981741, 'l1_mu': 0.16756893061354206, 'l2_mu': 0.17507797654817256, 'l1_sigma': 0.013281949457612498, 'l2_sigma': 0.0026516156124748004, 'l1_alpha': 0.0, 'l2_alpha': 0.0, 'batch_size': 100, 'n_segments': 5, 'n_members_segment': 1, 'lr': 0.006831230274937766, 'patience': 30, 'epochs': 500, 'verbose': 0, 'pdf': 'normal', 'activation': 'relu', 'name': 'dem_de08nosc_mu28v4', 'n_members': 5}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##################################################################\n",
      "Lead time: 6 month\n",
      "##################################################################\n",
      "\n",
      "Test period: 1953-01-01 till 1961-12-01\n",
      "--------------------------------------\n",
      "Search iteration Nr 1/1\n",
      "build\n",
      "Train member Nr 1/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00094: early stopping\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0496 - nll_gaussian: -0.2510\n",
      "build\n",
      "Train member Nr 2/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00031: early stopping\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -0.2430 - nll_gaussian: -0.3115\n",
      "build\n",
      "Train member Nr 3/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00196: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2904 - nll_gaussian: -0.1670\n",
      "build\n",
      "Train member Nr 4/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00066: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2939 - nll_gaussian: 0.0603\n",
      "build\n",
      "Train member Nr 5/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00034: early stopping\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -0.1550 - nll_gaussian: -0.2466\n",
      "Loss: -0.18316612616181374\n",
      "Computation time: 51.2s\n",
      "New best hyperparameters\n",
      "Mean loss: -0.18316612616181374\n",
      "{'layers': 1, 'neurons': 16, 'dropout': 0.1392979630611275, 'noise_in': 0.2805526307937335, 'noise_mu': 0.3695030198469691, 'noise_sigma': 0.2774055836932594, 'noise_alpha': 0.0, 'l1_hidden': 0.00021635301187854507, 'l2_hidden': 0.003898984378179704, 'l1_mu': 0.10426532658189042, 'l2_mu': 0.16944811384305358, 'l1_sigma': 0.05873702159329319, 'l2_sigma': 0.15217598962500917, 'l1_alpha': 0.0, 'l2_alpha': 0.0, 'batch_size': 100, 'n_segments': 5, 'n_members_segment': 1, 'lr': 0.0065568687912619834, 'patience': 30, 'epochs': 500, 'verbose': 0, 'pdf': 'normal', 'activation': 'relu', 'name': 'dem_de08nosc_mu28v4', 'n_members': 5}\n",
      "Test period: 1962-01-01 till 1971-12-01\n",
      "--------------------------------------\n",
      "Search iteration Nr 1/1\n",
      "build\n",
      "Train member Nr 1/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00077: early stopping\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6639 - nll_gaussian: -0.0278\n",
      "build\n",
      "Train member Nr 2/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00043: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4591 - nll_gaussian: -0.0539\n",
      "build\n",
      "Train member Nr 3/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00049: early stopping\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4424 - nll_gaussian: 0.0373\n",
      "build\n",
      "Train member Nr 4/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00041: early stopping\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5092 - nll_gaussian: 0.0320\n",
      "build\n",
      "Train member Nr 5/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00067: early stopping\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2368 - nll_gaussian: -0.3362\n",
      "Loss: -0.0697405118495226\n",
      "Computation time: 36.3s\n",
      "New best hyperparameters\n",
      "Mean loss: -0.0697405118495226\n",
      "{'layers': 1, 'neurons': 16, 'dropout': 0.26379537383516527, 'noise_in': 0.4014808015557165, 'noise_mu': 0.1705771192652386, 'noise_sigma': 0.2852825210574613, 'noise_alpha': 0.0, 'l1_hidden': 0.11879160331790689, 'l2_hidden': 0.12855032513241005, 'l1_mu': 0.010771207694765207, 'l2_mu': 0.04888306305900991, 'l1_sigma': 0.04115224797154078, 'l2_sigma': 0.10588677600442192, 'l1_alpha': 0.0, 'l2_alpha': 0.0, 'batch_size': 100, 'n_segments': 5, 'n_members_segment': 1, 'lr': 0.007716400027832348, 'patience': 30, 'epochs': 500, 'verbose': 0, 'pdf': 'normal', 'activation': 'relu', 'name': 'dem_de08nosc_mu28v4', 'n_members': 5}\n",
      "Test period: 1972-01-01 till 1981-12-01\n",
      "--------------------------------------\n",
      "Search iteration Nr 1/1\n",
      "build\n",
      "Train member Nr 1/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00130: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.4820 - nll_gaussian: 0.0244\n",
      "build\n",
      "Train member Nr 2/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00068: early stopping\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9156 - nll_gaussian: 0.0230\n",
      "build\n",
      "Train member Nr 3/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00031: early stopping\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0593 - nll_gaussian: -0.1979\n",
      "build\n",
      "Train member Nr 4/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00101: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.2662 - nll_gaussian: -0.0759\n",
      "build\n",
      "Train member Nr 5/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00120: early stopping\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.8722 - nll_gaussian: -0.3044\n",
      "Loss: -0.10616537556052208\n",
      "Computation time: 49.3s\n",
      "New best hyperparameters\n",
      "Mean loss: -0.10616537556052208\n",
      "{'layers': 1, 'neurons': 16, 'dropout': 0.4793717549187604, 'noise_in': 0.4775516421749886, 'noise_mu': 0.13499324858272976, 'noise_sigma': 0.37774363377494125, 'noise_alpha': 0.0, 'l1_hidden': 0.16821976737331892, 'l2_hidden': 0.14311423114565439, 'l1_mu': 0.09618141100020833, 'l2_mu': 0.16610305254641122, 'l1_sigma': 0.06387857714310592, 'l2_sigma': 0.11640728861750144, 'l1_alpha': 0.0, 'l2_alpha': 0.0, 'batch_size': 100, 'n_segments': 5, 'n_members_segment': 1, 'lr': 0.007035944433948811, 'patience': 30, 'epochs': 500, 'verbose': 0, 'pdf': 'normal', 'activation': 'relu', 'name': 'dem_de08nosc_mu28v4', 'n_members': 5}\n",
      "Test period: 1982-01-01 till 1991-12-01\n",
      "--------------------------------------\n",
      "Search iteration Nr 1/1\n",
      "build\n",
      "Train member Nr 1/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00082: early stopping\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.9402 - nll_gaussian: 0.2209\n",
      "build\n",
      "Train member Nr 2/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00159: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.3929 - nll_gaussian: -0.7369\n",
      "build\n",
      "Train member Nr 3/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00065: early stopping\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2551 - nll_gaussian: -0.2876\n",
      "build\n",
      "Train member Nr 4/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00063: early stopping\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4321 - nll_gaussian: 0.2198\n",
      "build\n",
      "Train member Nr 5/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00063: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.5150 - nll_gaussian: -0.1104\n",
      "Loss: -0.13884928226470947\n",
      "Computation time: 52.2s\n",
      "New best hyperparameters\n",
      "Mean loss: -0.13884928226470947\n",
      "{'layers': 1, 'neurons': 16, 'dropout': 0.4264858257767081, 'noise_in': 0.18480410622321808, 'noise_mu': 0.4951419513761459, 'noise_sigma': 0.40242139300320234, 'noise_alpha': 0.0, 'l1_hidden': 0.03528298219517241, 'l2_hidden': 0.08300955863816412, 'l1_mu': 0.18028564658213245, 'l2_mu': 0.1065334770194927, 'l1_sigma': 0.06937978988162201, 'l2_sigma': 0.12785373228553698, 'l1_alpha': 0.0, 'l2_alpha': 0.0, 'batch_size': 100, 'n_segments': 5, 'n_members_segment': 1, 'lr': 0.008800683282569312, 'patience': 30, 'epochs': 500, 'verbose': 0, 'pdf': 'normal', 'activation': 'relu', 'name': 'dem_de08nosc_mu28v4', 'n_members': 5}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##################################################################\n",
      "Lead time: 9 month\n",
      "##################################################################\n",
      "\n",
      "Test period: 1953-01-01 till 1961-12-01\n",
      "--------------------------------------\n",
      "Search iteration Nr 1/1\n",
      "build\n",
      "Train member Nr 1/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00031: early stopping\n",
      "3/3 [==============================] - 0s 4ms/step - loss: -0.0399 - nll_gaussian: -0.0194\n",
      "build\n",
      "Train member Nr 2/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00031: early stopping\n",
      "3/3 [==============================] - 0s 4ms/step - loss: -0.1780 - nll_gaussian: -0.3010\n",
      "build\n",
      "Train member Nr 3/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00079: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.3572 - nll_gaussian: 0.0239\n",
      "build\n",
      "Train member Nr 4/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00047: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.3446 - nll_gaussian: 0.1072\n",
      "build\n",
      "Train member Nr 5/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00039: early stopping\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -0.0783 - nll_gaussian: -0.2791\n",
      "Loss: -0.09368562214076519\n",
      "Computation time: 28.2s\n",
      "New best hyperparameters\n",
      "Mean loss: -0.09368562214076519\n",
      "{'layers': 1, 'neurons': 16, 'dropout': 0.35147411420373, 'noise_in': 0.11163585348985348, 'noise_mu': 0.3060758069736956, 'noise_sigma': 0.3384551114517867, 'noise_alpha': 0.0, 'l1_hidden': 0.013673849799732275, 'l2_hidden': 0.10626084807108638, 'l1_mu': 0.14161966998054742, 'l2_mu': 0.018786522028710895, 'l1_sigma': 0.1123540313635729, 'l2_sigma': 0.02654682242754902, 'l1_alpha': 0.0, 'l2_alpha': 0.0, 'batch_size': 100, 'n_segments': 5, 'n_members_segment': 1, 'lr': 0.006636954935921636, 'patience': 30, 'epochs': 500, 'verbose': 0, 'pdf': 'normal', 'activation': 'relu', 'name': 'dem_de08nosc_mu28v4', 'n_members': 5}\n",
      "Test period: 1962-01-01 till 1971-12-01\n",
      "--------------------------------------\n",
      "Search iteration Nr 1/1\n",
      "build\n",
      "Train member Nr 1/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00103: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.1225 - nll_gaussian: 0.0585\n",
      "build\n",
      "Train member Nr 2/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00146: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.8085 - nll_gaussian: -0.2418\n",
      "build\n",
      "Train member Nr 3/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00037: early stopping\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4571 - nll_gaussian: 0.0829\n",
      "build\n",
      "Train member Nr 4/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00055: early stopping\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6230 - nll_gaussian: 0.0460\n",
      "build\n",
      "Train member Nr 5/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00101: early stopping\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.5122 - nll_gaussian: -0.3621\n",
      "Loss: -0.08327770158648491\n",
      "Computation time: 49.1s\n",
      "New best hyperparameters\n",
      "Mean loss: -0.08327770158648491\n",
      "{'layers': 1, 'neurons': 16, 'dropout': 0.27418484304696117, 'noise_in': 0.32896554141039236, 'noise_mu': 0.2442968009692491, 'noise_sigma': 0.3260382324633713, 'noise_alpha': 0.0, 'l1_hidden': 0.12775885735603656, 'l2_hidden': 0.14352918505740606, 'l1_mu': 0.09340216577218136, 'l2_mu': 0.02178183040930164, 'l1_sigma': 0.04516814275843215, 'l2_sigma': 0.15793426443848793, 'l1_alpha': 0.0, 'l2_alpha': 0.0, 'batch_size': 100, 'n_segments': 5, 'n_members_segment': 1, 'lr': 0.007745613374836471, 'patience': 30, 'epochs': 500, 'verbose': 0, 'pdf': 'normal', 'activation': 'relu', 'name': 'dem_de08nosc_mu28v4', 'n_members': 5}\n",
      "Test period: 1972-01-01 till 1981-12-01\n",
      "--------------------------------------\n",
      "Search iteration Nr 1/1\n",
      "build\n",
      "Train member Nr 1/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00039: early stopping\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6849 - nll_gaussian: 0.3054\n",
      "build\n",
      "Train member Nr 2/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00040: early stopping\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2870 - nll_gaussian: 0.0231\n",
      "build\n",
      "Train member Nr 3/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00087: early stopping\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1509 - nll_gaussian: -0.2507\n",
      "build\n",
      "Train member Nr 4/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00032: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2451 - nll_gaussian: 0.0547\n",
      "build\n",
      "Train member Nr 5/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00031: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -0.0054 - nll_gaussian: -0.2409\n",
      "Loss: -0.021687417477369308\n",
      "Computation time: 30.6s\n",
      "New best hyperparameters\n",
      "Mean loss: -0.021687417477369308\n",
      "{'layers': 1, 'neurons': 16, 'dropout': 0.3679298467370563, 'noise_in': 0.3154146964587002, 'noise_mu': 0.3875303210272998, 'noise_sigma': 0.24596826124213958, 'noise_alpha': 0.0, 'l1_hidden': 0.10548902879862443, 'l2_hidden': 0.16759103498879885, 'l1_mu': 0.19461840238835199, 'l2_mu': 0.07014145247501583, 'l1_sigma': 0.042800980874542344, 'l2_sigma': 0.19638640619352823, 'l1_alpha': 0.0, 'l2_alpha': 0.0, 'batch_size': 100, 'n_segments': 5, 'n_members_segment': 1, 'lr': 0.006347016911606822, 'patience': 30, 'epochs': 500, 'verbose': 0, 'pdf': 'normal', 'activation': 'relu', 'name': 'dem_de08nosc_mu28v4', 'n_members': 5}\n",
      "Test period: 1982-01-01 till 1991-12-01\n",
      "--------------------------------------\n",
      "Search iteration Nr 1/1\n",
      "build\n",
      "Train member Nr 1/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00187: early stopping\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8756 - nll_gaussian: 0.2814\n",
      "build\n",
      "Train member Nr 2/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00103: early stopping\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.4936 - nll_gaussian: -0.0026\n",
      "build\n",
      "Train member Nr 3/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00072: early stopping\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.1463 - nll_gaussian: -0.2186\n",
      "build\n",
      "Train member Nr 4/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00031: early stopping\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.1801 - nll_gaussian: 0.2110\n",
      "build\n",
      "Train member Nr 5/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00124: early stopping\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.3682 - nll_gaussian: -0.0780\n",
      "Loss: 0.03864660761319101\n",
      "Computation time: 55.7s\n",
      "New best hyperparameters\n",
      "Mean loss: 0.03864660761319101\n",
      "{'layers': 1, 'neurons': 16, 'dropout': 0.3970703013691782, 'noise_in': 0.36297795374465724, 'noise_mu': 0.196076293467908, 'noise_sigma': 0.4287455768164322, 'noise_alpha': 0.0, 'l1_hidden': 0.1495084352860987, 'l2_hidden': 0.17509478729757694, 'l1_mu': 0.08491720241484912, 'l2_mu': 0.0308109430721901, 'l1_sigma': 0.14803181238410099, 'l2_sigma': 0.1806673617838588, 'l1_alpha': 0.0, 'l2_alpha': 0.0, 'batch_size': 100, 'n_segments': 5, 'n_members_segment': 1, 'lr': 0.0007535748526880034, 'patience': 30, 'epochs': 500, 'verbose': 0, 'pdf': 'normal', 'activation': 'relu', 'name': 'dem_de08nosc_mu28v4', 'n_members': 5}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##################################################################\n",
      "Lead time: 12 month\n",
      "##################################################################\n",
      "\n",
      "Test period: 1953-01-01 till 1961-12-01\n",
      "--------------------------------------\n",
      "Search iteration Nr 1/1\n",
      "build\n",
      "Train member Nr 1/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00036: early stopping\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0775 - nll_gaussian: -0.0322\n",
      "build\n",
      "Train member Nr 2/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00263: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6965 - nll_gaussian: -0.4022\n",
      "build\n",
      "Train member Nr 3/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00178: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.8927 - nll_gaussian: 0.0827\n",
      "build\n",
      "Train member Nr 4/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00050: early stopping\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6207 - nll_gaussian: 0.1034\n",
      "build\n",
      "Train member Nr 5/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00032: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0787 - nll_gaussian: -0.2410\n",
      "Loss: -0.09784362465143204\n",
      "Computation time: 57.9s\n",
      "New best hyperparameters\n",
      "Mean loss: -0.09784362465143204\n",
      "{'layers': 1, 'neurons': 16, 'dropout': 0.4703126387667723, 'noise_in': 0.18565695090881654, 'noise_mu': 0.22807267987484459, 'noise_sigma': 0.34329253157699424, 'noise_alpha': 0.0, 'l1_hidden': 0.18181981423611004, 'l2_hidden': 0.0713885396037243, 'l1_mu': 0.16659077981028578, 'l2_mu': 0.06441690093674315, 'l1_sigma': 0.12385493008430284, 'l2_sigma': 0.15478573717854538, 'l1_alpha': 0.0, 'l2_alpha': 0.0, 'batch_size': 100, 'n_segments': 5, 'n_members_segment': 1, 'lr': 0.003935875295851557, 'patience': 30, 'epochs': 500, 'verbose': 0, 'pdf': 'normal', 'activation': 'relu', 'name': 'dem_de08nosc_mu28v4', 'n_members': 5}\n",
      "Test period: 1962-01-01 till 1971-12-01\n",
      "--------------------------------------\n",
      "Search iteration Nr 1/1\n",
      "build\n",
      "Train member Nr 1/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00088: early stopping\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4767 - nll_gaussian: 0.2943\n",
      "build\n",
      "Train member Nr 2/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00031: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2061 - nll_gaussian: -0.0550\n",
      "build\n",
      "Train member Nr 3/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00033: early stopping\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2428 - nll_gaussian: 0.0914\n",
      "build\n",
      "Train member Nr 4/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00031: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.3088 - nll_gaussian: 0.0884\n",
      "build\n",
      "Train member Nr 5/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00031: early stopping\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -0.0212 - nll_gaussian: -0.2394\n",
      "Loss: 0.03594514057040214\n",
      "Computation time: 28.8s\n",
      "New best hyperparameters\n",
      "Mean loss: 0.03594514057040214\n",
      "{'layers': 1, 'neurons': 16, 'dropout': 0.3900760449051849, 'noise_in': 0.2736948772438786, 'noise_mu': 0.43051664764286446, 'noise_sigma': 0.1041295895250522, 'noise_alpha': 0.0, 'l1_hidden': 0.18014899428173145, 'l2_hidden': 0.19623411326511792, 'l1_mu': 0.06612070173678346, 'l2_mu': 0.19112867636457226, 'l1_sigma': 0.0680219230077463, 'l2_sigma': 0.010607405983033181, 'l1_alpha': 0.0, 'l2_alpha': 0.0, 'batch_size': 100, 'n_segments': 5, 'n_members_segment': 1, 'lr': 0.006164947981878827, 'patience': 30, 'epochs': 500, 'verbose': 0, 'pdf': 'normal', 'activation': 'relu', 'name': 'dem_de08nosc_mu28v4', 'n_members': 5}\n",
      "Test period: 1972-01-01 till 1981-12-01\n",
      "--------------------------------------\n",
      "Search iteration Nr 1/1\n",
      "build\n",
      "Train member Nr 1/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00094: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4743 - nll_gaussian: 0.2987\n",
      "build\n",
      "Train member Nr 2/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00031: early stopping\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2091 - nll_gaussian: 0.0092\n",
      "build\n",
      "Train member Nr 3/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00031: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -0.1183 - nll_gaussian: -0.2007\n",
      "build\n",
      "Train member Nr 4/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00090: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0417 - nll_gaussian: -0.0951\n",
      "build\n",
      "Train member Nr 5/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00068: early stopping\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.1027 - nll_gaussian: -0.3922\n",
      "Loss: -0.07603007163852453\n",
      "Computation time: 35.6s\n",
      "New best hyperparameters\n",
      "Mean loss: -0.07603007163852453\n",
      "{'layers': 1, 'neurons': 16, 'dropout': 0.3326887263130893, 'noise_in': 0.43588981311971675, 'noise_mu': 0.39786983040819524, 'noise_sigma': 0.18385437074716876, 'noise_alpha': 0.0, 'l1_hidden': 0.12158382469859082, 'l2_hidden': 0.05506610223237023, 'l1_mu': 0.018893266228072372, 'l2_mu': 0.06710256473131422, 'l1_sigma': 0.042929687676775456, 'l2_sigma': 0.08405168929538576, 'l1_alpha': 0.0, 'l2_alpha': 0.0, 'batch_size': 100, 'n_segments': 5, 'n_members_segment': 1, 'lr': 0.009384986763240505, 'patience': 30, 'epochs': 500, 'verbose': 0, 'pdf': 'normal', 'activation': 'relu', 'name': 'dem_de08nosc_mu28v4', 'n_members': 5}\n",
      "Test period: 1982-01-01 till 1991-12-01\n",
      "--------------------------------------\n",
      "Search iteration Nr 1/1\n",
      "build\n",
      "Train member Nr 1/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00067: early stopping\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.5289 - nll_gaussian: 0.3129\n",
      "build\n",
      "Train member Nr 2/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00031: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.3645 - nll_gaussian: 0.0090\n",
      "build\n",
      "Train member Nr 3/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00031: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0275 - nll_gaussian: -0.2035\n",
      "build\n",
      "Train member Nr 4/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00031: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0905 - nll_gaussian: 0.2002\n",
      "build\n",
      "Train member Nr 5/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00031: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2461 - nll_gaussian: -0.0636\n",
      "Loss: 0.05098547581583261\n",
      "Computation time: 25.7s\n",
      "New best hyperparameters\n",
      "Mean loss: 0.05098547581583261\n",
      "{'layers': 1, 'neurons': 16, 'dropout': 0.28414968778363625, 'noise_in': 0.37035774525150333, 'noise_mu': 0.412885035986286, 'noise_sigma': 0.10369162727598571, 'noise_alpha': 0.0, 'l1_hidden': 0.19434770196432394, 'l2_hidden': 0.13979724986472924, 'l1_mu': 0.09999472162117956, 'l2_mu': 0.021902080043833427, 'l1_sigma': 0.0314504481321954, 'l2_sigma': 0.12381958507928648, 'l1_alpha': 0.0, 'l2_alpha': 0.0, 'batch_size': 100, 'n_segments': 5, 'n_members_segment': 1, 'lr': 0.004272047979610174, 'patience': 30, 'epochs': 500, 'verbose': 0, 'pdf': 'normal', 'activation': 'relu', 'name': 'dem_de08nosc_mu28v4', 'n_members': 5}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##################################################################\n",
      "Lead time: 15 month\n",
      "##################################################################\n",
      "\n",
      "Test period: 1953-01-01 till 1961-12-01\n",
      "--------------------------------------\n",
      "Search iteration Nr 1/1\n",
      "build\n",
      "Train member Nr 1/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00037: early stopping\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2161 - nll_gaussian: -0.0161\n",
      "build\n",
      "Train member Nr 2/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00031: early stopping\n",
      "3/3 [==============================] - 0s 4ms/step - loss: -0.0468 - nll_gaussian: -0.2999\n",
      "build\n",
      "Train member Nr 3/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00114: early stopping\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6215 - nll_gaussian: -0.0097\n",
      "build\n",
      "Train member Nr 4/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00109: early stopping\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.9366 - nll_gaussian: 0.0066\n",
      "build\n",
      "Train member Nr 5/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00084: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.5015 - nll_gaussian: -0.3331\n",
      "Loss: -0.1304607198573649\n",
      "Computation time: 44.3s\n",
      "New best hyperparameters\n",
      "Mean loss: -0.1304607198573649\n",
      "{'layers': 1, 'neurons': 16, 'dropout': 0.4939319184091723, 'noise_in': 0.24942720365509655, 'noise_mu': 0.4968707542214149, 'noise_sigma': 0.37909125861509874, 'noise_alpha': 0.0, 'l1_hidden': 0.15493735735183656, 'l2_hidden': 0.09429260217229914, 'l1_mu': 0.06501006235514262, 'l2_mu': 0.051231631288583324, 'l1_sigma': 0.11184270245129815, 'l2_sigma': 0.040798532703598414, 'l1_alpha': 0.0, 'l2_alpha': 0.0, 'batch_size': 100, 'n_segments': 5, 'n_members_segment': 1, 'lr': 0.006735195845714845, 'patience': 30, 'epochs': 500, 'verbose': 0, 'pdf': 'normal', 'activation': 'relu', 'name': 'dem_de08nosc_mu28v4', 'n_members': 5}\n",
      "Test period: 1962-01-01 till 1971-12-01\n",
      "--------------------------------------\n",
      "Search iteration Nr 1/1\n",
      "build\n",
      "Train member Nr 1/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00063: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.3535 - nll_gaussian: 0.2403\n",
      "build\n",
      "Train member Nr 2/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00031: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.3114 - nll_gaussian: -0.0533\n",
      "build\n",
      "Train member Nr 3/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00068: early stopping\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.7414 - nll_gaussian: -0.0164\n",
      "build\n",
      "Train member Nr 4/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00053: early stopping\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.8542 - nll_gaussian: 0.0427\n",
      "build\n",
      "Train member Nr 5/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00074: early stopping\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.3601 - nll_gaussian: -0.2750\n",
      "Loss: -0.012361559644341468\n",
      "Computation time: 37.0s\n",
      "New best hyperparameters\n",
      "Mean loss: -0.012361559644341468\n",
      "{'layers': 1, 'neurons': 16, 'dropout': 0.18031505080188015, 'noise_in': 0.31037689293093096, 'noise_mu': 0.3038265269335425, 'noise_sigma': 0.3578956636163405, 'noise_alpha': 0.0, 'l1_hidden': 0.12044839055177624, 'l2_hidden': 0.12592365073875098, 'l1_mu': 0.1619994979264514, 'l2_mu': 0.009632997244411091, 'l1_sigma': 0.10923704860953587, 'l2_sigma': 0.0850274464138733, 'l1_alpha': 0.0, 'l2_alpha': 0.0, 'batch_size': 100, 'n_segments': 5, 'n_members_segment': 1, 'lr': 0.006712792088203309, 'patience': 30, 'epochs': 500, 'verbose': 0, 'pdf': 'normal', 'activation': 'relu', 'name': 'dem_de08nosc_mu28v4', 'n_members': 5}\n",
      "Test period: 1972-01-01 till 1981-12-01\n",
      "--------------------------------------\n",
      "Search iteration Nr 1/1\n",
      "build\n",
      "Train member Nr 1/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00044: early stopping\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.0196 - nll_gaussian: 0.3088\n",
      "build\n",
      "Train member Nr 2/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00033: early stopping\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.5790 - nll_gaussian: -0.0044\n",
      "build\n",
      "Train member Nr 3/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00062: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2501 - nll_gaussian: -0.2112\n",
      "build\n",
      "Train member Nr 4/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00104: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.5652 - nll_gaussian: 0.0044\n",
      "build\n",
      "Train member Nr 5/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00189: early stopping\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.0656 - nll_gaussian: -0.4945\n",
      "Loss: -0.07938187718391418\n",
      "Computation time: 52.7s\n",
      "New best hyperparameters\n",
      "Mean loss: -0.07938187718391418\n",
      "{'layers': 1, 'neurons': 16, 'dropout': 0.4615417946377146, 'noise_in': 0.48889167723829263, 'noise_mu': 0.466663101718231, 'noise_sigma': 0.3320027254172769, 'noise_alpha': 0.0, 'l1_hidden': 0.1967520266786775, 'l2_hidden': 0.061523870902077255, 'l1_mu': 0.0522196386947343, 'l2_mu': 0.0052481774322912685, 'l1_sigma': 0.1820023886634019, 'l2_sigma': 0.11300961868457529, 'l1_alpha': 0.0, 'l2_alpha': 0.0, 'batch_size': 100, 'n_segments': 5, 'n_members_segment': 1, 'lr': 0.004668741633905509, 'patience': 30, 'epochs': 500, 'verbose': 0, 'pdf': 'normal', 'activation': 'relu', 'name': 'dem_de08nosc_mu28v4', 'n_members': 5}\n",
      "Test period: 1982-01-01 till 1991-12-01\n",
      "--------------------------------------\n",
      "Search iteration Nr 1/1\n",
      "build\n",
      "Train member Nr 1/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00109: early stopping\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 1.2715 - nll_gaussian: 0.1680\n",
      "build\n",
      "Train member Nr 2/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00148: early stopping\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9907 - nll_gaussian: -0.1819\n",
      "build\n",
      "Train member Nr 3/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00031: early stopping\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0690 - nll_gaussian: -0.1966\n",
      "build\n",
      "Train member Nr 4/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00061: early stopping\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.4768 - nll_gaussian: 0.1331\n",
      "build\n",
      "Train member Nr 5/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00044: early stopping\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4804 - nll_gaussian: -0.0543\n",
      "Loss: -0.026327840238809585\n",
      "Computation time: 42.5s\n",
      "New best hyperparameters\n",
      "Mean loss: -0.026327840238809585\n",
      "{'layers': 1, 'neurons': 16, 'dropout': 0.3315163238827964, 'noise_in': 0.35677069312033216, 'noise_mu': 0.46411423850677314, 'noise_sigma': 0.38503617807775325, 'noise_alpha': 0.0, 'l1_hidden': 0.08829175701861797, 'l2_hidden': 0.15298140917568648, 'l1_mu': 0.16634598882062723, 'l2_mu': 0.04790531606913184, 'l1_sigma': 0.13481708247744964, 'l2_sigma': 0.17258364938281165, 'l1_alpha': 0.0, 'l2_alpha': 0.0, 'batch_size': 100, 'n_segments': 5, 'n_members_segment': 1, 'lr': 0.0075166709755434, 'patience': 30, 'epochs': 500, 'verbose': 0, 'pdf': 'normal', 'activation': 'relu', 'name': 'dem_de08nosc_mu28v4', 'n_members': 5}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##################################################################\n",
      "Lead time: 18 month\n",
      "##################################################################\n",
      "\n",
      "Test period: 1953-01-01 till 1961-12-01\n",
      "--------------------------------------\n",
      "Search iteration Nr 1/1\n",
      "build\n",
      "Train member Nr 1/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00039: early stopping\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2055 - nll_gaussian: -0.1220\n",
      "build\n",
      "Train member Nr 2/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00068: early stopping\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.3432 - nll_gaussian: -0.3999\n",
      "build\n",
      "Train member Nr 3/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00085: early stopping\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.9449 - nll_gaussian: -0.0861\n",
      "build\n",
      "Train member Nr 4/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00044: early stopping\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6516 - nll_gaussian: 0.0671\n",
      "build\n",
      "Train member Nr 5/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00031: early stopping\n",
      "3/3 [==============================] - 0s 5ms/step - loss: -0.0302 - nll_gaussian: -0.2231\n",
      "Loss: -0.15278844088315963\n",
      "Computation time: 30.7s\n",
      "New best hyperparameters\n",
      "Mean loss: -0.15278844088315963\n",
      "{'layers': 1, 'neurons': 16, 'dropout': 0.3570869819567478, 'noise_in': 0.1733786386559859, 'noise_mu': 0.24620611730079045, 'noise_sigma': 0.45346331172395404, 'noise_alpha': 0.0, 'l1_hidden': 0.0707571097376964, 'l2_hidden': 0.014793814952897045, 'l1_mu': 0.1947369775702232, 'l2_mu': 0.03000052739937218, 'l1_sigma': 0.09043645583281033, 'l2_sigma': 0.004583980743617211, 'l1_alpha': 0.0, 'l2_alpha': 0.0, 'batch_size': 100, 'n_segments': 5, 'n_members_segment': 1, 'lr': 0.009936045636328385, 'patience': 30, 'epochs': 500, 'verbose': 0, 'pdf': 'normal', 'activation': 'relu', 'name': 'dem_de08nosc_mu28v4', 'n_members': 5}\n",
      "Test period: 1962-01-01 till 1971-12-01\n",
      "--------------------------------------\n",
      "Search iteration Nr 1/1\n",
      "build\n",
      "Train member Nr 1/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00040: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.8145 - nll_gaussian: 0.3191\n",
      "build\n",
      "Train member Nr 2/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00031: early stopping\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.3625 - nll_gaussian: -0.0547\n",
      "build\n",
      "Train member Nr 3/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00039: early stopping\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.6686 - nll_gaussian: 0.0834\n",
      "build\n",
      "Train member Nr 4/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00095: early stopping\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.8513 - nll_gaussian: 0.0384\n",
      "build\n",
      "Train member Nr 5/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00062: early stopping\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.6139 - nll_gaussian: -0.2406\n",
      "Loss: 0.029121169447898866\n",
      "Computation time: 33.4s\n",
      "New best hyperparameters\n",
      "Mean loss: 0.029121169447898866\n",
      "{'layers': 1, 'neurons': 16, 'dropout': 0.30464729814288827, 'noise_in': 0.3006772346418378, 'noise_mu': 0.1122624132186218, 'noise_sigma': 0.3157761778172559, 'noise_alpha': 0.0, 'l1_hidden': 0.16673671126613843, 'l2_hidden': 0.09016402733414662, 'l1_mu': 0.174024027716215, 'l2_mu': 0.13678639836963657, 'l1_sigma': 0.07527497834013736, 'l2_sigma': 0.05667305512522043, 'l1_alpha': 0.0, 'l2_alpha': 0.0, 'batch_size': 100, 'n_segments': 5, 'n_members_segment': 1, 'lr': 0.007603928685018325, 'patience': 30, 'epochs': 500, 'verbose': 0, 'pdf': 'normal', 'activation': 'relu', 'name': 'dem_de08nosc_mu28v4', 'n_members': 5}\n",
      "Test period: 1972-01-01 till 1981-12-01\n",
      "--------------------------------------\n",
      "Search iteration Nr 1/1\n",
      "build\n",
      "Train member Nr 1/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00033: early stopping\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.8105 - nll_gaussian: 0.3140\n",
      "build\n",
      "Train member Nr 2/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00052: early stopping\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.7385 - nll_gaussian: -0.0224\n",
      "build\n",
      "Train member Nr 3/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00040: early stopping\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2112 - nll_gaussian: -0.2294\n",
      "build\n",
      "Train member Nr 4/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00121: early stopping\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1.0661 - nll_gaussian: -0.0507\n",
      "build\n",
      "Train member Nr 5/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00058: early stopping\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2323 - nll_gaussian: -0.2645\n",
      "Loss: -0.05060186274349689\n",
      "Computation time: 41.9s\n",
      "New best hyperparameters\n",
      "Mean loss: -0.05060186274349689\n",
      "{'layers': 1, 'neurons': 16, 'dropout': 0.1893429954952357, 'noise_in': 0.2696119391643908, 'noise_mu': 0.3235008457462182, 'noise_sigma': 0.42384894064931056, 'noise_alpha': 0.0, 'l1_hidden': 0.1553274107899254, 'l2_hidden': 0.1650401672209934, 'l1_mu': 0.16329444883206956, 'l2_mu': 0.08347659572767607, 'l1_sigma': 0.04004157772158606, 'l2_sigma': 0.12737079792127345, 'l1_alpha': 0.0, 'l2_alpha': 0.0, 'batch_size': 100, 'n_segments': 5, 'n_members_segment': 1, 'lr': 0.006011020565455133, 'patience': 30, 'epochs': 500, 'verbose': 0, 'pdf': 'normal', 'activation': 'relu', 'name': 'dem_de08nosc_mu28v4', 'n_members': 5}\n",
      "Test period: 1982-01-01 till 1991-12-01\n",
      "--------------------------------------\n",
      "Search iteration Nr 1/1\n",
      "build\n",
      "Train member Nr 1/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00156: early stopping\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8137 - nll_gaussian: 0.3109\n",
      "build\n",
      "Train member Nr 2/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00061: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.3236 - nll_gaussian: 0.0055\n",
      "build\n",
      "Train member Nr 3/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00031: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0580 - nll_gaussian: -0.2099\n",
      "build\n",
      "Train member Nr 4/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00075: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0866 - nll_gaussian: 0.2086\n",
      "build\n",
      "Train member Nr 5/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00050: early stopping\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2736 - nll_gaussian: -0.0700\n",
      "Loss: 0.0490454857237637\n",
      "Computation time: 55.9s\n",
      "New best hyperparameters\n",
      "Mean loss: 0.0490454857237637\n",
      "{'layers': 1, 'neurons': 16, 'dropout': 0.23181907197330243, 'noise_in': 0.18832702929046585, 'noise_mu': 0.2367847621102387, 'noise_sigma': 0.2636305020931111, 'noise_alpha': 0.0, 'l1_hidden': 0.06673004066263398, 'l2_hidden': 0.1985160242142665, 'l1_mu': 0.19809502351788555, 'l2_mu': 0.12068160997204286, 'l1_sigma': 0.18559473209311705, 'l2_sigma': 0.04333417138222373, 'l1_alpha': 0.0, 'l2_alpha': 0.0, 'batch_size': 100, 'n_segments': 5, 'n_members_segment': 1, 'lr': 0.0004270285310650193, 'patience': 30, 'epochs': 500, 'verbose': 0, 'pdf': 'normal', 'activation': 'relu', 'name': 'dem_de08nosc_mu28v4', 'n_members': 5}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##################################################################\n",
      "Lead time: 21 month\n",
      "##################################################################\n",
      "\n",
      "Test period: 1953-01-01 till 1961-12-01\n",
      "--------------------------------------\n",
      "Search iteration Nr 1/1\n",
      "build\n",
      "Train member Nr 1/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00056: early stopping\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2215 - nll_gaussian: -0.0439\n",
      "build\n",
      "Train member Nr 2/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00270: early stopping\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.2024 - nll_gaussian: -0.3345\n",
      "build\n",
      "Train member Nr 3/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00052: early stopping\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5084 - nll_gaussian: 0.0743\n",
      "build\n",
      "Train member Nr 4/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00037: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4611 - nll_gaussian: 0.1212\n",
      "build\n",
      "Train member Nr 5/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00041: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.1276 - nll_gaussian: -0.2469\n",
      "Loss: -0.08596378117799759\n",
      "Computation time: 64.9s\n",
      "New best hyperparameters\n",
      "Mean loss: -0.08596378117799759\n",
      "{'layers': 1, 'neurons': 16, 'dropout': 0.17886067763568314, 'noise_in': 0.14466988517658425, 'noise_mu': 0.49412834796941596, 'noise_sigma': 0.4383521415236221, 'noise_alpha': 0.0, 'l1_hidden': 0.13604483837468148, 'l2_hidden': 0.08003562037168217, 'l1_mu': 0.11998215766148956, 'l2_mu': 0.128528138829997, 'l1_sigma': 0.1753808231313667, 'l2_sigma': 0.1175064922666621, 'l1_alpha': 0.0, 'l2_alpha': 0.0, 'batch_size': 100, 'n_segments': 5, 'n_members_segment': 1, 'lr': 0.0020385355915327054, 'patience': 30, 'epochs': 500, 'verbose': 0, 'pdf': 'normal', 'activation': 'relu', 'name': 'dem_de08nosc_mu28v4', 'n_members': 5}\n",
      "Test period: 1962-01-01 till 1971-12-01\n",
      "--------------------------------------\n",
      "Search iteration Nr 1/1\n",
      "build\n",
      "Train member Nr 1/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00074: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.5464 - nll_gaussian: 0.3088\n",
      "build\n",
      "Train member Nr 2/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00031: early stopping\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2670 - nll_gaussian: -0.0599\n",
      "build\n",
      "Train member Nr 3/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00036: early stopping\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.2700 - nll_gaussian: 0.0963\n",
      "build\n",
      "Train member Nr 4/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00037: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2504 - nll_gaussian: 0.0851\n",
      "build\n",
      "Train member Nr 5/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00031: early stopping\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.0248 - nll_gaussian: -0.2484\n",
      "Loss: 0.03638908639550209\n",
      "Computation time: 29.5s\n",
      "New best hyperparameters\n",
      "Mean loss: 0.03638908639550209\n",
      "{'layers': 1, 'neurons': 16, 'dropout': 0.28006504986832115, 'noise_in': 0.20799808862123223, 'noise_mu': 0.47622214365824067, 'noise_sigma': 0.20079497786336253, 'noise_alpha': 0.0, 'l1_hidden': 0.12825658807289175, 'l2_hidden': 0.1738348673805564, 'l1_mu': 0.04949837721366848, 'l2_mu': 0.0828671723121292, 'l1_sigma': 0.105892635895241, 'l2_sigma': 0.07886248389152613, 'l1_alpha': 0.0, 'l2_alpha': 0.0, 'batch_size': 100, 'n_segments': 5, 'n_members_segment': 1, 'lr': 0.0011239331056571336, 'patience': 30, 'epochs': 500, 'verbose': 0, 'pdf': 'normal', 'activation': 'relu', 'name': 'dem_de08nosc_mu28v4', 'n_members': 5}\n",
      "Test period: 1972-01-01 till 1981-12-01\n",
      "--------------------------------------\n",
      "Search iteration Nr 1/1\n",
      "build\n",
      "Train member Nr 1/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00031: early stopping\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7234 - nll_gaussian: 0.3284\n",
      "build\n",
      "Train member Nr 2/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00031: early stopping\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2951 - nll_gaussian: 0.0069\n",
      "build\n",
      "Train member Nr 3/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00031: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -0.0464 - nll_gaussian: -0.2033\n",
      "build\n",
      "Train member Nr 4/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00032: early stopping\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.1857 - nll_gaussian: 0.0553\n",
      "build\n",
      "Train member Nr 5/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00031: early stopping\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -0.0360 - nll_gaussian: -0.2424\n",
      "Loss: -0.011013041716068983\n",
      "Computation time: 22.5s\n",
      "New best hyperparameters\n",
      "Mean loss: -0.011013041716068983\n",
      "{'layers': 1, 'neurons': 16, 'dropout': 0.18234433082365245, 'noise_in': 0.38300992458473104, 'noise_mu': 0.13254877442963023, 'noise_sigma': 0.10501991312424193, 'noise_alpha': 0.0, 'l1_hidden': 0.13895471495722805, 'l2_hidden': 0.13194710413464217, 'l1_mu': 0.020141597714870608, 'l2_mu': 0.06903701371844732, 'l1_sigma': 0.09705990188608289, 'l2_sigma': 0.019448231389717765, 'l1_alpha': 0.0, 'l2_alpha': 0.0, 'batch_size': 100, 'n_segments': 5, 'n_members_segment': 1, 'lr': 0.004749794208893706, 'patience': 30, 'epochs': 500, 'verbose': 0, 'pdf': 'normal', 'activation': 'relu', 'name': 'dem_de08nosc_mu28v4', 'n_members': 5}\n",
      "Test period: 1982-01-01 till 1991-12-01\n",
      "--------------------------------------\n",
      "Search iteration Nr 1/1\n",
      "build\n",
      "Train member Nr 1/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00053: early stopping\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.8657 - nll_gaussian: 0.3292\n",
      "build\n",
      "Train member Nr 2/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00045: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.5106 - nll_gaussian: 0.0133\n",
      "build\n",
      "Train member Nr 3/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00068: early stopping\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3567 - nll_gaussian: -0.2153\n",
      "build\n",
      "Train member Nr 4/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00031: early stopping\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0180 - nll_gaussian: 0.2214\n",
      "build\n",
      "Train member Nr 5/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00039: early stopping\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.3921 - nll_gaussian: -0.0935\n",
      "Loss: 0.051034455001354215\n",
      "Computation time: 30.7s\n",
      "New best hyperparameters\n",
      "Mean loss: 0.051034455001354215\n",
      "{'layers': 1, 'neurons': 16, 'dropout': 0.23074993498364754, 'noise_in': 0.11524533757680806, 'noise_mu': 0.3910765331124527, 'noise_sigma': 0.2643529551596975, 'noise_alpha': 0.0, 'l1_hidden': 0.18633839975249245, 'l2_hidden': 0.10635688593933071, 'l1_mu': 0.06799412029616601, 'l2_mu': 0.1478548385681351, 'l1_sigma': 0.09147319157580643, 'l2_sigma': 0.1913486724151094, 'l1_alpha': 0.0, 'l2_alpha': 0.0, 'batch_size': 100, 'n_segments': 5, 'n_members_segment': 1, 'lr': 0.009369936559390798, 'patience': 30, 'epochs': 500, 'verbose': 0, 'pdf': 'normal', 'activation': 'relu', 'name': 'dem_de08nosc_mu28v4', 'n_members': 5}\n"
     ]
    }
   ],
   "source": [
    "cross_training(DEM, train_pipeline, n_iter = 1 , modelname = name, layers=1, neurons=16, dropout=[0.1, 0.5], noise_in=[0.1,0.5], noise_sigma=[0.1,0.5],\n",
    "                     noise_mu=[0.1,0.5], l1_hidden=[0.0, 0.2], l2_hidden=[0., 0.2],\n",
    "                     l1_mu=[0.0, 0.2], l2_mu=[0.0, 0.2], l1_sigma=[0.0, 0.2],\n",
    "                     l2_sigma=[0.0, 0.2], lr=[0.0001,0.01], batch_size=100, epochs = 500, n_segments = 5,\n",
    "                    n_members_segment =1, patience=30, verbose = 0, pdf='normal', activation='relu')\n",
    "# cross_training(DEM, pipeline, n_iter = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decades: [1953, 1962, 1972, 1982, 1992]\n",
      "\n",
      "##################################################################\n",
      "Lead time: 0 months\n",
      "##################################################################\n",
      "\n",
      "Predict: 1953-01-01 till 1961-12-01\n",
      "--------------------------------------\n",
      "Predict: 1962-01-01 till 1971-12-01\n",
      "--------------------------------------\n",
      "Predict: 1972-01-01 till 1981-12-01\n",
      "--------------------------------------\n",
      "Predict: 1982-01-01 till 1991-12-01\n",
      "--------------------------------------\n",
      "\n",
      "##################################################################\n",
      "Lead time: 3 months\n",
      "##################################################################\n",
      "\n",
      "Predict: 1953-01-01 till 1961-12-01\n",
      "--------------------------------------\n",
      "Predict: 1962-01-01 till 1971-12-01\n",
      "--------------------------------------\n",
      "Predict: 1972-01-01 till 1981-12-01\n",
      "--------------------------------------\n",
      "Predict: 1982-01-01 till 1991-12-01\n",
      "--------------------------------------\n",
      "\n",
      "##################################################################\n",
      "Lead time: 6 months\n",
      "##################################################################\n",
      "\n",
      "Predict: 1953-01-01 till 1961-12-01\n",
      "--------------------------------------\n",
      "Predict: 1962-01-01 till 1971-12-01\n",
      "--------------------------------------\n",
      "Predict: 1972-01-01 till 1981-12-01\n",
      "--------------------------------------\n",
      "Predict: 1982-01-01 till 1991-12-01\n",
      "--------------------------------------\n",
      "\n",
      "##################################################################\n",
      "Lead time: 9 months\n",
      "##################################################################\n",
      "\n",
      "Predict: 1953-01-01 till 1961-12-01\n",
      "--------------------------------------\n",
      "Predict: 1962-01-01 till 1971-12-01\n",
      "--------------------------------------\n",
      "Predict: 1972-01-01 till 1981-12-01\n",
      "--------------------------------------\n",
      "Predict: 1982-01-01 till 1991-12-01\n",
      "--------------------------------------\n",
      "\n",
      "##################################################################\n",
      "Lead time: 12 months\n",
      "##################################################################\n",
      "\n",
      "Predict: 1953-01-01 till 1961-12-01\n",
      "--------------------------------------\n",
      "Predict: 1962-01-01 till 1971-12-01\n",
      "--------------------------------------\n",
      "Predict: 1972-01-01 till 1981-12-01\n",
      "--------------------------------------\n",
      "Predict: 1982-01-01 till 1991-12-01\n",
      "--------------------------------------\n",
      "\n",
      "##################################################################\n",
      "Lead time: 15 months\n",
      "##################################################################\n",
      "\n",
      "Predict: 1953-01-01 till 1961-12-01\n",
      "--------------------------------------\n",
      "Predict: 1962-01-01 till 1971-12-01\n",
      "--------------------------------------\n",
      "Predict: 1972-01-01 till 1981-12-01\n",
      "--------------------------------------\n",
      "Predict: 1982-01-01 till 1991-12-01\n",
      "--------------------------------------\n",
      "\n",
      "##################################################################\n",
      "Lead time: 18 months\n",
      "##################################################################\n",
      "\n",
      "Predict: 1953-01-01 till 1961-12-01\n",
      "--------------------------------------\n",
      "Predict: 1962-01-01 till 1971-12-01\n",
      "--------------------------------------\n",
      "Predict: 1972-01-01 till 1981-12-01\n",
      "--------------------------------------\n",
      "Predict: 1982-01-01 till 1991-12-01\n",
      "--------------------------------------\n",
      "\n",
      "##################################################################\n",
      "Lead time: 21 months\n",
      "##################################################################\n",
      "\n",
      "Predict: 1953-01-01 till 1961-12-01\n",
      "--------------------------------------\n",
      "Predict: 1962-01-01 till 1971-12-01\n",
      "--------------------------------------\n",
      "Predict: 1972-01-01 till 1981-12-01\n",
      "--------------------------------------\n",
      "Predict: 1982-01-01 till 1991-12-01\n",
      "--------------------------------------\n",
      "decades: [1953, 1962, 1972, 1982, 1992]\n",
      "\n",
      "##################################################################\n",
      "Lead time: 0 months\n",
      "##################################################################\n",
      "\n",
      "Predict: 1953-01-01 till 1961-12-01\n",
      "--------------------------------------\n",
      "Predict: 1962-01-01 till 1971-12-01\n",
      "--------------------------------------\n",
      "Predict: 1972-01-01 till 1981-12-01\n",
      "--------------------------------------\n",
      "Predict: 1982-01-01 till 1991-12-01\n",
      "--------------------------------------\n",
      "\n",
      "##################################################################\n",
      "Lead time: 3 months\n",
      "##################################################################\n",
      "\n",
      "Predict: 1953-01-01 till 1961-12-01\n",
      "--------------------------------------\n",
      "Predict: 1962-01-01 till 1971-12-01\n",
      "--------------------------------------\n",
      "Predict: 1972-01-01 till 1981-12-01\n",
      "--------------------------------------\n",
      "Predict: 1982-01-01 till 1991-12-01\n",
      "--------------------------------------\n",
      "\n",
      "##################################################################\n",
      "Lead time: 6 months\n",
      "##################################################################\n",
      "\n",
      "Predict: 1953-01-01 till 1961-12-01\n",
      "--------------------------------------\n",
      "Predict: 1962-01-01 till 1971-12-01\n",
      "--------------------------------------\n",
      "Predict: 1972-01-01 till 1981-12-01\n",
      "--------------------------------------\n",
      "Predict: 1982-01-01 till 1991-12-01\n",
      "--------------------------------------\n",
      "\n",
      "##################################################################\n",
      "Lead time: 9 months\n",
      "##################################################################\n",
      "\n",
      "Predict: 1953-01-01 till 1961-12-01\n",
      "--------------------------------------\n",
      "Predict: 1962-01-01 till 1971-12-01\n",
      "--------------------------------------\n",
      "Predict: 1972-01-01 till 1981-12-01\n",
      "--------------------------------------\n",
      "Predict: 1982-01-01 till 1991-12-01\n",
      "--------------------------------------\n",
      "\n",
      "##################################################################\n",
      "Lead time: 12 months\n",
      "##################################################################\n",
      "\n",
      "Predict: 1953-01-01 till 1961-12-01\n",
      "--------------------------------------\n",
      "Predict: 1962-01-01 till 1971-12-01\n",
      "--------------------------------------\n",
      "Predict: 1972-01-01 till 1981-12-01\n",
      "--------------------------------------\n",
      "Predict: 1982-01-01 till 1991-12-01\n",
      "--------------------------------------\n",
      "\n",
      "##################################################################\n",
      "Lead time: 15 months\n",
      "##################################################################\n",
      "\n",
      "Predict: 1953-01-01 till 1961-12-01\n",
      "--------------------------------------\n",
      "Predict: 1962-01-01 till 1971-12-01\n",
      "--------------------------------------\n",
      "Predict: 1972-01-01 till 1981-12-01\n",
      "--------------------------------------\n",
      "Predict: 1982-01-01 till 1991-12-01\n",
      "--------------------------------------\n",
      "\n",
      "##################################################################\n",
      "Lead time: 18 months\n",
      "##################################################################\n",
      "\n",
      "Predict: 1953-01-01 till 1961-12-01\n",
      "--------------------------------------\n",
      "Predict: 1962-01-01 till 1971-12-01\n",
      "--------------------------------------\n",
      "Predict: 1972-01-01 till 1981-12-01\n",
      "--------------------------------------\n",
      "Predict: 1982-01-01 till 1991-12-01\n",
      "--------------------------------------\n",
      "\n",
      "##################################################################\n",
      "Lead time: 21 months\n",
      "##################################################################\n",
      "\n",
      "Predict: 1953-01-01 till 1961-12-01\n",
      "--------------------------------------\n",
      "Predict: 1962-01-01 till 1971-12-01\n",
      "--------------------------------------\n",
      "Predict: 1972-01-01 till 1981-12-01\n",
      "--------------------------------------\n",
      "Predict: 1982-01-01 till 1991-12-01\n",
      "--------------------------------------\n"
     ]
    }
   ],
   "source": [
    "cross_hindcast_dem(DEM, test_pipeline, name) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = train_version + '_' + test_version\n",
    "r, p  = evaluation_decadal_correlation_ZC(name, variable_name='mean', ZC_version=test_version)\n",
    "rref, pref = evaluation_decadal_correlation_ZC('dem_mu28v4_mu28v4', variable_name='mean', ZC_version=test_version)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The array r and p contain correlation and p values for each decade for lead times [0,3,6,9,12,15,18,21] as defined in lead_times. index [1,1] is the 3 month lead time prediction for the second decade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVoAAAEACAYAAADyRL7nAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAABDxUlEQVR4nO2dd7gkVdGH39/mnCNL2CWHFZaooCJKxoABERQVETFjwOynop9+gqKCCUVQjCgCIkZEMigIIhnJadmFZQm7bIBN9f1Rp5m+szN3Zu7M3Am33ufp585093SfObfn19V16lTJzAiCIAiax6BWNyAIgqDbCaENgiBoMiG0QRAETSaENgiCoMmE0AZBEDSZENogCIImE0IbNBxJR0q6qo7P/0XS2xvZpgrn20vS/DLbXirpztz7ByTtk14fL+kX/dXOoHMJoe1SJL1Z0vWSlklamMTrJa1uVzGlxMrMDjSzn7aqTXnM7Eoz26rV7Qg6mxDaLkTSR4GTgf8DpgMbA98HDu7DsYZUsy4IgvKE0HYZksYDXwLeb2bnmdlyM1ttZn8ws4+nfYZLOlnSgrScLGl42raXpPmSPinpUeAnyeo8R9IvJC0FjpQ0XtIZyVp+RNKXJQ0u06ZTJD0saamkf0t6aVp/APAZ4E3J8r4prb9M0tHp9SBJ/yPpQUmLJP0sfUckzZZkkt4u6SFJiyV9tpe+OUjS7ZKeSW3+WJn9jk37bdibWyEIqiWEtvvYHRgB/K6XfT4LvAiYB+wA7Ab8T277DGASsAlwTFp3MHAOMAH4JfBTYA2wObAjsB9wdJnzXZfONQn4FfBbSSPM7K+41f0bMxtjZjuU+OyRaXk5sCkwBvhu0T4vAbYC9gY+L2mbMu04A3i3mY0F5gKXFO8g6XPpfC8zsxDYoCGE0HYfk4HFZraml33eAnzJzBaZ2ePAF4G35ravA75gZs+Z2cq07p9mdr6ZrQPGAQcCH04W8yLgW8BhpU5mZr8wsyfMbI2ZfQMYjgtjNbwF+KaZ3Wdmy4BPA4cVuS++aGYrzewm4Cb85lGK1cC2ksaZ2VNmdkNumyR9E9gfeHnqlyBoCCG03ccTwJQKftQNgAdz7x9M6zIeN7Nniz7zcO71JsBQYKGkpyU9DfwQmFbqZJKOk3SHpCVp3/HAlGq+TJm2DsF9zxmP5l6vwK3eUrwBOAh4UNLlknbPbZuAW+9fNbMlVbYtCKoihLb7+CfwLPDaXvZZgItlxsZpXUaplG75dQ8DzwFTzGxCWsaZ2XbFH0r+2E8ChwITzWwCsARQL+eq1NY1wGMVPrf+FzC7zswOxm8I5wNn5zY/BbwK90m/uNZjB0FvhNB2Gcka+zzwPUmvlTRK0lBJB0r6WtrtLOB/JE2VNCXtX3U8qJktBP4GfEPSuDRgtZmkl5XYfSwujI8DQyR9Hnc9ZDwGzJZU7lo8C/iIpDmSxlDw6fbmGlkPScMkvUXSeDNbDSwF1hZ9r8twV8XvJL2wluMHQW+E0HYhZvZN4KP4ANfjuAX6AdyKA/gycD1wM3ALcENaVwtvA4YBt+PW4DnAzBL7XQj8BbgLf+x/lp5uiN+mv09IuoH1+THwc+AK4P70+Q/W2NaMtwIPpMiJ9wBHFO9gZhcB7wAukLRzH88TBD1QJP4OgiBoLmHRBkEQNJmmCa2kjSRdmkabb5P0obT+jen9Okm7NOv8QRAExUj6cZr4cmuZ7ZL0bUn3SLpZ0k6NOG8zLdo1wHFmtg0eHP9+SdsCtwKvx31uQRAE/cmZwAG9bD8Q2CItxwCnNuKkTRNaM1uYBYSb2TPAHcAsM7vDzO7s/dNBEASNx8yuAJ7sZZeDgZ+Zcw0wQVKpQd6a6JfkIJJm49M0r63hM8eQpn8OhZ1HAMvxKUsz8ZihbmF1qxswwFiLz+oYj09RW4nPchiLh1EYHuT7DB4DNhT/H41Or5cDo9JnVwHL0rGeTuuy2RKL8bnQY3LHDGC+z1ycWuvnJL1/Mnx3RJnty4AlPj07PxHlNDM7rYbTzKJnVMz8tG5hTY0toulCm2Ifz8Wnay6t9nOpc05Lx7Cp+IT27YFd8UnzncqjlXcJmsxn8Pi0rfEpbRsCr8xtX0fPx73jgdfh09R+g5s9G+F+sIvTttOAvYBt02e+gydomEtBaJ8GTseFenTRMqrE6xF0n0B/rOdMv1qY8hpgvVkxiSuB38P1ZtbX8D8o3d11h2Y1VWglDcVF9pdmdl5fj7MZ8KOGtar/CWFtP96Iz4QYiluxhwIP4QMLc3DraAUwFQ82Ho2L7FRcJTIRvhmfqrYxbrlOpTCXWbijLz+3eRgu0E8Ai9I5sie1UgxifRHOvy8l2N0ozv3IfPxflLEhPWdN9ommCa0k4dmS7kgB9H2mZO69NiVEtTOYh8/DfRIXx4n4FLVngNm4+H0fF8JpuPWbPeu+BJ/5MQufhZGlLNsJuA3PaHMNBWHOMwX4SNE6S+dZls6fX5bl/i6menEuJ8SlrOZMnCPWE4ALgA9I+jXwQmBJmglZF820aF+Mz8S5RdKNad1ncDfWd/Br8E+SbjSz/ZvYjqYSwtqZCBfKWbl1W+dezwT+N70udiPsD1yGW6VvwE0egFcApwDH4eL1bspntyluSyZ40yvsm2G4b7mUIOeF+om0PISL89pSB0ttqMVqHgWMpPPEWdJZuIdnSsoz/AX8wQYz+wHwZzzx0D34Pe0djThv04TWzK6i/BNMb7lS25oQ1oFHsZiMoHR80BBcZNfgGXdGN7FNmTCOojZxfpbSgpxft5jaxLlaq3k0Ls6txMwOr7DdgPc3+rxRkqQCIaxBrQyhPX9YwoVuJGXyWZbA8JtGKUEufv0U7uBcjt9sSlFuIKvbacfroaWEsAZBAeEW/AjW9zeXIxPnUoI8GfdjDzQGvNCGsAZBY8mLc7XZ3budASe0IaxB0LlMome4XJ7x/dmQGul6oQ1hDYKg1XSd0IawBkHQbnS80IawBkHQ7nRUvPGjJZYgCIJakHSApDtTztlPldg+XtIfJN2UcmfXPWmhI4R2NSGqQRDUj6TBwPfwvLPbAoenPNl53g/cbmY74LPIviFpWD3n7QihDYIgaBC7AfeY2X1mtgr4NZ6MLY8BY1O+ljF4Soyaqi4XE0IbBMFAoly+2TzfBbbBs3bdAnzIzMrl8KmKjh8MC4Jg4DARmFFm2zj/s5ekfD7a4sTf1eSb3R+4Ec8TtBlwkaQra8mnXUwIbRAE3cRlZtbb4FU1+WbfAZyQEszcI+l+PLnbv/raqHAdBEHQdGbklhZzHbCFpDlpgOswPAdtnoeAvQEkTQe2Au6r56Rh0QZB0BDaQEQrYmZrJH0AuBCvKfBjM7tN0nvS9h/gqYjPlHQL7mr4pJktrue8zayw8GPgVcAiM5ub1s0DfoDnm1gDvM/M+myOB0HQv3SCmFbCzP6MJ/jOr/tB7vUCYL9GnrOZroMzWT8/8teAL5rZPODz6X0QBG3EjF6WoG80s8LCFanMeI/VPD84yHgaUPQsCILaCdHsX/rbR/th4EJJJ+HW9B79fP4gGDCEmLYP/S207wU+YmbnSjoUr5K7T6kdJR0DHAORPLgW1uHVXB/G41geBu7Hazcdj5e7DgYGpaatd7r49paPdlyZ9e1Afwvt24EPpde/BU4vt2MKMj4NYFOpOKB4wGN4Ab1iQX2MwlxB4RfmZLws9gXAIf3e0qCdKJczpNMFuN3pb6FdALwMr9b8CuDufj5/R7KEgpg+jAf0PYZXNM0Yh/9YXkxh4GIaXtsd4JfA74HdWX++YRD0lrQpRLh+mhneVap++ruAUyQNwXXimGadvxNZQUFQ5+OF5R/Fq4pmjMIv/J3oORo8qsKxXwP8FzgVDxIsVwc+CIoJK7h+mhl1UK5++s7NOmensAp4hJ6P/Q8CT+f2GYZfyNvRU1DH0jeRHAu8EjgHuAJ/rAiCeuhUAZZ0AHAKPmHhdDM7ocQ+ewEnA0OBxWZW108mZoY1kTX4xZi3Uu/HfauZ03kwMB3YlJ6COoHGBznvBlwP/BzYkfYePAg6l3Z2Q+Ty0e6L/ySvk3SBmd2e22cC8H3gADN7SNK0es8bQtsA1gGPs76gLgLWpn2ER0/MxEVuRno9GRfb/mAQ8AbgW8CvgPf003mDIKMNEvg/n48WQFKWj/b23D5vBs4zs4cAzGxRvScNoa0Bwx/vs0Gp+fjA1KN4FYiMLJXb1vQcmBraj20tx0zccX4JsCeeYj4IBhCl8tG+sGifLYGhki7DvW6nmNnP6jlpCG0ZltHTh3ovLqgrc/uMxUX0RRQEdTqeyKGd2QdPtvlD4CTa4wYQBNUwmfJxtOP9TyPy0Q7Bx5L2BkYC/5R0jZnd1Zc2Zwcc0DyLi2mxoOYz/I7ARXQHevpRx/RrSxvHMOD1eBDzH9LrIOgSGpGPdj4+ALYcWC7pCvznH0JbidXAQno+9j+AFwPKGIpbpFvSU1DH033hUFsD84Df4bG1M1vamiDoN57PR4sH/xyG+2Tz/B74bgpDHYa7Fr5Vz0m7TmjLTUFdnLaBDwpNBTbGPeOZoE5iYGVCz8fWfpHuu5kEQTHV5KM1szsk/RW4GZeN083s1nrO26vQStqpimOsNrNb6mlEX6hlCuoM4AUUBHUqXXiH6QPjgIOA84CrgJe2tjlB0C9Uykeb3n8d+HqjzllJby7HTe3ejJ05wOxGNagUa4Hb6H0K6nhcRDen9BTUoDQvAv4N/Ax3JYxtaWuCoDupJLTXmdkrettB0iUNbE9JHgK+kl4XT0GdiftVK01BDUozCE808y3gLGJOdBA0g16FtpLIVrtPvUwADqW+KahBeWbiMbWX4e6DbVramiDoPqpyVUp6MXCjmS2XdARuUJ5iZg82tXWJMXgkQNA89gVuohBbGz7soB0ZOXEiY0eUjlQfsXw5LF1aclurqXaQ/VRghaQdgE/gOVDqmikRtBfD8XjaRcAfW9yWIOg2qjVc1piZSToYt2TPkPT2ZjYs6H+2waOyz6Mw2y0I+ooBT+HBqtmkoNEtbVHrqFZon5H0aeAIYM+UASdmbnYhBwN34o8wxxP+8KAyWQ6Q+bklC7XMT1kfjSdUGohUK7RvwmdPvNPMHpW0MQ2MMQvah3HAgfiMsX/gFRuCAHoKamalZqGWeUHNIoPm4RFBWQ6QLHTwqn5pbXtRldCa2aPAN3PvH6KCj1bSj4FXAYvMbG5adzxeZeHxtNtnUvBw0EbsjsfW/hR3JXRqToegbxiF8kl5QS1OqjQKF9AsB0gmqmNo7yehahJ/p/12Ba4B3mRm59RzzmqjDl4PnIjPAVBazMx6yx19JvBd1hfkb5nZSbU3Negvstjak/HY2ne1tDVBszA8eVL+kT+zUFfk9htJQVCLLdR2FtRSVJP4O7ffifhU3bqp1nXwNeDVZnZHtQc2syskze5Tq4KWswEeU3spnrJok7RuVvo7g3DSdzqfomdi1jzD8Vwgs3HrahSexW5k7m+niWyimsTfAB8EzgV2bcRJqxXax2oR2Qp8QNLb8Koqx5nZU6V2knQMaaLSxAadOKiN/fELZD5wB+6zzcjySGyMC29+iWm8ncE+eAa75bgFuwR3DWTL3fRepnoIPYU3+9vb67rLJ22+OcwoEw9z331w222V8tFWTPwtaRbwOrxSd/OFNrkMAK6X9BvgfOC5bLuZnVfj+bIirJb+fgM4qtSOqXNOA9hIKk7MG/QDw/CBsYxVuHN9UW55FLiFQiIf8NHlabg1lLeCpzCwsqO1O/v2ss3w//cKCkK8HBfg7H3xtqfxcK5n07q1xQfFkzs1mUr5aKtJ/H0y8EkzWys1xm6vZNG+Ovd6BbBf7r3hIZdVY2aPZa8l/YiIje8ohuGiOato/Tr8B7aoaPkXPUulD8Ezp2VuiGyZSST/aTeE/0+G0/cnymKhXoHfhPs91V9Pqkn8vQvw6ySyU4CDJK0xs/P7etJKuQ7eAT4F18yuzm9L03JrQtJMM1uY3r4OqCvHY9AeDMJLjExm/TwJy1lfgO8GrqVgRgjPZ1HKDTGOjvUFDniGpWVCi9tRRMXE32Y2J3st6Uzgj/WILFTvo/0Ont+g0rrnkXQWXgdwiqT5wBfwej7z8N/YA8C7a2tu0GmMxvNozilavxpPxl4swrfTs9DlSHq6IbJlGv1XPTjoHqpJ/N2M81by0e4O7AFMlfTR3KZxVLjOzezwEqvPqLmFQVcyFHcZFJfQWYcPyhQL8A14cuSMwfgzXbEbYgPavzhm0FqqSfydW39kI85ZyaIdhscfD6HnYPJSPNQyCBrKINwnOBHYqmjbStYX4Pvx8JV1uf3G4xbvHHoOxk0g3BBBa6jko70cuFzSmf2VEjEIyjESt2A3KVq/Bi9rVCzCl5MLkcEHdqalz2fiuwEefB9pIZvPQE5SVO31NVzSabir7PnP9EfS7yCoxBBcLKcXrc9mPhUL8C30nG+fDeblB+Nm4W6NgZptqlE0XFw33RS2LJOdetUquO22Rp+xIVQrtL8FfgCcTunwuCBoO4S7EcYDWxRte5b1Y4LnAzfS8wIfS2Ewbg7wMmIQrhID2XItRy35aE9takuCoB8ZgQdTblS0fi3wJOtbwf8ALk7bqhmcsLRkPuFu9w1XK673N7UV7Uu1QvsHSe/Ds+flZ4Y92ZRWBUGLGIxPqpgKbJdbb3gA5twqj5NlXupmKonrUvwGdRXwadwNs7LXT3Qv1QptVk3h47l1Bmza2OYEQXsiPBsJ+DSiDXrZ9wnc+n0CD0HbiEJylmZMQV5Hz6iLQU06D1QW12X4IOQVeEjeWtx3vpqC/3sgUm0+2uJ48yAY0JQT2+twkdkCH1x7BK9YsQ6fvbMnPV0K9fIccBFuOT6RzjMS2BZ4LY3xl1Y6xpOpHTNxv/c30uuj8Dn7c2kv675SPlpJbwE+md4uA95rZjfVc85q89EOBd6LXyfglal/aGary34oCLqcUmJ7K16x+dVF6xcCP8d/2Y2sWnEankXtODxyAjzHwLX46PX7cTdIrVQS18eBK/Gbyi3A3sBn8O92AX6jaSdxzagyH+39wMvM7ClJB+Ld/ML1j1Y91boOTsUn83w/vX9rWnd0PScPgk6nWGyH4FOLV+GzfTJm4jld84/4jeAxvHrx5Ny6IXgu4QtTO6qlWuv3f/E8xeAukfcBB1DohzLBV+1CxXy0ZpbPCHoNnnimLqoV2l3NbIfc+0sk1WVKB0G3kBfbQ4HfAyfhM9E2xAVsEf5oP7vB594E+DueOHU6bjGvxF0YQ+l9OnI1wroAt1r/A/xfOv62wPa4W2CzGttbt492881hl11Kb1u4EDyfSl35aIt4J/CXPrU1R7VCu1bSZmZ2L4CkTYl42iB4nkxshwMH4b7Z+/Ff9N34gNixND6J/dHA33A3wWLcYh6F+0XfR09LF6oT18dxv+/lFBJ/b4UL9wy89EAt9PMAWCPy0fqO0stxoX1JvY2qVmg/Dlwq6T68oZsAvX2ZIBhwZGKbJc3eFE/PXyx2jUR4JYz9e9mn1gGxh/GZSdsCn8At11qfnds4uqCafLRI2h7vhgPN7Il6T1pt1MHFkrbAb2wC/mtmz1X4WBAMKJ7BBzEW4T+UVXgehlH4s2mzYiEfwWe0LcJFfiw+OLU1fQvzOgDYmfUzq1WikriuxaswtJiK+WglbYwXNXirmd3ViJNWW8qmmM0k9aWUTRB0Lbfhic6PwKf9rsVjg27FS0K/Aa8k20guwgemdsLFXHiaye/gEy6Oprq0kcUiWa3IVhLXNXjo2fnAH/BS9q2kyny0n8cfRL6fqiysMbMyjuHqqGTRnoPfLG9M7/P+jV5L2Uj6MfAqYJGZzU3rvo5HvqwC7gXeYWZP96HdQdB2LMETNY+iEKAPsDn+w7mVxgvtJXiJ6uIQrtfizsWllBfavj7eV/rcajz06/e4uC7GY3tfOWIEbx45kvOfKlmPtd+olI/WzI6mwRFVlYT2DcCb8EHG3wNnmdk9VR77TOC7wM9y6y4CPp3uKifiM/M+WeKzQdBxvAj4DR50uSUe37oRPkB2H40T2bzPdTTwYDpXhnDL2lg/AU6zxHUVHlz/e7wQ4FN4IutXjRjBISNGcMDw4YweNHBLc1bKR/s74HeSRuOxZt+QNBn4bMpV29tnr5A0u2jd33JvryGShwddxHg8wPwO3Ip7AHcnPI6X9q5n6LrcgNZHgBNxK3oD3Cf7FP64eDQe5dAscc34PvBVChb9a0aO5JARI9hv+HBGNqiKbKdTbdTBs3g/LsVnFjaiWshRuAFQEknHAMdA40NigqBZjMT9pUvwH80E1q+XVi3VRAtshlvQD+Czz9bgv5dtcGu2P0b/11AoNz8KmDJoEDMGDYqSQjkqDYa9HDgcn03xd+AUM7u+3pNK+iz+v/lluX1SkPFpABtJJePcgqBdMOAh4K/4Y/Qg/EezHI8CmFLDsWoJx3o8HX82pSdD5OOWahXdaj97LO4PvhAf1Pn+8uWcvHw5s4HDR4/m8JEjmTtkCGqEddvbhIWb2ncOVSWL9mLgZjzT2XDgbZLelm00s2NrPaGkt+ODZHubWQho0BUsAP6E+8KG4oNUt6fXd+KRCMOrOE6tMa9H4VOd9sYTkUyhfGLyZoruaHwq8Otxa/6PuOh+bflyvrp8OVsDbx4zhsNGjqzxzN1BJaE9ijKzJvpCyprzSTxhw4pGHTcIWs1i/JF9Xno/GA/VOQz3j50DvKWXz/c1y9ZGuIhfj2d92hR4OS66Y3v5XCNEt9znxuPf9S24xf17/Pt/ftkyLlq2rMazdQeVBsPO7OuBJZ2FZ4abImk+8AU8ymA4cFF6jLjGzN7T13MEQbswDbdg78KTyVyOCw74ANHCMp+rN43hOjyaYQ/8Ef5a/DH0dNxPezw9k9uUoq+iW83npuKDckfjswOeSm0daFTy0R5vZsf3ZR8zO7zE7mfU1LogaHOyKbcbACtw620oniYwy1SymNITABqRK3YQPYPbX5iW1fhEhloDqhYAN+HivDfV586tRnRnpaXVVJGPVmn7Qfi/9Ugzu6Gec1ZyHRwtaWkv24U/HR1fTyOCoBPJBCUTopfiyVxW4MI6CB8Y2x+PKc1oZPHC/SltsQ7FcxT0hXV4HPAC4Ie4j/l16XjVRADV45ZoNlXmoz0Qv1dm98tTqTMfbaUb3o9wV0+5ZUzaJwi6inXAo/hsrmJ6K8kykYLVtg4XwYl42NMMGl8h9mCqj9Gslh0pDKhNwy3yL+BxwG/HIyuqZUFuaROez0drZquALB9tnoOBn5lzDTBBUq2pH3pQyUf7xXoOHgSdwgo8POvBtDyEx8EOBr6MW4i1WGd5C+YiWpPq7o+4aVZPefTX4dN578UjKS5Jx90e74/LcVOvmpjZfhLbRuSjLbXPLMq72ivS6JthELQ96/DKBA/mlkVpm/DH/hfjz42bp/eV/JTPpWPekfadiM/smYtHAjR7ftQ6Cv7URlfgFd4Pm+ODWlkl26uBd+OTNPbFHZp7UHnwrR6eYDILytzylvjwYyPy0Vads7ZaQmiDrmc561urWY7PUXhy5b1wYd0UF45aWAD8Fo8f3QEfiMos5FXp2M1iHZ5g/Br8ER8878EeeLB6oxmEx8yC30hOwq3cS/FaYeNwX2Kjk+c0kGry0VaVs7YWQmiDriLzrT5AQVwfT9sG4dbpSymMdEynfuvvH7i4fQjPSTsZn6t+M/ArXHibFdJ0Fl5q5uX447zhgnsibpW/jeZZ04Px6cY74d/9ejyxzGgKEzgexy3dHZrYjhqpmI8Wv2d8INUTeyGwxMz67DaA6qvgbomPvE03s7kp+/hrzOzL9Zw8COplGQVBfQB3rGUFCUfjya/3xh97N6UxSTqKyUp85we7JuFTYh/By8E0S2j/TOl57IfiExmOoD4fbbUMxXPN5vPNPgKci6fvm4HnR22GlV0LVeaj/TN+f7gHfzip28VerUX7I7yczQ9TY26W9Ct8nCAI+oW1FKzVzAWQPS4Pwgdn9sJFdQt8xLw/rKi3Al/Ba2ntgAfpj0ztfRAfTGoWI/GBqo3pGVO7CFeRViYmPAY3Fa/G3QtnAHUFozaIKvLRGl6pvWFUK7SjzOxfRUkh1pTbOQgawTMUBPUB3FpdnbaNxa3VfXFRnUN1uQQaTWbBnoRXir0PeBL3Cy/ARXa3Jp7/WOBLuAtkKi60j+NOxmNp/eP6GAo1zZ7GXSpHtrA9raJaoV0saTPSyJukQ6gj1CEIilmLX1APUBDXrCLeIDy25hUUfKtTaK2IlIqH3RH3k2bloZs5+p6xPfBT3Kp9HHdjTMEnHLQbE9IyEKlWaN+PpyzcWlJWSfmIprUq6HqW0jO8aj4Fa3Ucbq3uT8Fa7Q/RqoZKEw4G0z8+0WI2S0vQnlRbBfc+YJ9UaWGQmT3T3GYF3cQa/DE6L6xZ1ajBeOzMPhSs1Um0/pE3T6NncwV95557YNKk0tseeqh/21IL1UYdTMAjRWYDQzJfbV/y0QbdzxLWt1Yzh/4EvBR3Jqqz8RHrdiFEtTk82uoGtJhqXQd/xmOib8HdQEEAuIA+Qk9hfTptG4Jbq/tTiAQoY4y0jBDWxjDQhbQS1QrtCDP7aFNbEnQET7O+tZoN/kzEfat5a7WdZsSEqPaNENH6qfZ38HNJ78LzSWSzFzGzJ/tyUkkfAt6Fu+J+ZGYn9+U4QXNZjVurD1CYFLAkbRuCz1HM8sltTvsV0QxhrY4QUkfSJLwgxmz8sj/UzJ4q2mcjCnMw1uFJa06pdOxqhXYV8HXgsxSSKxg+2aYmJM3FRXa3dNy/SvqTmd1d67GCxmH4AFU+bnUBBWt1ErAdBWt1Y8Ja7RTaRUjXUZi116Z8CrjYzE6Q9Kn0/pNF+6wBjjOzGySNBf4t6aKifLbrUe1v5aPA5ma2uOKeldkGL2GzAkDS5Xg2tq814NhBjfwXd74/hIdcgQ9ObYTPQcyEdXzJT7eOENYC7SKkGWvwG/Wd+M16Pn4Tfwp4QeuaVQ0HU8gB9FM8dUMPoU05Dxam189IugMP826I0N6Gz/ltBLcCX5E0Gc+4dhCej6IHko7BZ/G13SNpN3ELPZNbT8VzA8zFs1q1Iia0Nwa6wLabqILn7b0Xv2nfjItsfgbfRHxQNLumbmxucyrlo+2N6VnyGDNbKGlabztLmo3PU7m20oGrFdq1wI2SLqWnj7bm8C4zu0PSiXg+5GV4iaL1pvOmzjkNYCMpypI3iTfiwnpfbvl12jYcd1btiA9ybUrr3QXFQtPtwtuOwvoMbq3eiQvrI7hbIMvluxs+yWQOjX8Suv9+GFZm9sojjwAV8tFK+julL5vP1tIOSWPwnDkfNrPeyn0B1f9uzk9LQzCzM0iFGiX9H/50EbSISWnZJb1fQkF076UgvENxi2Qe7v/ZjNbP2Oo24W1HYV2MW6t34k8/j6X1g3Ff/V64qM6m9ly+/Y2Z7VNum6THJM1M1uxMCvngi/cbiovsL83svGrOW+3MsJ9Ws1+1SJpmZoskbQy8np7Z1YIWMx63YndM75/B51xn4nsuPniW/dB2wIV3C5qThrAWOk14201Y1+F+1f+m5XYKcdEjcDHdCRfWjWivySYN4AK8LNoJ6e/vi3dIFXLPAO4ws29We+BK5cbPNrNDJd1CiVIOZrZ9tScq4tzko10NvL84hCJoL8biyUuyf/YKegrvBfjjziDcF7c9Lrxb4RUMWkk7CW+7iSoUBq4yi/UOCoMxY3FB3Sv9zSr7djEnAGdLeic+PvxGAEkb4GXJD8Lzqb8VuEXSjelzn0mpF8tSyaL9Vvrb0Hy9ZvbSRh4v6F9G4aFe26X3z+JhYffiwvsXPOBaeI7Y7XEf71Z4wphW0p/C247C+iyeiPxOfHDkIQoDV1PwAavZuD9+Mu2Vc6LZmNkT+JBF8foF+KA9ZnYVfeiWSkL7PWAnM3uw1gMHA4cRuIhuld6vwn/AmfBehIsveN7UTHi3ofVp8xopvO0orEspDFzdQs+Bqw3wOi3ZwFWrb4LdTCWhHUg3tKBBDKNQNRX88fRhCoNrl+PiCx5ONhcX3a1xq6qV1CK87SasWb2wzL96G4XRnCG4P/3luLW6Ca33pw8kKgntLEnfLrcxsncF1TCEgtW0Nx4r+AgF4f0nXkUVPOYyL7yNKJ5YD+0mpnnW4f2Y+VdvozBFOhu42oXCwFWrQ/MGMpX6fiXw7/5oSDBwyKIVstCgdfhUm2xw7QbgyrTvOFx4M1fDBgzcx6w1eP/cScFqXZm2jcMt1eyGNoPuHLi6+254pkw27E7OR/tEo0O7gqCYrFTNLLwUuOGxmpnw3oqX9AavbLsdBeHdiO4UFHARvYfCjKv8wNVUfDrrHFxg2y1ZetCTSkLb5jkggm5EFEp374EL7xMUBtfuBv6V9h2JC27maphN+00brpYl9By4WkBh4GoW8CJcVGfjoVdB59Cr0JrZi/qrIUFQDuGDZFPwUXLwSrP3UxDfrIx1Nm14Hi68m9GevknDB6oyYb0VL64IhYGrV+AWawxcdT7teA0GQUWyacM7p/dL6Cm8v0nrh+KiNQ+3ejenNdOG1+HzzPMzrrIJ8iPxm0OWI2BD4ofZCqrJR5vbdzCeDOsRM6s4zyD+n0FXMB4X03np/TJ6zl47j57ThrPZa1vSHGtxNYWBq5vwX202cDUet7Rn466A6XSvn7nDqCYfbcaH8Il0VYUfV5qC22uJp75WWAiCZjMGHyzK8p+upCC89wJ/wCeyZwNx+WnDo/twvhUUZlxlA1dZSrpp6fhZVMBEYuCqTamYjxZA0obAK4Gv4Lm6K1LJov03bggINwSeSq8n4NfSnGpOEgStZiSwbVrAc30+QMHi/SvwJwqp/rLZa1tT2mRZQiF+NRu4MgrCvQeFUKsxTfg+QVn6Ix/tycAnqGFMstJg2BwAST8ALsgSJ0g6ECibbiwI2p3h9Jw2vBrP15AJ78W4+II/2r8A950+gA9cZaVGMh/wPhQGroY3vfUDl3vugfllkqouXw40OR+tpFcBi8zs35L2quYzUL2Pdlcze0/2xsz+Iul/qz1JELQ7Q1l/2vB8CoNrV+JW8ChcUF+U/s4iBjo6iQbko30x8BpJB+Hu/XGSfmFmR/R23mqvkcWS/gf4Bf6EdAQe2hgEXckQfLBqNoVpw0vxgawYuOpaKuajNbNPA58GSBbtxyqJLFR/zRyOT0b5HZ56dFpaFwQDgsH4IFaIbFdzArCvpLuBfdN7JG0gqdd8s5WotsLCk3g4Q0OQNAE4HZ/GbsBRZvbPRh0/CIKgVqrJR1u0/jI8MqEiVQmtpKn4KNt25MIOzewV1Xy+BKcAfzWzQyQNo/WJ+IMgCJpGtU9Cv8SjWeYAX8QHX6/rywkljQP2JBVnNLNVZvZ0X44VBEHQCVQrtJNT5drVZna5mR2FD7z2hU3xad0/kfQfSadLWi9GXNIxkq6XdP3yPp4oCIKgHag26iDLzrZQ0ivx+OwN6zjnTsAHzexaSafgU90+l98pBRmfBrCRtF5hyCAIBh5PPbWU8gFP7WuSVSu0X5Y0HjgO+A4+WeYjfTznfGC+mV2b3p+DC20QBEFXUm3UwR/TyyV42aE+Y2aPSnpY0lZmdic+ynd7PccMgiBoZ6ry0UraUtLFkm5N77dPExj6ygeBX0q6GU+49H91HCsIgjbG8If6B/HH2YFIta6DHwEfB34IYGY3S/oV8OW+nNTMbsTrxgVB0AUYnppycVqeyL1eDDyb9tuuJa2rjmrz0fZlHkC1QjvKzP4l9UjutqbczkFnshCv+ioKeV2DIMOAZ/CQobyQZq+fy+07CJ9JNwtPPzkDT84zi74P7vQD1eajrXkeQC25DjbD+xpJh+C/y6CNeRZ/ZMtPHV2OT+B+Ag/92D1tewbP0TqCgvWxPTHldKCxDs/pkAlosaiuzu07CK9yMQs37TIxnY7P1+/AZDsV89Hm5gEcCT4PgCpqK1bbF+/HQ622lvQInkP5LVV+NmgC2Q9gEp54opizgUfwH8MewI74P/uv+I/g5Xi4xxQ8VeCVwBZp/SI8qcVGwORmfomgJawDnmZ9qzS7pvKPqoPxa2AW/pSTF9MptGUhzGbno83PA9gBz9n9ITPrNbas2qiD+4B90sSCQWb2jKQP4wlwg37mXlwwh+AX+mtwsc0ytF+Lp/37QPp7Ki6us3HxfSGe3HpnPHH1lnhg9O7p+NPwW/Qi/EeWHTfoHNbiYlrKZ/okPcV0CP5/3hAfOMmEdEZa315PNQvxIuyleByanI+WKucBlPpQ1RSp9kcJoW0JFwIvwx/XzsdLp7wYryIA8BhubWQMwkd7x+FX2Nq0flZavxwvWPhM7jNj8B9k0L6sxUueLC5ansD/d2tz+w7Fr4lN8BttXkwHUlayBuSj7dM8gHrcKGHktIDn8B9GVsl1e1xoH8cz/YM/8t8ObID/uFbgAdDPpc9lPthhuEW8Mh0zP7w6kYLwhkXbOtbgollqJP8p3A2QMRy3QOfgTyfZY/4MvPZU/A8rUk0+2j7NA6hHaGNabAtYg1uu2aPfaPwHlH/U2BG3UP6MC+aE9H4cLqyZoK5L7w0X5TtzxxhEYSg1+4E+iDukRuSWkWXeD2PgWEn1shoX0VI+06fp+UMbgd88t6Cnv3Qm/v8NMa2LE4CzJb0Tr4n4RvB8tMDpZpalSszmAQzDC3CUdVVkVKqC+wylBVUUnlSDfmRIWpal94Pwx8Js2HNdWrcDcGBadwmeem2L9Pde4PX4j/kZfJBjJv6jvoJCHsz9caFekN4/CdyIW8R5S6oUwi2sUmJc7brhdI9Yr6IgpsUj+Uvo+SMbiYtpPiwqs0zHEmLaLKrNR9uXeQCVijNWXeUx6B+G4v7T+cBuuOAtTq83SPusxa2kNfht+cG0nfR3Ae65F4UKm9OB/XCf73L80XNi2rZB7u8rcVF4Dnc5rMgtpd7n1y3BnV7PpiXvQyxFXqxrFelsXX+K9XOs/3ifWadLivYdjYvpXAoimv2NqrndRweGug0sVuNCkYXRDMJ9cLfglukTuGtgWzxEaxxuzV6LJxGehA9+7IIL5HTgMOBhPBJhau5c04F3V9EmURCziRX2LYel71ZJqItfL8HFayXViTX0FOu+WteZWD9L+dlP+cFEcMGcgv8/8lbpdFxog4FDCG2bsQ63Vu8G7sKt0Xfij/3gVuUM3H96Hv7I/yr8H7kJLrTgyYL3yB03P6A1Pi2tRLgfdxh+o+grq6jOss6/z8Q6s6yrmeI4HL/ZrShaPw4fgNqZnmI6jSgbEhQIoW0xhvvs7k7LPRSiAjbA/aSbU3h8h4IPdoeiY21ctE+ebvXrZWJdz40jb1n3JtKrcQt1BgUxHVHieEEzeRQffypF+xbmDqFtAUtwQb0r/c38dxNx3+hcPPnGuJKfDhrNUNrDyg+6lxDafmAlfg/O3AFZFPQoPA42E9bpLWldEDSXUtOwBhohtE1gDZ5jLXMFPIz7XofiE6X3wcV1Y7onfCkIIES1HP0utJJG4OGaw9P5zzGzL/R3OxrJOjxkKvOz3k8hWmAjPCXQXNzXOrRFbQyCRtKNglpDPtqPAEfjQyy3AO8ws2eL98vTCov2OeAVZrZM0lDgKkl/MbNrWtCWPmG42z0/gJWNRk8HXoEL6zbEyHPQ+XSjqJahYj5aSbOAY4FtzWylpLPxiMkzeztwvwutmWXJ2MENvKF0wHTe5bh/NRPX7DY3Ho9RzfysfY0rDYJ2YACJaikq5qNNDAFGSlqN21ILSuyz3gf6HUmD8WnzmwPfy2XCaVu+jVuxI3FRzYR1Jt0bOhXURicl3xngglqOivlozewRSSfhky5XAn8zs79VOnBLhNbM1gLzUu2d30maa2a35veRdAxwDLSHlTgS97d+lRjAGghUEs378UHOGbi1MCjtfyFwVXr/NmCz5jazzzxa9L5zhLe3fLSLoULi73rz0UqaiFu+c/D0IL+VdISZ/aK3z7U06sDMnpZ0GXAAcGvRttPwqg5sJLXctbAJcF2rGxE0lKV4qN1o3Lee3UAzkb0cn9a8BHgdPpV5MHAH8Ef8x/Msnm1kB/zn/yDusFsCXIr7xfITSdqVYuGFThLfHvSa+LsB+Wj3Ae43s8fTZ87DJ2H2KrT9bpxJmposWSSNxBv+3/5uR61sgk/3HKjlkruNBXhp59OBn1G4ANfhInsfnjbylcAXcCsg82/9DXcbfQTPfPYfCsPP49K2PfDrJUs92XJLoQ88WmLpcrJ8tFAmHy3uMniRpFHyarV74/feXmnFU/BM4FJJN+NG4kVm9scWtKMmMquk3ENL0Fn8Bf+fnoD72/+FJ4XJfhB340lhtkl/R+O/sDX4AGg2a28bXJgfwUU6X7xwPIUKpp0otKXocuE9AdhX0t3Avuk9kjaQ9GeANJ50DnADfm8dRHry7o1WRB3cjOem7igm48OL9+DhW0HnsgbPjzApvd8OuBr/32YX5lRcbBfizrgn8bjEJ/EA8Ew4R1GoIjyOnsPP43BXQjfTRS6HWvLRfgF/0KmamBlWJcLdBxWfEYK2Zy3uO81ST45Jr/NpDrfHQ/p+igvpOjyhzOO4XzYTVFFIvD6Jntm9BmoMdTeJb6MIoa2BjXFf3goG7o+oGxiMW7RZ+Z9B+A8hS5e4Fh8FmY0Pgk3C/+9X4REwY/BpQwtwC/de4AXpc+vSttlp+zbpmJ0S9tUsutDNUBMhtDWwCf7ImP2wgs5kMC6Y2dOJcCGYRcFSzeqpZYnRF+D/f/B8FTem5VEKCdDXArsC302vZ+HPoQsopLlcmbZFFYWBRQhtDWyE/yjvIYS2kxGeSP1vuPV5Ez7TbxYeJTAM98veDvwJF9yNgEPS52fgDrtLcN995rMfDGyNi3NWcigjE/B/AWfjyc43w8V74/R3GmH5VmYBBadPMaWisdqDENoaGIn/GCLyoPMRPqz8XTw6YG/8xzAIH+wCF78j8IiDrNpw9tk5eOWLYgbRszxQMRvjIr0Qn/BwA4WBtRF4SM4W6dybABtSKC0fdC4htDWyMW7pdNJ0y4HOfNxy3TS3Trj1uXXRvlvkXmcC20iy6gwZq3D3w4LcchmFqsaD8Jt7Zv1mSySF7yxCaGskmyG2iEjU3c4sBv6Jz+5agD/KH0/BWm0XhuE37/zssXV4Xo28+N6Kh6BljMet6rz45me3Be1FCG2NZD+IuwmhbTeW4j7QS/FcBOAC9Fp8imy7iWw5MvfDVHrWhVuOi+4j6e9C4GZcmMFFu9j1sBGd8727mRDaGpmBX9D3Ai9pcVsCj2m9AbgYH8hahz9qH4BPj53SspY1ntG4iObdG6uBx+hp/V4F/D1tFy7Yxa6HCf3S4s5C0hvxB59tgN3M7Poy+x0AnIKPyp1uZidUOnYIbY1kVRNub3VDBjBr8LmPV+NunNX4o/SewE4MrNSVQ/EBsw1z6wyP782L739xV0rGWDzkbEsK4juTAe96uBV4PfDDcjukFK/fw8dS5wPXSbrAzHqVhBDaPrAJ7vtbRYwI9xfr8MTrV+OCkU0a2RmfNjuHAS8SzyM87GwyPcMQV+Duhrz74c94XC+4aM+gp+thY9qqpLoVHCWlWJf26ePBze4A8FwxZdkNuMfM7kv7/hpPmxhC22g2xi/OB3CLIGgOhidy+QeervBpXAzm4uK6JXEB18Io3IWQz5G7Bh/YzSzfR/Ab2SVpeybaxa6HibTkqeH3u+327BdPPPGo9TasXbuW973vfdx1F1Ml5R/5e+SjbQCz8Mi8jPl4Bs1eieu0D+QzeYXQNp5FuLhejvsfBwFb4fGn2xGDO41kCO5C2CC3zvB8upnVuwC/1vNlUEZT2vXQTEExs5v23HNPbrvtNrbbbrse2y677DLmzZvHnXfe+Q3gG+WO0VvibzMrlRZxvUOUalqlD4XQ9oFx+B09Ji40jiXANXgMaZbxag7uMNuBxsezBuURPlg2Ab+xZTyLux4eyf29kEKOiCF4JE6x66GReUGuvPLKec8999yNJ5544vPr1q5dy9lnn81dd9014ze/+U2vn+8t8XeVzMeHaTI2pF1rhnUDWYKZoO+sAK7Hw7Huxj1sG+DJtufRHiWMggIj8JvfnNy6tXhGs/zA23X4DTNjEgXXw1Z1tqGUVZuzZh+r8/DVcB2whaQ5+L3mMODNlT4UQttHNqEwRz4EoXpW48lY/oFX51yD99/Lcb/rQE+n12kMpjDbbae0zvCY5rz4PoDfVBuRIyRv1dZizVZC0uuA7+ARcX+SdKOZ7S9pAzyM6yAzWyPpA7gxPxj4sZndVunYraqCW3McWruR99Pu2sqGdADr8ExZV+N+vpW4K+CFuLhuwsAJxxoICA+3G08hTSR44vRn8UkW9ZC3ah999NGGWbNm9jvgdyXWFyf+/jMesFE1/S60fY1Dazdm4XeJENrSGD476x94AP1SfBBrLm75bE75HExBdzKcxg1kXnnllfNWrlx549KlSxtizTabVli0fYpDazeG4klKlra6IW3KlcAPcDHdBrdct8X7LQjqJbNqN9100/7yzdaFzPq3bJykQ4ADzOzo9P6twAvN7ANF+x0DHJPezqWoHHlQM1NIhe+DPhN92Bi2MrOx9R4kVaHF+lvE+kArLNqq4tBSkPFpAJKuN7Ndmt2wbib6sH6iDxtD0YSCPtMJApvRilmLfYpDC4Ig6FRaIbTPx6FJGobHoV3QgnYEQRD0C/3uOuhjHFoj5yoPVKIP6yf6sDEMuH7s98GwIAiCgUZklguCIGgyIbRBEARNJoQ2CIKgyQwooZUU2fYagCqkoA8qE33YGDqlHweE0EqaKulU4KeS3iRpZlrfEf+kdkDSNEmnStqgkwLF24now8bQif3Y9UKbMoVdgk+U+DWwN3AodNbMklYiaTu8794FfL7FzelIJM0FziL6sC46tR+7VmglbZ5eLga+ZmZfMbNz8BzTE9I+YdH2gqQdJY3Dy3X9D57DeW9JL2ppwzoISVnCqqW4MEQf9oHcb3UZ8Dk6rB+7TmglbSvpIuDbkial2uznSsq+62JSOtmwaEuT+vBPeG7uKWb2CHCLmS0FzgC+1NIGdgCS5kn6JfBNSfPM7CHghujD2kg3++8AR0kabGYP0IH92FVCm8T0/4C/pmzoTwKY2Qozy+oUz8WLIwRFSBoi6VvAL4GfAX8BXpU2LwdISdqnSnpba1rZ/kh6FfAT3GW1CvhUujafg+jDapH0SuB0vCjH7sAJ6ab1LHRWP3aV0OIi+pyZfQNA0u6Snq8Nl5KOT8XzUSNpX0kTWtHQNmUmnhd4TzP7DT5NenyyJNal/gO3It4PIOkNkqa1prlty2bApWZ2BnAiXlpreOrD7BE4+rAy2wB/S/34MTyl8eGSpuT26Yh+7GihlbSfpKNToTTwAqpzJL02PfoeD5yeu+MNBaYBO0u6BC+yOqBJffguSRub2cNm9iMzeyZtHg1sYmZrk9iuhedLfoyXtBx4C16tZsBS4jq8C9hf0sfxp6dpwPclvTBzV0Ufrk+JflziqzXdzJ7Gs/zNAvbIPtMp/diRQitpuKQf4YMLU4GTJb3ezJbgmcCOBX5gZvvjj78vlfQC3NLYD3gtcLKZvTf9AwccRX04BfiOvDhdfgDnXFwwJiexlaSRSUCGAm8ys9eb2YBMhl3iOjxF0qvN7C/4NbgHcKyZ7Qs8DBwiaWNJQyV9guhDoGQ/flvSfvgT1UTgh5J+lV4vxsUWSWM75lo0s45YSAlw0uuJuA9sUnp/CPAEMBbYB3gMOCxtmwGcDcxO7z/c6u/Spn34Bryo75hsX2A6PuCwR9Fxtm/1d2nTPjwk9eHo9P7srK9wt9bfgIkDvQ+r6Mc34oI6Ji2HAu9K214N/Cn32Y7ox06yaCflXs8BtqDwmHA97gd7j5n9HR8Qe3eyzF6B3yWzR7aT+6vBbUhvffhvfODmWHg+ImNZ2m8wPO/jxszqLWTayVS6DlcBH07v78efngDmpW3Rh05v/Xgd/nv+iJktA841sx+lbS8gV6m2U/qx7dMkStoFD5ZfY2Zb59b/Fo/v/DfwErwg7THANma2RNIX8UoOWwAfMLMBG2lQQx/eDbwH78On0z4/B+41s+P7t9XtRR+uw83xQqTvwSuqrwI+2CnC0Cz6cC1unX7PewA/xP207zOze/u77XXRapO6wuPFcOCr+IX7H9zflW2bgVsLpwJHpnU/AfbK7TO61d+h1Usf+vDHwEtz+4xp9Xdo9dKHPjwT2D29HgHs0Orv0A5LPdcisAHuh2359+jTd291A3r5p2TW9qbp756432ZIej+oaP8JwG+B8a1ue7ss0YfRh+2y1NGPE1rd9kYsbeejzeIMLfW2md2X/l4BXA18L+06KO0/RtIRuF/nAWDlQJ9aG31YP9GHjaEB/biiG/qxLXy08kQRs4CLzWxNie1DzGuNzQTuxOvCL5Q0Eh9cOAb4j5ld2q8NbyMkbYPf/f9ZZnv0YQWiDxtD9OP6tFRoJU0EvoLHG94H3IvHv96b/TNy+8rMTNIn8YkG/wAeMrNvtaLt7YKk8cBJ+MDL48C1wE/M7B5JQ81sdW7f6MMSRB82hujH8rTadfAJfMrsPOCdwHZ4/CaZyEo6UtJBVrgjDAJ2xSv4fqffW9x+fAK/Ye4AvBuYDMwGyC7s6MOKfIzow0YQ12IZ+r3cuKR9ccf3hcDxZvZc2rQfHlu3naRFwGrgX/gUxuPSZw/AY+62NLN7+rvt7YKkNwLTzOx7+CjtOoD0JDABD47/u6TJeGKTW4g+7IGk1wMvM7MP4YlLVkP0Ya1I2glYbmZ3Etdiefpr1A23Vn8NXArsUrRtT9z5/V48NOYkfJbX5kX7qb/a244LPkvmXOAa4HDc+s/cP9no7U+A1+Q+s33RMQZ6H24L/AoPL1oHTM9tiz6svh/nAH8C/om7CF4R/Vh+aarrIBstlDQJuAJ40sxebp4j9nnM7Aoz29XMTgW+hifh2NXSXU4pl6yl/85AomjEdSPgMTN7kZmdBSX7ZBZeTQJJgywFyOdmdQ3YPpS0J/Aj4Boz2xE4GU+/V0z0YQmKrsWPATea2e7A+cDRJT4S/Zhoto92BIB5Xtiv4wHLmZ9mP0mbpvfKhYHcjvt27s8OYoVcsgOREbnX2wMbAkh6H/B5SS+TNMJ8FHdL/GZ2g6T3Ap9Lj29Yyrw1QBmZ/t4O7Gdm35Y0jNy0zyQEayRtRvRhOUbA84K7nORuAcYDd0jaCnx8RdIWRD8+T1OEVp7n9SLg65IOS6tPAXaVtBB4DXAQcL4KJWcGSzpY0sV4UpjF3RA/11dyffg1SYen1TcACyX9GLfElgCfBo5M2zcEdpN0Kd7Hv7YBmp0M1uvDw8xssZktTzemVbi/8C3Q42a+KX6dRh8min7PhyZL9CpgC0n/AQ7Aw7J+IWn/9LFNiGuxQKN9Efgc72uBg4Ed8Wz9n0nbXg28PbfvGcCX0+t98MGv17ban9LqpUwfHocPXn4Dnw8+NO37VuAHadubgSeBfVr9HVq9lOjDX+Suw6zvXpbWT8197vDow1778VfAx9K2rYDzcvt+Dvh2ev2W6MdcPzbonzGINIUudfD3c9uOwpNFTMvvn/6+Ib/vQF4q9OE7Ux9OwAcOLwHenLZtj/vIBvV3m9tt6cN1uA/wB9LgTXaMVn+PVi9V9uN0Ug5ePAkReDKYc6IP11/qdh1Iegfu8P7ftOoWvNzE7PR+KD4R4aTsM+YlPd4OfAHP0TmgqaIPh+A+66+ZT108GTguBXv/Gn+MG9BVfft4Hf4d2IWeGfsH8nhAtf14X9r+DB6SeaykD+HZtS4GbCBfi6WoS2gljcEfKU4EDpS0tfnI4k+Br0q6Gngp7kOcLGmapMmSvg68A3inmZ1fTxs6nRr68G3AhpJmmNkFeAq5p/E+PMnM1lkyKwYafbgOZ6TPDcVv9g+1pOFtRg39+HY8AmYwnvv5dmAn/Fo81RIt+RLtSgMeMzZOf08AfpNeD8bvdC9J7zfC42OHpGWTVpvy7bTU2IcjWt3edlxq6MOf4IUSW97mdlxq6MefAsNa3d5OWep2HZjXqwd/nJ0jaX/z8I0lZnZV2vYeYEXaf42ZPVjvebuJGvtwdYlDDHhq6MOVwHqJiwKnhn5cjldBCKqgoUllJL0bH6R5WXq/G/BZ3K9zlJk92rCTdSnRh/UTfdgYoh8bR8OENgV8r5N0DrAQeA74O3C3dVrZiRYRfVg/0YeNIfqxsTRswkL6p4zCp88ejqc8+2v8U6on+rB+og8bQ/RjY2l09q734bOX9rVCVq6gNqIP6yf6sDFEPzaIRvtoB9kAj0Osl+jD+ok+bAzRj42jLUrZBEEQdDOtrrAQBEHQ9YTQBkEQNJkQ2iAIgiYTQhsEQdBkQmgHMCnBz41peVTSI7n3wxp8rgmpKkS57WvTeW+TdJOkjyqVMGoWkpY18/hBkBFRBwEAko4HlpnZSVXsO8RSOfgajj8b+KOZzS2zfZmZjUmvp+EJpq82sy/Ucp4a2/T8OYOgmYRFG/RA0rskXZesynPT7CAknSnpm6k0yYmSNpN0Tdr3S3nrUNLH0/qbJX0xrT4B2CxZrV/vrQ1mtgg4BviAnMGSvp475rtz5/qEpFtSe0+o8B3mSPpn2va/+XOWaXMQNIQQ2qCY88wrEu8A3IFXd8jYEi9NchyeWf8UM9sVWJDtIGk/vOjhbsA8YGd59dlPAfea2Twz+3ilRpjZffj1OS21YUk6167Au5JoHgi8Fnhhau/XKnyHU4BT03GeT4jSS5uDoCGE0AbFzJV0paSscOF2uW2/tUIF092B36bXv8rts19a/oNP39waF7G+kGXp3w94m6Qb8fpVk9Mx9wF+YmZZCs4nK3yHFwNnpdc/b1Kbg2A9Gp3rIOh8zsQLZN4k6Uhgr9y25VV8XsBXzeyHPVYWSqFUhbwU/VpgUTrmB83swqJ9DgBKDTKcSfnvUGr/km0OgkYRFm1QzFi8pPlQUinuMlyDF9cEOCy3/kLgqFQWBUmz0uDWM+nYFZE0Fa/s+13z0doLgfemNiFpS0mj8XpzR+V8sJMqfIerc23Nry/X5iBoCGHRBsV8Dn88fxAvzFdOHD8M/ELSccCfgCUAZvY3SdsA/5TX51sGHGFm90q6WtKtwF9K+GlHJtfAULwCws+Bb6ZtpwOzgRvkB30ct1j/KmkecL2kVcCfgc/08h0+BPxKXkjw3OzE5dqMW9NBUDcR3hX0iWRFrjQzk3QYcLiZHdzqdgVBOxIWbdBXdga+myzMp4GjWtucIGhfwqINgiBoMjEYFgRB0GRCaIMgCJpMCG0QBEGTCaENgiBoMiG0QRAETeb/ATwz7xoNDvXhAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 360x252 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from os.path import join\n",
    "from ninolearn.private import plotdir\n",
    "plot_seasonal_skill_ZC(lead_times, r,  vmin=-1, vmax=1)\n",
    "# plt.contour(np.arange(1,5),lead_times, p, [0.9, 0.95, 0.99], linestyles=['solid', 'dashed', 'dotted'], colors='k')\n",
    "plt.title('Correlation skill')\n",
    "# plt.tight_layout()\n",
    "plt.savefig(join(plotdir, 'TL_r_skill_' + train_version + '_' + test_version))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we also want to compare the skill of the reference case AI to that of the Distorted physics AI. This can be done by plotting the ACC skill of both DEM instances together as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEWCAYAAAB2X2wCAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAACT/UlEQVR4nOydd3gVRReH303vpAdC6L0mEHrvIL0pCFJURFRULJ8FGygWxA4igiKCIEV6R3pvSWihhhAghfTe773z/TFJSM9NSEhx3+fZJ7m7s7Nn9+49O3vmzG8UIQQqKioqKpUfg/I2QEVFRUWldFAduoqKikoVQXXoKioqKlUE1aGrqKioVBFUh66ioqJSRVAduoqKikoVQXXoKpUCRVECFEXpV8A2X0VRemX8P0dRlL8y/q+rKIpQFMXo8VlatiiK0l1RlBvlbYdKxUR16CpFoijKYUVRohVFMc1n2wRFUc4ripKgKEqIoii7FUXplm17Y0VRNiiKEqEoSqyiKJcURXlTURTD0rJPCNFCCHG4tOqryAghjgkhmpS3HSoVE9WhqxSKoih1ge6AAIbn2vYm8APwBeAC1AYWAyMytjcAzgD3gVZCiGrAk0A7wPqxnEAVoiq9aaiUDapDVymKycBpYAUwJXOloijVgE+BV4QQm4QQiUKIdCHEdiHE/zKKzQVOCiHeFEKEAAghbgghJgghYnIfSFEUR0VRdiiKEqMoSpSiKMcURclzjyqK0lRRlDuKoozP+FxgOKYwFEWppSjKJkVRwhVFiVQUZVHGegNFUT5UFOWuoihhiqKszDjf7GGcZxVFuZ/x5jJDUZT2GW8fMZn1ZJSfqijKCUVRFma8oVxXFKVvtu3PKopyTVGUeEVR/BVFeTHbtl6KogQqivKuoigPgD8y12Ur866iKEEZ+9/IrFtRFFNFUX5QFCU4Y/kh8w0rW71vZZxfiKIozxb3+qlUPFSHrlIUk4HVGctARVFcMtZ3BsyAzYXs2w/4pxjHegsIBJyQLf7ZyDeDLBRFaQvsA14VQqwtRt05yAj57ADuAnWBmkBmfVMzlt5AfcAKWJSrio5AI2Ac8i3lA+T5tgCeUhSlZ66y/oAj8AmwSVEU+4xtYcBQwAZ4Fvg+4xwzqQ7YA3WA6bnOoQkwE2gvhLAGBgIBGZs/ADoBHoA70AH4MFe91TLO+3ngZ0VR7PJeKZXKhOrQVQokIxZeB1gvhPACbgMTMjY7ABFCCE0hVTgAIcU4ZDpQA6iT0do/JnKKDXUHtgFThBA7ilFvfnQAXIH/ZbxdpAghjmdsmwh8J4TwF0IkAO8D43OFPD7L2GcfkAj8LYQIE0IEAceANtnKhgE/ZJzTOuAGMARACLFTCHFbSI4gH1bds+2rAz4RQqQKIZJznYMWMAWaK4piLIQIEELcznYOn2bYFI58W5qUbd/0jO3pQohdQAKgxuYrOapDVymMKcA+IURExuc1PAy7RAKORcR1I5EOWl8WAH7Avozww3u5ts9AhnAOFaPOgqgF3C3ggeSKbLlnchcwQr41ZBKa7f/kfD5bZfsclOvBdDfjGCiK8oSiKKczQkwxwGBkSz6TcCFESn4nIITwA2YBc4AwRVHWKoriWsg5uGb7HJnr3JNy2axSCVEdukq+KIpiDjwF9FQU5UFGDPcNwF1RFHfgFJACjCykmv3AGH2PKYSIF0K8JYSoDwwD3sweb0Y69NqKonxfvLPJl/sZdeX3QApGvplkUhvQkNNpF4eaiqIoueoLzohpbwS+AVyEELbALiB72ULlUIUQa4QQmW9SAphfyDkEl9B+lUqC6tBVCmIk8pW+OTIO6wE0Q4YTJgshYoGPkbHXkYqiWCiKYpzR4vw6o45PgC6KoixQFKU6gKIoDRVF+UtRFNvcB1QUZWjGdgWIyzi+NluReGAQ0ENRlK8e8fzOIsNBXymKYqkoipmiKF0ztv0NvKEoSj1FUayQWTzriggvFYYz8FrG9XkSeR13ASbIkEk4oFEU5QlggL6VKorSRFGUPhkPhhTkm0Hm9fob+FBRFCdFURyR39VfJbRfpZKgOnSVgpgC/CGEuCeEeJC5IDsHJyqKYiSE+A54E9nZFo5s9c4EtgBkxHM7IzsdfRVFiUW2SM8jnXNuGiFb9QnIN4DFufPLM7Jj+gNPKIryWUlPTgihRb4FNATuITtjx2VsXg6sAo4Cd5DO8tWSHguZutkIiAA+B8YKISKFEPHAa8B6IBrZP7GtGPWaAl9l1PsA+eCYnbFtHvI6XwIuA94Z61SqMIo6wYWKStmhKMpUYFpGWERFpUxRW+gqKioqVQTVoauoqKhUEdSQi4qKikoVQW2hq6ioqFQRyk3sx9HRUdStW7dE+yYmJmJpaVm6BpUhlcneymQrVC57K5OtULnsrUy2wqPZ6+XlFSGEcMp3oxCiXBZPT09RUg4dOlTifcuDymRvZbJViMplb2WyVYjKZW9lslWIR7MXOC8K8KtqyEVFRUWlilCkQ1cUZXmGxOaVArYriqL8pCiKX4Z8aNv8yqmoqKiolC36tNBXIIdbF8QTyFFwjZDynr88ulkqKioqKsWlSIcuhDgKRBVSZASwMiO8cxqwVRSlOAp7KioqKiUmOjka31hftDpt0YWrOHrloStyGrIdQoiW+WzbAXwlMrSkFUU5ALwrhDifT9npZIj0u7i4eK5dW7L5Cfz8tDg6mmFrm16i/R83CQkJWFlVDmXSymQrVC57K5OtUPHtTdQk8k/gP2y4v4FEbSLVzaszwnUET1R/gmrG1crbvEJ5lGvbu3dvLyFEu/y2lUbaopLPunyfEkKIpcBSgHbt2olevXqV6IBvvhlNQIAd8+fD88+DQQXv2j18+DAlPdfHTWWyFSqXvQcOVBJbhYDvv+fW3bs0+uADcHYuk8PoNDpS41NJjZNLWnxa1v/Z1+felhyXTPCDYGKiYnBOceattLdQjBVCOoSws9FO/qz7JxNbT+SV9q/Qpkabog15zKSkwOnTZXMvlIZDD0ROFpCJG2Wsu/zaa7dYsaID06fD8uXwyy/g4VGWR/xvEJ4YzsmIk3imemJtqs7hXJp8/z188EE3Fi+GqVPL25oiWLgQ3nqLRgA//wz9+8OECTByJMLSirTEtJzON5cDzr2tIEetSdZPjdjYwhhTG1OMrY2JNYzlXvo9EowScGzhSOsGrXGr4Yafjx8mx0yYdnQa6bXTOdryKN2Od6NN0zbM7DCT0c1GY2JoUqaXTR9SUsDTE7p1q0VZPNtLw6FvA2YqirIWOXdirMiYELisqFs3iUOH4K+/4K235AXatg2GDCnLo1ZdwhLD+ObkN/x87meS0pP44uYXPN3yaV7wfIH2ru3JOTeDSnE5fRreeQfMzATPPgsnTsCiRWBqWt6W5UV74BB33viZq7Vnct+qJqYxyaQeiCN1zwXSuEYqJuT/Up4TQxNDTG1MMbUxxcTaBFMbU6xqWOHQ2AETG/nZ1No0q0z2ctm3mViZkE46v3n/xhfHvyA4Ppi+9fryWe/P6Fyrc9bxjA4b0Xl9Z66su4LPbz4Y7zKm7799CWgZwIctPuTN1m/yYvsXme45nRrW5dfF9/nncPUqTB9xD2hQ6vUX6dAVRfkb6IWcbiwQOWmBMYAQYglSqH8wcuqwJOREt2VGVHIU/wT+g2eaJ5MmWTN0KCxYAL17y+2hofINUfVBRZPdkadoUuh590dMtzak+vCT7I5Yzu9ev9OyekteaPsCz7R+BjtzdQ7hkuDtDXXqwLffnuH8+W54eYGxcXlb9RCdVse9Y/e48ttprq65QLKYgGmsdKrVWrpRzdoEk5QYTO/5Yep3EdPkGEwtDDHp7InpgB6YdmyDaTWzHI7ZyPTR24rp2nSWX1zOZ0c/417sPbrV7sbq0avpVbdXvuVNbUzxfMETzxc8Cb0cis/vPpivMqeuT11SHVM51PIQP3n+xIDOA5jZfiZdanV5PI2V9HQ4dozLK7z4atUsJrOG0bd3IecgL13KTZyrXbt24vz5PP2mRbLiwgqe3fostma2zPCcwasdX8XVWk6VmJwMrVpBw4ayBdSwYWlbXTIqWpw3tyOf0GoCdXa/Reqy/ViRmFVOMVOIqhGFv50/ka6RNO/UnPHDxtOnVZ8K02qvaNe2IJKT4cwZaatWC4aGEBQEXl4wfPjjt0cIQeDpQHzX+eK73peEkASMDTQ0MbhFyx9foMHzPTl+6njea5uWBvv2wZo1sGWLPLHatWVIZuJEaJknb6LYaHVa1lxew9wjc7kdfZsONTvwWe/P6F+/f4H3XUH3gSZFw/Wt1/H5zQf//f4IRRDQKICzHmcx72HOK11e4emWT2NubP7IducgMhJ274bt22HPHrRxCXRVTnLbqCnX5m3kVh1LOo8bV3Q9+aAoSpl2ij5WpnpMJeleEodSD/H1ya/59tS3TGw9kbc6v0Uzh5a8/jp8+KG8r957Ty5mZuVtdcUgLDGMBScWsPj8YlI0KUxsOYE5taey+hMr0ndtp3ENf9LqpeDgn0ZytDN1etYhJLk5zpedSfdOhx1w/MPj7LHfQ7Vm1fDo6kG9dvVwae2CfUN7DAwreO/0Y2bVKnBxgQEDwDybvzA0lH/nzYMlS+B//4MvvgCjMv41CiF4cOEBV9ZewXedL7F3YzE0NaTR4Ea0jDpKoyPLMNm0AUb0LbgSExMYOlQuCQnSqa9ZI1+Tv/pKtqgmToSnn5aOvhjohI4NvhuYc2QO1yOu41Hdg23jtzG08dASNyCMzIxoOa4lLce1JPpONBf+uID1cmvqra9Hyq4U1rVaxxedv2D0oNG83P5l6trWLdFxEAKuXZMOfMcOOHkSdDp5Azz5JD/zGmd+b83qFeA44TmuHD5csuMUQaVz6ADNbZrzcq+XuR11mx9O/8DyC8tZcWEFgxoO4u0hb3NtTB/eflth7lxYvRoOHoRatYqut6qS6cj/OPkz7ndT+CPdncERdlgu2osS/hcWVq+yY0wv7jZsiw6gOzQPvc2YKwcYdusUTsEBJMRoCdl6mCPel/G6HE/SzSTST6XjpfMCwMjcCOeWzri4u+DS2oXq7tVxbuWMuV0pt3wqCZcvw/Tp0KuX7FPMzx/98INcv2CBjLOvWwc1yiC8G34tXDrxtb5E3ozEwMiA+v3r0/vT3jQZ0QSz1cvhlcXw8ccwYoT+FVtZwTPPyCUsDNavl849syXVvbt07mPHgoNDgdUIIdh6YyufHP6ES6GXaO7UnH+e/IdRzUZhoJReI8Gunh29P+1Nz096cnvvbbx/98Z8mzldTnXh/ob7jG47mjoj6/By95fpV79f0Q+R1FQ4elQ68O3b4c4dub5NG/jgAxg2DDw9uRdowOzmMGiQfM6VJZUu5AJ5X68ikyJZcn4JC88uJDQxlDbV2/B2l7exD36K1X8Z8eefMrUxPb18YpflEhYQggifk+z/ex7fphzC2ymdefTh/U/2A6Bt0IiTYW6sce/J3o7tEAYKsV51ifepzfAXw4m1uYtfbCKKTtC5ngvPdHOj75tTMd2/D5o0IaZdS3Y7JvB7zE0iY6rRKKYRLRJaYBZgRkpkSpYZNrVspHNv7Ux19+qyNd+o9FrzFTHkkpgI7dtDdDRcuCAbaVCwratXS+dvbQ179pROxla0fzRX1kknHnopFBSo17seLca3oNnoZlg4WMiCx4/LDqhBg2Dr1hw5wCW+tv7+0rGvXg3Xr8sf3aBB0rkPGwYW8thCCPb47eGjQx/hFeJFI/tGzOk1h3EtxmFoYFisQ5bU1oTQBC6tusTZpWeJvRVLmkkal1teJqJ3BOPHjmdqm6nYmNo83CEsDHbtkk587175lmJmBv36ybeWIUPAzS2ruBBy9ZEj4Osr+1IexV4oPORS6Rx65M1I/hr/F8+sewaHRjmf+imaFFZfWs03p77hesR1atnUYlanWUxrO43kGBs6dIA33oCZM8v+9TY7j83pJCXBN9+QeuII2pMnsUiQjnXzeHdaLFpPY7OacOwYd0Qt3vnoLJc72ZFiZYxDYg0CdzXh5cmWnD4dwt69Nbh8GfzC45nxVSCmjYPAIpVqxgrDDCIZfe0wbfZvRomORte3Dxt+mM4y72VU33KA604KdVsOZ6T5WOpE1iH8Ujihl0KJuB6BTqMD5Guwc0vnHE7epbUL5vZFtOaFkD+oe/fkEhTEWVtbOkyeXNZXtlhMmybTafftg759BV8e/xLvEG9uBN2gS8MutK3Rlm61u9HCuUXWPlevykbtqlVQrYRjYuKC4vBd74vvWl+CzgYBUKtLLVqMb0Hzsc2xrpErFTUoSKaI2djA2bNga5tj8yPft0LIJ9rq1fD33xAcDFZWiFEjOTi0BR/FbeVU0Gnq2tbl4x4fM8l9EkYGJfthPqqtQgjun7jP+WXnubL+CiJFEOocim97X1oPduPlaCea7TgDZ87I83J1lZ562DDo0yfrIZWbtWtlq/yHH+D110vH3irl0G//e5sTI77CVhtDk1cH0PiVfihubjma3jqhY/et3Xxz6hsOBxzGxtSGCbXf4caKNzn0rznu7jJ3vXPnQg5UipS6Q9fpZLzu9Gk4dQrq14fZs3kQG0S1mg24bZXG6ZoCpXNn+k34iDqdBoKBAUIIFn7vxSLfMNKcBA5pVix9vTVuZnbYmMZjbmvNv/8ewSUyhtYD3cGuLufPQ99+AseWEfR9PpCj/g9ISddR39GSMW7GjHI1wrVHR4iPR9jaouh0JJgqnHATXGpkjdmY8Qwd8z61LGoRcS2C0EuhPLj4gLBLYTy4+ICk8KSs07KpaY1LQ2tcXA1wsU7GxSgCh8R7GATee+jEU1NzXIp0a2uMT54slc64kpKcnoxvuC8XH1xk1/5ENr37Gs1GbebqplEANPu5GRqdBgutBfdT7xOdEs2Lni+yZOgStDotL+18idYurWlboy3uLu4Y6iz58EP51m5XRGJRYlgiV/+5iu86X+4euwsCarStQYvxLWjxVAts69jmv2NqqowHXbkinVTz5nmKlOp9q9XC0aMc2/AtH6Xt4UgtLTUTDPiInjw7+lNMOnV9pNS00rQ1JTSWK/O2cHzDVWJDLdAYarje9DqiwTWe8WjNsOFvYNi2XZH2RkZCs2ZQr54MqQt0XAqK5aRfBETdY+bYQvoqCqFKOXSAwD4DcTu0L+uzUBSUevXAz09e5H/+gQcPoHZtfM3i+S7oH1bc24qiGNI14Vuu/zWDsBATXnhBOnbD4r3dFZtHvtmSkx/2qk2dCps3Q1yc/GxnR+L40Xw8ohq/nP8FJSWFsZ6T+LD7hzRyaJRVxb9nY3hj2QUSHBJJj7LA8mYj1n5Xk7auvnD8O7hzFF67wNHjJ+lx9nlIjSfKoT8GnV7guqYfAwYa4OoKO/emcz4shI3eQZy9E4WiQOf6Doxp68YgWw2WZ0+hPXaUhAO7sb51lzcGKSzsCE/Zd2fuKTPqt+mDsZMLxMQg7t4j8WYQobfieBCsIyzRkgdUJwJHdMgvxQgNTpaJuDjpcKlvgUsLJ1w61MGiZX0wMCC1b19MjY3h2DFoUPp5vdkRQhAcH8zF0IsExgUy3XM6AH1X9uXgnYMAWBhZUvPeG4weDV8N/AyANG0aJoYmHD58mJ49exIQEwBAPbt6BMYF0vbXtoQnhQOgoFArcgpBv/xO7VoG/L0unaatkqhm9rDZnhydzPXN17my9gp3DtxB6ASOzRxp+bTs/HNoXHC8OosXX4SlS2HjRhg9Ot8ipekkzwad5aNDH7Hv9j5cLF2YXW0o0/dFYrZ9t3y4NGjwMFOmSZNi1//ItoaEyFDK9u3w77/ybdfCggcdhnNSacXlc2mQoBBtG82dznfoPK0z0wZNw9HCscAqpz4rWLc7gQ8XRnAnMYIT18JIzngGDK1vzKLpA0pkapVz6Ef37KF73Xpc+3Evt387hINJIk0H1cZ+42+ywODBMmUoG2nNmvDOd4P4zfs3Jh9U8L/7A0bWbdj+TQxKnToy7lVGIz2KdbNptbLVlNn6Pn1a3lz37snts2fL4GznzoS3asCXof/wi9cS0rRpTGo9iQ+6f5DDkYfEJvPF1mts8w1Bl2IMJ5yY+WRL3p3gA8e+hZt7wMQa2j9PervX2LbkMAOfbIXRrX+IObiC6pahCNu6XKn/I50n9KJOHTh8GJyc4F5kEpt8AtnkHcS9qCQsjBQGORkw1iiSTuF+GPjdIjDsNsutb3GDSJZvBdMM/aRUQzDFEOrWlfmltWtnLdoaboSnVyM0FEKvRhJ6MZTQS6Ekhj5MqbSuaY1Laxc02lCandiOnZUG+w2/YtuxCYYmj/6ETtWkYmJogqIorL60mt99fudS6CUikyMBMDYwJmF2AiaGJuy+tZu4pBRcRBt6uNcusCOvoPsg80HhHeItlwfe9DWezTdvdORBqI70ATOo1/cAjbWNsLtuh8lRE2oG1KR6req0HN+SFuNa4NzSWf9MkKVLpUN//32ZXlMApeHQLzy4wMeHPmb7ze04mDvwbtd3eaXDK1gYZ4QoYmNh06aH2QtCyDDQxIkwbpwMbehBsW3NDAdlZqWcOyfX16olwyhDh8q+hYwUOU2KBt+Nvvy76F8STyeiU3T4N/LHZpQNz778LO1qS/8aFJPMCb8INh6P4IRfJEZW8o3SIV2Hg28kQwc0ZOL09lw+f0oNuQBw/jzBc+bgmpEOEBZlxKbD9oRGmeDZNIEBHWIwMdTKMbYJCbKHKiFBttybNyfaIJWE3duoFZyAQI5586U5r5ks4cdBe2hpFyTjiYoClpYPFysrmbKVm9zXL5/r+SAigup16sibw8xMPjgy/6any1hmu3byOCtXypsM5Pu2u7vsNX/lFWmDqSkPNDF8ff5HfvFaQro2nWdaP5PDket0sGFzOkuO+hNsdRtNmg7n8+mkedVlwZY29Gl+GZZ0A3M76PQydHiB5GQz1gxZQ+DpQCbsnECjwY34/f3rsP0H+nQ/R5DhswSE12H9EUOsnQz5qftxHMKvw927iHv3OG/kwMZWfdnZtBvxppa4xoUxKuAcY5IDqO9khba2Gwcc4zkcfApx7Rpd7+roGWTEvxvm80T/lzDfsFl2ynXrJpfWrfO8OiWEJhB6KTTLwYdeDCX8Rji6VN3DQgpUq1UNuwZ22NW3w66BHfYN7LP+zy/rJiYlhrNBZ7n44CIXQ+VyPeI6Aa8HUNOmJgvPLGTVpVW4u7jjXt0ddxd3Wru0ztFqfvttWLZM9gFmZqpEJ0dzK+oWNyNvcivyFpf8LjGozSDa1mhLK5dWmBkVnk8bcj+d4UNjOX/JEaeWi0nv+wExdjEA7Oi6g8F9B3Pi/gkO3TlE2xpt8XT1pLpV9ULr5NQp6NlTxn137iz09fRRHLpvmC+fHP6Ejdc2Ymtmy9ud3+a1jq8VLikRHCxTfVavlgn6iiLtnDhRvkUU0rmgl61JSfKhsWOHXIKC5DE6dnwYD2/VqshQSrR/NPsW7sN3pS+aJBPuNDbmbntzUtzqEJWS0QeQYoJBuCNzZ9iTstSL4L8u0/ervnR7t5v+9hZA1XLo27eTOvNZTDEBjbzwGmHAofj2nExojb1hHKPtD1HTNCLnfrm+pFRFxw7XBHa6JnAveADHvVaRrrFhZrXf+TxxNlaamJzO2dJSNktBdswZGMieVSMjGb83Nn7Y05rrWCkJCZiBfMikpOSJA+vLAyv4uiv80g7SDWHSZQM+8LKgYbI5mJmRZFyNP1Kf5DvXoaR1jMTQMo3aV2NxPxKC4mbF2512Udu0pnyQWNwD4yZgZkNcigm/LIkmKVJhz+BdBDe/g7WhjgY3XXHfMomo9Go48wAFA0aO3I27+zUuhtci9YYZV326YmNnhq2bBXYNHDBvXpPrzWqzOTidY7cj0QloU9uWMW3dGNbalWoWxoQmhPLnxT/57fxSbkXfxtbcll/vujNy201MgjJUI6ytpWPftk1eVyHy/aEdOnSIdk3bEf3PQaLf/IxopyZE9xhO1L0Eov2jc7TqtQZa4uvFE9cijojaEYy0Hol7fXeOWB3hzRtvAlDTumaW0361w6tFDhNPSEvgjw2hvPZMAzqOOk+TyQu5FSmdeGZrHsBAMcDMwIwkrewzMDIwoqVzS9pWl444M35uIkzw3+/PlbVXuL7lOinxaZy17MPokToGzqiHZRtLLoZdpEutLpgZmfHV8a94/8D7WcepYVWDtjXasnbsWqxMrEhKT8LcyFy23kNCZOvX3Fy2SO3t8z2nS6svcWvnLcz6mxGxKoIRy0dgW9dWr3v0ZuRN5h6Zy9+X/8bSxJI3Or3Bm53fxNZMv/2zuHHjYabM7dvynh06VIZlBg/OM7ikQAcZFPTQgR84IMOXVlYwcKCsb/DgYomPJadpORcQxQm/CE74ReAbHIcAjNK0VL8Xj1V8IAbp9dl/aDh79xsT9ftmrvx9JYczL9RePahaDh0I+WUUNaLOQPMR4PE01OkGBgYEHA5g8+TNxAfH0/PjnnSf3R0Do8LT44QQ7L29ly/2LuXY70PA53msnaL57od0pg0wkKGOu3fll961q7wheveW60OySda89x58+aV8hezXL0cI4d6ZM9R++23ZCt+zB554Qjbj2rWTre/WrR/GDTMdfjbnH5IQwtcRW1kSf5h0tEwyaMMH2i40TLXMKucd7MITN6di1C0AY4dEXB6k0H7fbdo5+NG5uxdNnP0g2gDWGkFyKgFmKWxqmM6gSw7sS5xEnIE5+4f/jXtqAGmGEGlnSnQ1U/aGDGSY11z23WuA+aTO1DYOZUCNCGYYGNEUQ5LTLPG63IX9u1qi6KTDPfbzMao5VsPtUAtS4ltxqYY5IYYKhgha2cOw7s70b1YTZ0sHTgedZpn3MjZe3UiqNpVhZu7M0rSj2z0wiYyR/SEg86PDwqST795dfhcODjl/GDt2wKhR0K0bkRtXgZk51jprzl46y/Rj0/FL8SMdKblsqDXkyc1P0vRKUxIsEwhzDsM10hVXF1fsG9hjW982q2VvWceSaLto7qTcka3tzFZ31C2CgwQsuQjWwTCtIzXtHWnk0IjG9o3lX4fGNLJvRH27+pw8dpK6HnXxDvHGK8RLLsFeRCVGUTegLq2utKLl9ZaYJJmg2CjUeKIGXad0pWn/phgYGSCEjJT07w9PPvnw1otLjePig4tZ4Rr/aH+OTj2KoihM2jyJ3bd209bFg7aHruN5KRzPnzdTv/PgAn8Tv3X6jdS4VGq9WotrH1zD2NyYZ/Y9g3OLgh3fneg7fHb0M1ZeXImJoQmvdniV/3X9X6ExZr0QQr4xr1kjU0bCwmRLfexY2XLv0QMMDR/eBzqdbN1n5ob7+Mh66taVLfBhw+Q+eoZXNVodFwNlR+Zxvwh87sWQptVhbKjQprYdXRs40q2RA3UNDdj60yauLw/AMtKQVAOFpB5RuN5xpfOMznR/r3uOelWHnoEQgq0TPqBtnavUsjmPkhYP1WpDxxehy0xSYlLY9couLq+5jFsnN0b9NQr7Bvm3RHLjE+LDu39s49+fRqE02s3Tb1zirc5v0bZGAbPqpabKFsC9e9JBN2kiXxufe+7hgyApCZ2xMQaLF8t8tuRkCA+XsboiXu1C4kP4+sTXLMkIrUxylzHyhvZS0+DaNXl456YxfLb9GufuRlHdwpIn7kRT+9BOBo84jItdOGm2zTDp8yY3a7Rk4/WtbLy2Ea8QOSDo95a/kvJhGiN+7EHNJtU4ffIknUaPznHDR0fLSNC0GcnEpEYRmRzJzgORHF56htnNLtNpRDNW27ty1ucUdQLvs7d+EhHJUbQ83pK+fn2JvhPDfUPwa+mAf3N7Ui2M0RKNa3gI45Pq0szVmm2x27hqfJU7lne4Z30PYwNjutbqyvz+82nv2p6Ln7+K6bGT2J+7gn1sOsY6YNIkDj/3HF26d2Hz5PZcNI3monEUF60SCbKBT43689EH+4iMD2PC+41wjzPHPVYuTeJMMHxmCnGjnyXm8j2cZ4wiPSUNbWo6unQtpAvOiI6cpwNWxPEcyxGKDmGgRRgIDAxhZ+fOfBL0G8EBNTln0Z2WxrdRdEI6IZ1OqhY+84xsDffujUanw8jKCiwsEObmhE97n/N3HAlds4/O0XtINzQmwUHLfYdI7tmGs8xT4OdkQF/qM+6BA3bVWvLpujlcvOPG62MC+XqJDSaONjKsGBcnU+fMzeXbYsa9td53Pftu78P77FauGESQbggtnVty+aXLACw5vwRrE2va1mhLY4fGhF8O51ePXxn4/UBSPFJo7ticVQNWoUnRMHHXRNw6ueW4RwPjApl3dB6/+/yOoWLIS+1e4r1u7+Fi5aLXb65YaDSylb1mjYy7JyRAzZowfjxXLSxoHhwsw0gPHsg36C5dHo5qbd5crywaIQQ3QxM44RfBydsRnPaPIiFVIyO2NWzo2tCRLg0c6FDPHguTnCmWGg10aC/QBdxmUKuVGJ3WYZxuTGzNWGpPqM2ktybh4CI7rFWHnoHQCZZPWE7gukAaP1GLMZ+YYnLzH3BuDgM/lz+kS+vwvVKX7TOPoNPoGPTDINo830bvTqPbEff46dTPLL+ymIRrnaifPJ7v59RkWPOBxRuCLARER3Pk/Hl6DtC/RzskPoT5J+bzq9evpGvTmew+mQ+6f0AD+wYIAYcOwbffwt7jSdQZdgOtWzD2libM9HDA8Kv9BJxK5oZDU94ZvwynJ1+kZrcxhCVHUP2b6ggEHWt2ZJTZKMY8MYaGDg0ROoFiIM+rqBvt3j1wdJS+Y8sW2VLs1EmwZ4+CZdA+WPMk2NeH9tPAY4KM0wN3g+8ScD2A0MAIrjornLylxS/QHJ2iYB+RTINLEdS/Gkm6VSQr3lhBTEoMg3YPwizZDBM3E+5b3SfQMpAo+ygSrBOwxpSnrDvxTNs5dO/RHes5JqQrgmZJFriHG+B+K55+Jk3xOOArDR8yBKFAijaNBE0SiemJnGpfgzXtTLgffJ1Plt9GKwRCAZ0CRoZGnGtbn7CmXWkc7sDIHUcwTDVCJENagpb0xHS8acPPvEJjbvKO0XeY2JhhamOGaTUzTGzNSR8+BouhfalGDEa/Lub+3bvYY0HM9Qck+odxNLkdoWb16NxJ0CXgL0yNtCgpKYjkZERSIqd/fp999XSYbd7Oez95A5CGMe/wNT8yC7favkz98TgTb/nT9J2vH35JBgbyCzp9Glq0kKOWli0jtZYrvp61iLM0ope2Fvz0E26r2hAUL3PWLTBm/K4x1PZuzDuLGnDezQHbdrUxDjNm76i9JIYkMmn/JGp1rsWDhAd8eexLfvX6FZ3QMa3tNGZ3n42bTU6HX2YkJckW+OrVMgFCo5H59IMGyVb4oEHyRtWDwOgkTvpFcuJ2BCdvRxIeL0OidRws6NrQka4NHOncwAF7y8LldxcsgPfe0fFtty3UcEyn35J+rPphFQFrArC7Z4fGSIPoJnhi1hOkWafRu0/JxLmqlEO/GRrPp+tP0kFjRejHR6hZ25andzyNXV1b+QS+dxqWDwQjM9JqD+TIVldObTal8fBmDFs2DEsnS72PFZMSw/Cpfhxb1w4cr1F34td8PKUHE1pNwNRI/4wYfZ/GhTlygP37pe7HxWvp1Ojrh1mrAIyM4OVODjwdvgmr6yu4F+jGwKPvkd7nHOZtNtHYqSG7J8qMn3VX1tGlVhfi/41n08RN9F/Qn46vddTb1thYaNxYRpT++kte7g0b5MCJ7t1h59ZULAK2wbllcP8MGJlDq7EwYB6Y2+apLzoxjR2XgvnHK5CLgbEYAO0drXimfyP6N3Nm48R1+B/zRxumRRHygRPeLJzkr5KxMrGi5uKaNO7XmJGvjeRGxA3q2tbFxNCEsMQwbv34MTc3LuVWvzbc9KzHrahb+EX5kaxJzjq+mZEZjewb5RsicbYsPGtEk6ohJiCGaP9oom9HE3U7ihj/GKJuRxHtH51T6zujozY1LZWUBykYGBvQcGBDWoxvQZPhTTC1LuJeSkmBiAjCwu9y/b43foGX2HnAhS073kNnHUjjp1rQ+56O2sYO1DdzpbaJE25Gdlh/NA+78HjZUrW1lR1+ycnSGSYnw7FjaJwcuD5vFt6bfsbbyRjrI29hZHeDmfEHOLBqBeMvP40gFctES574dyDeI07T0K0Bx8LOk6pJpaljU/o36E8DuwY4WDjgYO5AS+eW1LSpSaZvKXMht8hIvNatw/OFF/QaCh6VmMap2xkO3C+CgEjZr+FoZUrXhg50beBIl4YOuNnlP1goP27fhtYtdUxz3IJ9YM4OUCEEu3fvZs/CPVgctsA8xZzYfrF89+93JTrdKuXQ9/o+4M21XiSmywwVp9Ak6kek8Nb3T9C2vgOGChDkDRfXwOV/ICWGVMWB35eMJEm4MmL5CBoNblTUYXKwdXs6019OISzQGlr9hdPo+bzRdwIz2s3QS1K2KIceHB/M/OPSkWt0mhyOPCZGNvTt7GDTFh3vLruLkfstUnTpTGptzv+s92PhvRxDkcyZKEfeNE3kpFUoRgZG9KnXh/EtxvNsm4eKxud/Pc/Ol3ZSq0stnt7+dJ6sj6Js/eILOeDl66/lwwXkG/CkSTIhYfv2jP6qkEvSsd87Ay+fAgNDeHAFHBtBPg9Dv7AENnkHstkniJDYFKzNjBjaugZj2rrhUcOGU16n2HhgI/sC93HN9RpN7Jvw9NtPIxwFYqXgVszDuHZcalxWvUZaaGBgT6MmXbKcdiN76bhr2tQskVZIZKR8iH37rfSRuRFCkPAggejb0UT7P3T2QQFBdJnahWajmhU9KlYPbtyAq/7RmDc6w/mgzJTH89yNvZtVpl6cIZ5RprQd/yaeDbvTtkbb/OPaQhB1N4KffzzNJRczzsekZU07ZogWk/Q4jDRxKCIBt9hE7BOMsRrbgS03VpOoDUdHAjolHp0Sz4c93+T1Li9wP+4mbX5tg6OFY5azd7Bw4LUOr9Gzbk9CE0LZ47cna1tmOVsz22J/L4Xdt0lpGs7eieLk7UhO+EVwNSQOIcDK1IiO9exlK7yhI41drEr08BEC+vfV4XhsC800l/N0gGbnbuhdli9cjkU1C97937vFPhZUMYcOcPDQIWwbeHDkRjgHLgXjG56IAKqZG9OtoSM9GzvRo7ET1S0VuLEbru8gtMEcNk3ejpvxfur1cqPJ7NkYO+gf50tOhi++EMyfL2j0zE9crfMGlsaWTGs7jVmdZhWq0lbQzZbbkU9xn8Ls7rNpYN+AgAD48Uf47Td49VVBjwmhfLX7OgGRiXRp4MA7AxthfeZ/1L2ykSvXGnEq4ClmGgmcOp3gswljGNNieI6HjRCCY58f49BHh2g0pBFPrn8SY4u8rZmiHLoQMj1440YZrhw0SK5fuVKOeRo4UIZiskLwOq105ppU+L5FRp7xFPB8FmzzKqZpdYLT/pFs9Apk95UHJKdrqeNgweg2boxuWxN7K8GGqxv4zfs34nfEM3rzaFZNWoXWU5vVus76a9+IOrPnY7T0t5xPoEdACBg5Ur7lnz4NbQvoXsmPspSAmD+frElfFItIvAPP4jXvFbzT7+HVtgb+SYFZZWtXq41nDZlZ06Z6WwzTG3PwWiK7Lj8gIVVDTVtzxreuRmxEKFY163Dw9mnOBV7FMNWUWoobhokORGuN0diYUli+lqECRkbpGBqmgEESOiUejYilW922tHFtQmiSPz+e+zLjQZCADvlA2DRuDSOaDePo3aO8f+D9rAeBg7lcJrlPws3GjYikCB4kPMDRwpErZ6/Qr08/ANK1Oi4FxnD8lmyF+9yLJl0rMDZUaFvbLsuBt3arhnEpaAr9+Sf8M3UH7fAq1JmDjAyFhsKtW2oMPYvcP4zoxDSO+0Wwads1fBJTicloWzRxsaZHY0d6NnamXV07jLSCqHn9cTbyRqs1JK1mX8x7PwcN+4Ghfqpd/v6yw/xy2EVm/XiIY9FrEa7neLL5k7zd5W3auea9zrntDYoLYv6J+Sz1WprlyD/o8QH17epz7hx8841M7jAwgMGToklrfo1rEdH0dojmTcu1HLDU8FnIOURKFNXTTfA8+w2r97/ClKkGLFuWv05N+NVwlrgvoeXTLRn++3AMjfPPP9bH6SQmyiSTgAA4f/6h7vzvv8t+32HDpP050vZ1OvA/BOd+k4OZAJoMhp7vQo3W+R4nIVXDnisP2OgVyCl/mQLYsZ49YzzdGNyqBkFRt1nfbD31e9Rn4raJ+Rur1cpsiHXr5ICaF14o9NyKYuFCeO21vNoc+lCWDn3ZMqlR5OIiw2Ad/54lWwR//QUTJxKdHI3PAx+8gr3wfuDN+XsBhEfWx1LbB2NRHUjFhSC6u8fwdvwBXEIukYrCEUXLDl0SyQ368Gr/+bhXd0ebrmXb89u4tOoSbV/vQMchFsReuELMjdtE3wkkJiKG2I5diRkzjpikdGIOHCHW0pYYCxtiDE2JTYf41IKnn1MAG3NjTI01xKaFoCWONGJI0UaRJqJ5o/N0Wlavz+nggyw89yVaJQFjxZwWtqOwFG0Ji65GUpoWRYEWrjYZIRRH2te1y9OR+aiEhsrh/Z1rB/HB5Ht0eTN/PRGdTiZgHTok+2e/+kp16FkU9MPYPn07Xsu8cXimJYZTWnEiIIpzd6JJ0+owMzagc30HejZ2ouX9y7DhZ5rWu4SVVRLCfSLKqMXFskGnk6/b164JPIadxM/jaeIN7tOzTk/e7vI2gxsNznptzLS3IEdez7Z+Vgf82LEyVj5hehKpTa5z4FYInS3uM995P7Ue7CcZHZ8YKBy+2Zgml5pg5TCLXw+3Y9YsGQLIPWG2ECLrNTL4fDA12tbI6gAtzrXNTUCA1PP+4QeZ1pvJkiXw0kvy5l23roCQZsw9OL8cvFfCk39Cve6QEC4fqvnE2kF2XG3xCWKjdxB3IhIxMzZgUIvqmB24itFKf966PhO7egWEv9LSpEG7d0uRqBJOLODjA506SX3zbduKLz1S1iJtXl7y/gm6r+U77eu88roxyg/fZ22PS0ln56UQNnkHci4gGgVo7mpA12qncNrry71/mvP9m9+y30zhKFosUBhlbEPN9BQY87vsD4kNhGAfRN0e7J19ijM/nKH1M60ZvjxbIyEpSWbdVK8un/49e0o94bQ0ud3KivTP5hE3bQYxccnEXLtFrEtNYtJ08gGQnE5sUhoxyelEJz38PyYpnbiU9PzG7mWhUYJ52rMtvZu4kogPBobJ9K3ft/h58Hqg0+h4sc8tVp5pwoUL0rHrdHKg98GD0nmbmMgHLMjbzt5e9kE5OKgOPYvChlCfXHCS/e/tx62jG+O2jMPAzozT/pEcuRHOkZvhWR0gbtXMqHs/hvZXD1DT0oW+C1/DziYSNkyVue2tngSrwgccxMbCRx/JeXQdnXT0f2kPR6xnEBh/n6aOTXmr81s80/oZth/YzjHdsSxHPtVjKrO7z6a6aX3+/FM2pLZsgaZN4apfGn/6+PKPTxA6oeUTk4+ZqgSAqQ2iw3T+um2F/xtx2DhU43zDcaw5VIO5c6UduR1MWmIaG8dvxH2qO83H5BVfKs61LYykJBk3z3yYZLZin3pKJiEUqGyZniLj6YoCu94Bn1XQ+ilo/wJUz19sSwiB970YNnoHsuNiMHEpGowEeNaypV/rGvRq4kRD53xioUlJMj506pQckTq44DzsgnjmGSl7cOGC3gkUOXgcqptRhy4yuV8Qu3UDueito5m7EcduhbPRO4h9vg9I1eio72TJ5BYmjDY8js2NDRBxk+iYahyJ/pG+S/vJ0bIPLiJCBDNHzISoO2DpCKbWcOpn2DsbFENErQ7cDWrA8XWmDN3xIbZ1C0kPTkuTebbe3nIZMkR+HxcuyLEYpqayhdSmjYxjDR2aQ4Y2E61OEJ+SnuX4Y5LSiE1Ox/fqNaYM7oqRUVxWyuTg1YPZ7bcbQ8WQzrU6M7DBQAY3GlxwGnIx0Gl0/NxvC1FHLsO05/lkmRuffgo//ST7WEDK0wweLNflRk1bzEZRF+Pa5mtsmrgJKxcrXrr8EiZWD9/970YmcvRmOEduyjzTpDQtBlqBy4NEprSMZbLVX1iEXwTFEBr1B/enZWjAqOCUJW9v2So9exaOHddwz2Y9C04u4MKDCzhZOBGTHINQRFaM3CK1Pj//LIXBIiOldvb3P2q5prnLV3sv0El3nUNKEKLaIb6sXpeedg2p3WcuBz/z4sT8E9TsUpuNhk+x55glP/4onWdukqOSWTN0DUFnghi6dChtn9fvJi7ujRYXJzNchg2TLfZMvvtOTuA9YYKMrxcpgBZyEc4ulR3ZmhSo3VnKEjQveH62NI2O37YeIsbclcM3wrgZmgBATVtzejZxoldjJ7o0dMQqc37L2FjZc3v1qtSy7tFD7/MEqdIQEACNitennkWZO/SICPD0RKeDjd+dwM8yns0+QYTFp1LN3Jjh7q6M8XTD/e4KlANzQeigVicC4ruy9r0UJh58iVpdHvZr5GuvJg0Cz4LfAbh9AEIuIhRDlHfvIExt0Ny9iLFDdbAuQoIgk6go+V1kOnofHznwYe9e+Sp0/LiMJ2U6eg8PmZ6Yi/xsTdemcyboDHv89rD39l7OB5+nb72+7J8s5wTYeXOnfnIJ2RACblzTsWnyFtK9LnPQoA8bQ7vj6Ch/z2fOyHGHvXsXPmGT6tCzoc/FCPYK5v7J+3R8tWOBZdI0OrzuRrPv/H12Hw/ggaWMD7Qzf8DL9ufonHgAs/RYlLdvylBAUpTMq87nXVurlaGSgQPl5337BNpaR/jt8kLSYtL48ckfqW9Xn5QUOQYpNhYGDE6h2bDdXBAn0MUOolnsMd4w20QT3T1ud5tFvb6fYKAYkBKTwsYJG/Hb7UerZ9ux4Mogznkbsnw55CcFHhcUx18D/yLqVhRj/h5Ds9HN9L20xb7RhJBpzr/9JkMsTz31cNtXX0n9pylTpD547nBQviRFwYXVMtZetxuM+FmuTwjL940pU8Hw7pG7hCSkcsfJnMM3wjjhF0FimhZjQ4X2de3p1cSJXk2caaQko/TsKQeAHTqkV6/mwYNSUqeQSXf0okwdukZD5JCRbIs1YePIF7kSo8HIQKG5rRPpu8P4cdgeGk98CVyay9RevwPgPh4cGrC03VK0qVpmXJqR481GL3sTwuXDuFE/Dn50kKZRb+Hq5A8uLaFBH2jYVz6c9U3zFeLhyGwLCzk69M03c47KbtRIDjCqVUuuNzbm8JUrRdoanhhORFIEzZyaEZ0cjeMCR3RCh0d1DwY1GMSghoPoXKszJoYPG28iY5yYgYEc5D3tOR0dQ7bQmsvspw8WA7rz++/5vkwUiurQs1HcixFwOIDQS6F0eLVDgWlJOq2O3d+cYN2aSzxoYseDJvYkpKfT1OA+Rq6t6dHIiRm3XsBSJKN4PC1/DDb5K8GFhMiZSdzcZPjh+vULBAV58O238CAhhHe+9+aq0V/4plzCPv1ZnlbCec1sO3V0QWDfALq9Aa3HgZEJEdcj+Hv438TciaHL508wa1U7bt6Us33lN1tYclQyv7b9leSoZMZvHU+93vX0vk5QshstNVU2fC9ckLrP7u4Pt332mZzZbNo0+PVXPZ06yGBkWgKY2UCQF/zWH5oOgQ4vQN3uWQ/VTIe+xH0JBoYGTPeejqIopGl0nL8bxZEb4Ry+Ec6N0HgAXKuZ0bOmBT1//Ypud7yxOvivjHUVwI0bUv5k+HCZnvkolIVDT9PoOHg9lH9W7uWwsENjaEQLVxsmNzNgKEcxvbweozh/EtMsWJf8ExO/ejLHqPfE8ESWtl1K13e70mFmh0ey9/a/tzk0fSHNWgXSYXACxmHnQZcODfvDMxkSDjH3oFrRo6TzEBIiW+8+PvJGW7NGdtC8+iosWkRi3bpY7tyZr657fuiEjosPLrLHbw97bu/h5P2TaHQafhr0EyNqvMqufcnsP6jh3Alr5s+H8ePljEPfzvSnzuFV7KcP7q90Z9Gi4p1GJqpDz0ZxL8bW57Zy4Y8LtHupHU/89ESh+i4PLjxg0zObCL0ajsur7Uh7oiHH70Ticz+ascohnjI6hqdyHYFCau3umPV8Q7ZEcnHkiAzDXLsmPzs6abl4wZDLSXsZuupZ6hm8RlpyKxwsDdhnNQ97M4HS/S1oPlKm+QE3d9xk08RNGJkZ0W3hU0x8vzahobJDrk/eQwIyxnzk0yM0GdaEGm2LP0FlSW+0Bw+kNI2Rkcx8yR5j/ugjGY556SXZ31DsVN+4YDizBLxXQXIUODaRI1HbTuLwiTP06tULr6Ve7HhxB88ee5ba3fK+6wbHJHPkZnhG6z2ShFQNRjoN7cJu02tED3p1bkwTF+scD/yUFNkJGhgIFy/KUeaPQmk5dCEElwJj2egdyLaLwcQkpeOUEMUokxhGvzOFpg4msKAhpMVD3e5oWj7NnHXD+fwba9q1k510des+rE+n0aHT6jAyzdnZURJ7A88EsmbwGgxNDJm0cxTOljfB2Azq94LkaPi6Pti4QcM+0KAv1O8J2VQri83583DoEKlffYWpTid/HN27F71fNtLSIEXEse3CMT4YP5B7ARnXwTwCqybn6T/uFi+MaUjPuj0xEhb0af6Au6nVuXpVasiVhLJy6JVykujiMvy34Vg4WXDy65NE345m7LqxmNnmL11a3aM6L5x7gQPvH+DMj2dw3BfAwtWjsZjanpN+bdlwczJf3bhEt6T9jLl7jNVrd3OrTio9ahswzs0Kg9rtmb7zRcISwzCbGYntoZ7EpIcxdbobZtU+4txpWz7TDmcCy9nTazXP9GmDRVo72emU4UyEEBz/6jgHPzhIjTY1aDN/HCMmVyM1Vb7+d+iQ1+47B+9g4WiBS2sXen3SqwyvZv5Ury47dmfOlP2P2fn0Uxl/nj9f9vp//30xnbqNK/T/FHq9D76b4ewyODQP2jwjt9/cS+uuCsdcBGcXnc3XobvamvN0h9o83aF2Vqjt8HFfjkSb89WZUL46E0qNamb0bOxEryZOdG3oyOz/GXPxotR5elRnXhqExCaz2SeITd5B+IUlYGJkwMAaxjy3fzbuzeIwaNMYqr8qC49aAtVbgV0djIB57cCzixwrsHevFPnSpGpQDBQMjQ2LFLHTF7eObjx77FlWDVjFn4M28rr/6w/7sBRDGPwN3D4IlzeC1wq5bswyaDkGtOmgGGQ1aPSiXTto1w6fWrXoNGeOVC77999CnXpoqOzcPnRILp6esGaNDRM7DOFQH6mV17RdCFeV9ey7s4c9/kfQjO/HLPdZjKp3jBO3q7NuSzxWVlbIJMuKw3+ihZ6J9+/e7JyxE/tG9jx79FksHPMf2usV7EVgXCBXzl/h+NrjRItoOnbuyPfvf4+BoQENfmzI/ah0zHUeWGnbYKRzZ5LhEeYZ/0GokStrhB37bEzAwQIXK2fM42xoaj8Sk/OreVrsxlZJJK1OT0yGfw8OOWfZSUtMY9vz2/Bd50urCa2o8eIwho4yxtRUzlGZ30xrV/+5yqaJm6jbqy7P7H2m2NclO4/aisxUuc2tdiuE7CT9/nupHf71148045hstdu4SnuvfQChVwCIirLFul0PjFsNgjYF5KZn59QpQkY8xdH2/Tk85gWO340jPlWDgaKQdNcOT1dnvn3bKU/rvSSU5Nomp2nZ6/uAjd6BHPeLQAhoV8eOSc0NGBi7HbMji8FaB8aW0HK0dJjGBeush4TIh6+iwNaPzuP32xGme03H2jVvU/NR7oWYuzE8uPCApiMKCGdp0yHwnIzlt3kG7OvBxXWw5z1o0Fu23hv0ARv93jIPHz5Mr1at4JNP5M2VbY7PxESpfg1SVn3zZvm/tbXsFx85UoYE80On1bHxmY1cXXuVpEkG/LDuI0aNAt2YpzgVeIqBDQYyqOEg+tXvV6zUSLWFXgK0Oi1RyVGEJoaSokmh3fPtsG9gz7qf1vH68dcJSwkjNCGUsMQwGjk0Yu8zewGYsmUKvuEZok7twUJrQbJ3Mn/2+pNRq0bxTOuJKIqCi6ULzpbO2Jo6Ehf5DFuuulH7/lZe11zmjWiBV0xLNjSdwzl/fxbcfhorJYWE+gOh77uYuHnmsTfmbgzrRq7jwcUH9Pu6HyltuzBgiIKzs2x01K+f9xy9lnqxY8YOanWuxZi1Y8rycuqFosgW+uTJMist84eiKDJPPj1dDpwyNobPP38Ep569/2LqDgi5SNLlE0Rs3I510DmwNJUOXQhYPghsa4NrG6jZVrZcTTJ+4Z07U2P1csYNHcq46Ouk79mLd0QaO33C2aoNx9fgOoN+uE51m2yt90aO2JjpNxCtJOh0grMBUWz0CmTX5RAS07TUtDXnre7VGebhRh1XF/BeDQcXQbgWun0AQ14Hk6K1RzIn33jwAPZ84Y2VhSWJBlaUMHJQILZ1bLPmM/Xd4Is2TUvridkGkBkaQ50ucsnEri40Hiid/JWNcp1zC3huj+xLKQoHB1i0iJgYOLI1icO/3uBQjAd37yqEh8tw4IABcj6L3r1lf3hhk8XrtDq2TN7C1bVX6f15Hz7c0x1LS5lmfCBsJDqh45+r/2QpTU5yn8QfI/4Aco7/eJxUSocenRbN+eDzWc4402HP6TUHgJm7ZvLP1X8ITwpHJ+RsNnVt63Ln9TvU7VWXo8FH8bntQ93kutQPqU+jfo1o6fSw6fv78N8xMjDC2dIZJ0snTA1NufTXJXa9sotfWv/C6EWjaT2pdc4vrAHQoR3wNiF3bxJ2fCXpIdfZeS0ae5NqhLV6G6uOQ7Fyzj/jJOBIABvGbkCbrmXiron4pjZk3BDZob9v38MfYiZCCI59cYxDHxY+lL88MDGB+Hh4+WXZR9Ul4zerKDInNz1dSsebmMCcOaVwQHM7qN8Li/q9aDj0fQwMDWQLECA9GSwcIOA4XF6fYYgB9PkIur8p0/Ca2cHqlTBuAsroJ/HcupWOYxz4dExTQuNSZMfqzTB2XQlh3fn7GBkotK1jJzNnGjvTrMajt94BAiIS2eQTxCbvQAKjk7E0MWRIS2eedb1H09AtKN7bwfZDcJ0JG3zg53j4bimMKqB5WQi6wGCq60LYmzKYNZ4K69ZJqfnSRgiBz+8+3N57m+So5EKzzqjdUS5CyDcuvwMQfv2hM9/yssx2atgXGvRFZ9+I6BiFiAhITpZhmoUL5QheISwwoyldXK4ydlYTUlONMDKCGTP0szvTmV9ec5k+X/Thqn13jh2T2VouLjDBZQITWk1Ao9NwJlCmRmamP6Zp02i6qCmd3DoxqOEgBjQYUKzUyEehUoZchi0dxo6QHTnW2ZnZEflOJIqisPDMQi6HXcbZ0jmrFe1q7Ur3OjKulvn03P7idryXetPjox70mtOr0BGUADEBMWyevJl7x+7RfGxzhiwZgoVD4a0iIQRHjhwp8PVKCMH5JefZ89oe7BvaM37reHaeduC552R4cNeu/CeW0Wl0rB68GqvqVoUO5S8updVxFx0tY/3x8bLfKntal04nR+AvXy47Sz/4oHTt1Wl0JIQmYFMzV6su/gEEX4BgH5kSWa+7FHJb1hsMjMDIhfOnHTgcN4hX/p6MeY2cWjPpWh0+92I4fCOMwzfCuRoiRcBcbEwzWu/OdCuk9Z6frZmjNzd6BXL+bjSKAt0aOjK6jStDI5ZjfGUdxAXJjsOWY6QGzvEbMj/0xRfl0NwSsO2FbVxZc4UBe9/k6WfNuHNH9nG8+ebDt6bSuhc0KRo2Pr2R61uu0+PjjN9aAQ/A5GS4eVNOGRARIf+Gh8vTbRk2j+TzmzFP8gPgbmwtlnpN4Ytj/2PB1z68PaMGF33SOXIwjc7t02l9fhmm33wPnfrCujUQfQV0GtCmyQe+Nl2+rTk3lR22F9dmbEtDaNK5uc2XZKfeOD87jYEd7zJ/yAKeGKhB0abLcjoNdH5F3kvBF2DX26BNR5OeTFh8EGlpiTwnEjikaHnFtjE/JMRipNOBaxsON3hfDblkMrTGUF7o+UKWs3a2dMYy8xUaeLXjq4Xun3kzDV44GJ1Gx9HPjhJ5I5IRK0ZgbF5wK9e2ri1TDk3h5IKTHPr4EPdO3GPkipE0GNCgwH0Ka7lp07TsmrkL72XeNBrSiNGrR7NspRmvvQZ9+8pOxuzD6gG06VrSEtIwtzNn/NbxGJkaFfkgKg/s7OSAzI4d5aj7o0fl3AsgUxeXLpUt9Q8/lC31UtDNyuKvQX+RnpTO8yefz7nBujo0GSSXTBwawLi/INiHyMs+1GvqQzuLr+HTk/DzdjmI5tI6cG2DsWtbOtRuSod69rwzqClhcSkcvhnOkRvh7L7ygPXnAzE0UPCsbScHNjVxonkNmzz3gEar45hfBJuyjd5s4GTJh31dGe14H/s2Ga3YVRfBpYWUH24yWMbGr1yBZ5+Fzp3lu38JSI1L5crfV2gxvgXtuplx/rys8ubNR+zXyIYQcv4J6ZiN6PDNk5jZbefop0c5sC2JYI/BhEcoWU77449lmO7qVdmQyY6iyMzSlhM+xN/lQxZ9FkDXGgdpa32AoYN1NH8RLI2j4NteuAPuABlzPvPZWPjfZniiNzxxP6+h/T+VDj0pSsbvM48JNLY3QhnYj9EzwZQEBtTbjxJgLMNFhsZgYAxpGRkABkZgYgWGJhgZGuPq3AxhaMziRv3ZEneHG9e2EObaGVfb2oQZP7rSZkFUyhZ6aebzCiE4+c1J9r+7n5rta/L09qexdC5aMz3EO4RNz2wi4loEHV7rQL+v+hX4MMjP3oTQBNaPWc/9E/fpNrsbveb25vMvDPjkE+kA//477yxZaYlpbHhyA8lRyTx3/LlSy0woytZHYds22Rrfvz+v1KxWK4fTr10rO0tnzSp+/fnZe/qH0+x9Yy8vnH8BV0/9Zo0PC5P587a2Aq/R72Lx9QJ45XWY0g72vA+ZkrxG5rJVN361HOiUEgcmlmiEgs/9h61332BZ3tn6Yes97M5VQoxd2ewTRHh8KrYWxoxs7cwk5zvUD9qKcn2XbPW9dQOsnB4qVWYSHS2HFScmSuEWV/3OLTdCJwg4HIC1qzWOTWV+qRBSCdDYGC5dypyb5eG1zd7ZffRoztZzeLgMq40fL0cON28ut2efOveTT+CTTwRbXvmXpb/C5er9cXJWcHKSU/VOmSLj23Fxsr/IyUmmvjo5yTfUokYaHzl4gJ7WARnO1kQ6WEMTcGoC3gEw6zX4cz64uj10xoYmYOkgQ3Y6LbrkOLa/uIf7Z0J4wetlTG3M2LQJxoyRby/vvFOiy52HkPgQbnjdUFvoZYGiKHT9X1ccGjlw6rtTGFvqF4eu0bYG072ms//d/Zz96Sx39t9h9OrRVPcoOlYWfD6YdaPWkRyVzNh1Y2k2tgVvvSWFrqZMkaMuc3fW5BjK/+vQMnHmZcHw4bIDKr98XUNDWLVKttTfeEM6k1deefRjekz14OCHBzn38zlGLM9n9FUudDp53eWIcwWLVvMhKV1+IXZz4KO7EOUvQzXBPjK+a5ExbHT/HLi4FqMa7rSv2Zb2rm34X7s2hBm3l3nvN8PZ6/uADV5SvtbI4A69mjgz1rMmfcxuYLLlKbgQCub24DlVzvJkmZHEn92ZZ6pG3rsnc+1K6MwBFAOFen1yDjhTlIdCaq++KmUsGjXyIC1NOudhw+AP2d/HoEEyRz+TatVkFsn48Q/nX850xpl/5QxwCiN/HsCIRQIDA4WIGxHYuNlgkm0mIBsb6UCLizAwhPbP579xYBO47Ct/VDodXL+eZwCSTihsmX6Iy2tu0ufzPpjamBETI9NwPTxkKKq0qGFdgxvcKL0KsyOEKJfF09NTlJRDhw6VeN/C0Ol0QgghUuNThf8Bf733u7XnlvimxjfiU+NPxfH5x4VWo82xPbu9F/+6KOaZzRPf1/lehPiEiPR0IaZOlQOMX39dCG3OXYUQQsQGxoqfW/wsPjP5TFzdeLUkp6Y3ZXVttVoh5swRYu/evNvS0oQYMUJeg19/LV69Bdm7fcZ28ZnpZyIxPLHIOoKChKhfX4jFi3MZnPnF/PBDwTvf2CvEzreFWNZXiM+chfjERojvWj7cfuFvobm0UVy8dEF88+c/IuHIIiH8DshtMYFCrHlaiKvbhUhPLdzIDz+UtvzyS5HnUxhB54PE7lm7C70uDx4IMX68EB4eUeLJJ4V46SUhVq16uP3YMSEuXhQiOFiI1CLMLoi0xDTxbc1vxW+dfxNJkUklqyQbet+3X3whhJmZEJs2Za3SarRi44SNYg5zxNHPj2atf/FFIQwMhDh//pHNy8Oj/M6A86IAv6o69HzY+/ZeMddgrjj1w6ksJ18UiRGJYt3odWIOc8QfPf4Q0QHRWdsOHToktBqt2Pv2Xrm95x8iISxBpKQIMWqU/BbmzhWioEP92edP8YXVF8V6yJSUsrq2iYlCtGolhK2tELdu5d2ekiLEkCHyWixfrn+9BdkbejlUzGGOOP3Tab3qiY/P5/qnpwsxerQ06o8/iq5EkyZEyCUh/A4+XPejh3Ty2Zcdb+llUxabNkkbnn++4JtET7Y8t0V8bvm5SIlNKbJsWf/Orm68Kj4z+UwsbrlYxAXFPVJdetsaHi5Ep05CKIoQixYJIYQ4+PHBPM78yBF5yd8q5lelL6pDz0ZZ32ipCali7ai1Yg5zxPYZ24UmTaPXfjqdTvj84SO+sPpCfGnzpbi46qLQ6XRi37Z9YtXAVWIOc8TOV3YKTZpGxMcL0a+f/AZ+/LHweiP9IkXQ+aBSOLOiKctr6+8vhL29EM2aCREbm3d7crIQAwbI31r2FmFhFGbv3eN387wtZScmRoiPP5bHLZCUFCH695dNtY0b9TMqO+kpQgR5C3Hud+H/x4tChFwu3v5XrwphZSVEhw5FGFo0yTHJ4nOLz8XWaVv1Kl/WvzMhhPA/4C++sPpC/FD3BxF5K7LE9RTL1sREIYYPlz++994TSRGJwus3r6zNyclCNG4sRL16QiQklNikQlEdejYex42m0+rEv+/+K+YwR6zsv1IkR+v/Y4q6HSV+7/q7mMMcsW7MOjHfbb741PhT4bVM3jSRkUJ07CiEoaEQf/6Zfx3+B/zFzpk79X5DKC3K+toeOCDPe/jw/MNLSUlC9Okj/efatUXXV1J7dTohnnxS2nLuXBGFExKE6NxZCBMTIfbtK9HxhCiBrTExQjRpIoSzsxD375f4uJmcWXRGzGGOCDqnX+PgcfzOhBAi6FyQ+Nrxa7FxYgkemBkU11ZtSqo41fkNkW5iIR+a2ciMbj3CV10kZeXQ9epZUxRlkKIoNxRF8VMU5b18tldTFGW7oigXFUXxVRTl2dKN9D9+FAOFfl/1Y/jy4URcjyAlNqXonTKwq2/H1CNT6fN5H25svYEmUcOUQ1NoO60tISFyAhcfHzlNW37yt1c3XmX1E6sJOBRASoz+x60M9OkjM1p27ZL56bkxN5eZMd26yT7AjRsf7Xinvj/FxqfzVvLbb1Kkat68vGlyebC0lBOoNm0qx4mfOvVoRumDTidvjtu3paHF1WfNhRACr1+9qNG2Bq7tSt6hWha4tnPluZPPMXTJUEDaWpbotDq2TtvJ3lPVuPHlZjnVEIBGw+XLUvZ58mQpC1PpKMjTZy6AIXAbqA+YABeB5rnKzAbmZ/zvBEQBJoXVW9Fb6NlJS0oTQshWe+jl0GLtG3krUuzdLHsC/f1l55ulpWyp5sf5X8+LuQZzxe9dfi+VzqLi8ljefnRCXL9eeJm4OCG6dBHCyEiIrYVECIqy9+gXR8Uc5oiwq2FZ665ckf1i/fvn/5ZQIA8eCNGwoewIuHixGDvqZ2sO5s6VzcSffir2cfIjLTFNbJm6Rfj84aP3Po/7dyaEEClxKeKPHn+I69uKuEFyoa+tWo1WbHpmU56YuVixQujathVPtAkRTk5CREQU6/DFpjxb6B0APyGEvxAiDVgL5M4FE4C1IkdQWGU49IJnga1kZOaXn/r+FEs9l3Jx1UW997VvaI+JrQm+vnJi5ZgYqZiYn/ztyW9OsuPFHTQc1JBJ/07C3L7sBiCUJ4oCTZrI/zdtknnPubG2llOAenrKeTJ37SrZsdpOa4uhqSFnF50FZB71c8/JVLtVq4qhzw5yzPf+/TI3b8AAuHWrZEYVxY4dMnF78mSZN1cKGFsYM+KPEXhM9SiV+soKbaqW9KR01o1ax8WV+v/O9EGn1bF16lYu/XWJPp/3ofvsbIqMzs6kX7nBzz6d+f2dG488mUl5UeTAIkVRxgKDhBDTMj5PAjoKIWZmK2MNbAOaAtbAOCHEznzqmg5MB3BxcfFcu3ZtiYxOSEjIkK58vKTHpXN1zlVifGKo/Uxt6j5bV69Rmt7eRsyd2xFjYx0LFlyiXr3EfMtFe0UTdiCMRm82Krc888d5bVNSDJg0qSNGRjqWLPGmWrX0fOwx4q233Llzx5LPP79M+/bRxbb3+lfXCT8STucNnTGyMuLePQtiYoxp3Tq2RHZb3LuHx2uvoTMzw2fhQlKdnPTaTx9bze/fx/Oll0h2dcVn4UJ0uUeXlQBNgobk4GSsGxdPgqu8fmeaJA2+H/oS4xNDg5cb4PZk0eEmfWxNDkrG+yVv3J5yo84zdXJsCw015afJBmzXDcPaIpXLX3xBXIsWj3Qej2pvQfTu3bvAgUX6hFyeBH7L9nkSsDBXmbHA98gRsw2BO4BNYfVWppBLdjRpGrF12lYxhzli/ZPrRWJsmoiNlW/jd+7I/pXz52Wu7r59MgXP3Dxd1K8vxO3b+dfnt9fvsZ9HQTzua3vmjBCmpkL07i3z0fMjMlIId3cZJskdqtLH3qBzQWIOc8SuT04/atbfQ7y8hLCxEaJpUyHCwoouL/SwNS5OpgA5OgoREPDoNmZw+qfTYg5zROiV4oULy/N3lp6SnpUGfOr7U0WWL8xWnfbhlx7/ID7vdp0QgwfLUGjgET8ZVjM3F+Lu3RLZrg9lFXLRZ6RoIJBdpcgNCM5V5lngq4yD+SmKcgfZWj+rzxOnNNFqpcBPUpL8m33Jb11xysp1hiQnDaO5qSPpGw7xxoYwgih89oO6dVM5ftwoj2Ji5lB+vz1+vHzlZZya69fSq0p06CB1XaZMkTrp+cmT2NvLSEfv3nLE4u7dxZvf2bWdKy1f6sbr37gx2UjqxzwybdvK0MiAAXLo5MGDMo5TUjKHq968Kce+16lT9D56IDI6Q13bueLcIu+crBUVI1Mjxq4fy4HZB2gyokmJ68kMs9g3sqfnxz2xcsnbKl63Tob0fvgBavZoIOdR3Lq18FmeKyj6OPRzQCNFUeoBQcB4YEKuMveAvsAxRVFcgCaAf2kamsnBgzBrlgcmJvk73/S8b+16YWAgMywsLOTf3IudXfbPCubmXRDaVsxwtsbcHEw1iVg6W+ZbR2SkFzVq5PRAuYfy/xedeSaTJ8tpIr//Xqrqde2at4yjo5wXuFcvGDxYSgpnyvIWRVoafO3Vl3BjqR1TanTvLtNwRoyQT5o9e3JMrFAsvvpKzrzw3XfyyVVKBJ4KJNw3nGHLhpVanY8LA0MD+s+XqSZCJ/Ba6oXHsx55psoriOwx897z8r+mkZHw2muyYZHVXeHk9FDI/8wZ2YL45JPSUy4rQ4q8MkIIjaIoM4G9yIyX5UIIX0VRZmRsXwJ8BqxQFOUyMuzyrhAioiwMNjQEIyNB9ep5nW5Bzji/9bnXGRuX5PuSMcmrG6+ydepW+q8ZTZNheVsThw/rcnyOC4rjr4F/EXUriic3PEmz0flrpP+X+Pprmc6ZnzPPxNn5oVMfNEi22vXhww+lNslfP4QTviuAui+3LxWbAfl0+esvePpp2Xu7ZYuUjywOu3dLIydMKJlCWSF4/eqFibUJLcfnM9VVJeLu0bvsfGkn1zZdY9ymcQ+ntSuA3M68xwf5v9K99ZbU8Nm/vwABsI0bYcECCAiAZcseCt5UVAqKxZT1Ullj6PkRFxQnfvX8VcxR5oiT353MMxgot73nl55/bEP5i0tFuLYXLwoRGFjw9sBAIRo0EKJaNSFeffWm+OcfOVT76lU5sjt7KuLu3TL776WXhDjw4QExR5kjom5Hlb7RS5fKA40bJ4Qm/5HF+V7bW7dkGqS7uxzBWIpoUjVigcsCsX3G9iLL6nRy9K6fnxCnTwuxa5cQ//xzolTteVR8/vARcw3nimUdlonEiJzXKve13Txls5jDHHFk3pEC6/v3X/mVzZ5dyEF1uocppAMHSo2IUqA8Y+gqRWDtas2zR59l86TN7HtzHxHXIxi8aHCeSSc0KRqMzIzwfMGTxkMa5zuP43+d5GSp1le7Nhw5Amb5TI9Zs6YMvfXrBwsXNmLhwpzbDQ3lbGROTjKU5uwsQ9THktqBcpzVs87R6q0BWdKt+sizFskLL8ic1HfekbH0JUuKfuVLSJBayQYGMtxS0nBNPqSlQWSkIX22vEZYcDrr1knVxEzZ2+x/M5e0tJx1GBt34sUX4d13H3lcU6ngMdUDMzsz/hn3D390/4NJ+yZh45b/1HR1e9fFobFDztTEbCQlyflBGjeGjz4q5KCKIsXaa9aUO/TsKfs48pt1pgKgOvRSwtjCmCc3PMnBDw9y/MvjNB7SmCbDH4Zf7hy8w+bJm3l6+9PUaFNDdeYFYG4Ov/wi/dyMGVKyNT+/WLs2XLsGW7acpFGjLoSHS03z7BrdmZ9TU+Vgy6goG56kGfW3+/Dm9t6kI1+fDQwePgAyF2fngj87OBTwAPjf/6RT/+IL6dTnzy/YqQsBzz8vZ3TYswfq1cu/XEbR2Nj8nXF2p5x9XVxcZjqyScbyEDu7h9K2detKifXscreOjjLVfsGCByxZ4srSpdLU994r/37CpiOa8szeZ9jw5Aai/KJyOHSdVkfopVBqtKmBxxSPQuuZMwf8/eHw4fwbDXl4/nk5u/aaNY/W+V3GqA69FFEMFPp+0Zemo5pSs73MfNGmaQk/Es7xL45j38her8kz/uuMHAlz58p+KA+PgsPKsiWeRuvWebfNnw8NGsjMmUyfmp4OV3Z2YNuoq6x48zIG7dvm+wC4ckX+jYzM/7iKkvcBkOX0q8/DqX99nBasxjn1N5xmv4CDQ059+9RUiPhsCeHrbxAxbQ0Rkf0JX1iwg46IkJNP5Iep6cPjOzrKc3Z0BIfE+xjs2kHd/z1JrbZOWY46ty2FIcRNFi1y5auvpFTCb7/JmY3ef18+CMqLuj3r8rr/61lx9KTIJIRWsHXqVnw3+PLK1Vewq29X4P7e3nLC8hdekA1uvRkyRC4AQUEQGCin5KpAqA69DMh05sFewawdvpb4B/G4dXRjwo4JVXb0Z2nz4Ydw8aLstOrYUc64pi/Hj8t5SseNy7ne2Bg8RtTGp0stajsn0W184fVoNNKp53b4uT9fvfrwASCEAjwvl5+An+QDwM5OhjCSkuQ8q/CSXH5DLshy9vYPW8sNG8rzznTG2SeMyPxrYZH/S8DmSV7cSIzjqenVMHmENkTdujJ6NHu2TMT5/Xc5F+yUKXJd/folr/tRyHTmvht82T5tO5bNLIk6E0Xvz3oX6sw1GpnA4uwsO+JLzKuvyjerdetkhlMFQXXoZYhZNTPM7c0xqWfCpL2TcszMolI4Bgbw558yL71I8axsREXJZJG6dWXoJrezUxSFZ489q9cIXyMjOdrfxUW/Y2u12R4AIRrC3vuWcK/7hI96kfDqrbh1K4YWbuY4rl2Ek50Gx6/fwbGWeZaDLpVYPrLF6rvBl7bT2pbaPVe7NixeLJ34/Pky4WPFCplyOnu2fPiUB7U618LGzYbwM+H0/qw3PT4sfIDC998/FMaztX2EAy9ZIlvrI0fKC/Pii49QWelRoeYUTU9PJzAwkJSUwhUGU1JSMNMr8FUxqEz2lpetZmZmuLm5YVxAWlhEhAwv5J7KLvucokLA6NFSGPHkycIfBEIIovyicGhUhqIdKSnwxBNw7Bhs3sxRY2N6vPce3L0L586VmRfMnFN1xsUZuLTW82mUD4XNLxscLFu4v/4qQ1kTJ8q3osaNS3y4EpMSk8KeP/cw8vWRhZa7fRtatpQpr5s2lUJaeUKCfA3ctUv2rM6dq3eljzJ3b2FzilaotEV/f38RHh5epAZ4XNyjzW7yuKlM9paHrTqdToSHhwt///zTOJOTZZriyJF51RGzp3+dPSt11L/7ruhjnvjmhJhrOFfEBuYz00ZpEhcnRPv2Qpiaiqg2beTsHbt2ldnhdDqdWNR0kfit02+PXJc+qXUhIUK8+aYcKW9gIMTEiXnkxR8LRdmq0wnRt69UaygsJbbYpKcL8dxzQrRoUayUxnLVQ39cpKSk4ODggFIJRmSplB6KouDg4FDgm5mZmQxZbtkCn35acD3t28sOL33G5jQb1UyOPvzVq0Q2602mbGSDBtj5+EgB9ieeKLPDCZ2gx8c96DmnOL19Jad6ddnBGBAg+zs2b4YWLeQ4K1/fx2KCXvz5pxyUNn++zEAsNYyMZG/xsWMyNSglRbbcy4kK5dAB1Zn/Rynqe3/tNdkRN3eufF3OTkICHDok/3d31++t166+HY2HNMbrVy80qWWs9OzgAAcPcvXDD2WKSBliYGhAq6db0XDg4w1qZ3YyBgTIvPUdO6BVKynlcPnyYzUlD6Gh8OabctKU6dPL4ACZvd4AU6fKocyhoWVwoKKpcA5dRSU/FEX2Q3XoIDvirlx5uO2VV+TsMgEBxauz/cz2JIYlcvWfq6Vqa764uBDWt2+Z6oEkRSZx7MtjJEUkldkxisLJCb78Un4Xs2fLRJDWrWHMGKnXUx7MmgWJibIjt1j69yXhmWdk2lOXLmWnl18IqkMvIT/99BPNmjVj4sSJ5W1KgYSEhDB0qJzWKzIykt69e2NlZcXMXJMm9OvXj+jo6PyqqFCYmclX+mHDHmae7N3rwsqVMs2xuLnRDfo3wL6RPZdW5TPDRiXk4p8XOTj7IAkPyu+VPxMHBxlduntXDrQ8cADatJFJIV5lHOXKzs6dsHatvD+aNn0MBxw6VL4uxsVJp3728QrOqg69AIQQ6HS6ArcvXryYXbt2sXr1ar3q0xQ0MqQM+e6773jhhRcAmUXy2Wef8c033+QpN2nSJBYvXvy4zSsRrq7w99+yJejrC99+24QePUomiasYKIzfMp5xm8YVXbiCI4RUI6zVpRbOLSuOTK6dnQyTBQTIv0eOyOyjYcNkok9ZEh8PL70kY/rvvlu2x8pBx44yzcrGRgq2paY+tkNX3Dz0WbMKfEcz12pLlrDr4SFFjwsgICCAJ554gt69e3Pq1Cm2bNnC+vXrWb9+PampqYwaNYq5c+cyY8YM/P39GT58OM899xzTp0/n1Vdf5fLly2g0GubMmcOIESNYsWIFO3fuJCEhgdTUVLZv315guW3btpGUlMTt27cZNWoUX2eMetizZw+zZ89Gq9Xi6OjIgQMHSExMzLee3GzcuJF58+YBYGlpSbdu3fDz88tTbvjw4XTv3p0PPvig+Ne0nEhNlS2+9HQDVq/Wf/RjbqqKbPHdI3eJvBFJtxXdytuUfLG1lS31WbNg4UKpEtyhg+wf/vhj6NSp9I/54YdyMOeJE8UXwHxkGjWSTv3ePZlv+5iouA69nLhx4wZ//PEHixcvZt++fdy6dYuzZ88ihGD48OEcPXqUJUuWsGfPHg4dOoSjoyOzZ8+mT58+LF++nJiYGDp06EC/fv0AOHXqFCdOnKBOnTqFlrtw4QI+Pj6YmprSpEkTXn31VczMzHjhhRc4evQo9erVIyoqCoDPP/8833osLR8OCbxz5w52dnaY6nEz2dnZkZqaSmRkJCaP/c4vGaamMiaalOSFm5vnI9V15+Ad9ry+h8kHJ2PpVDmlGbx+9cLM1owWT5XdtGmlgY2NzFd/7TX4+Wf45hs5GnbAACn1oK/GfVGcPi0fHK+8UrxRxqVK9lFp8+bJYaplrKtecR16IS3p5Ph4rHOPMCkl6tSpQ6eM5sK+ffvYt28fbdq0AeQ8gLdu3aJHruly9u3bx7Zt27LCGSkpKdy7dw+A/v37Y5+hzFZYub59+1ItQ/SnefPm3L17l+joaHr06EG9DOGmoupp1uyhrnpISAhOes51CeDs7ExwcDB1y1Oko5hMmQKHD8c/cj2WLpaEXQnD53cfur1XMVu4hSGEQJOiwX2qe9aE5hUda2sp9jVzphzRu2CB1MLv21f6vO75iyTqRVqaHN5fs6bUSSt3hJBKYH/8IV8Zliwps0NVXIdeTmRv5QoheP/993mxiGG9Qgg2btxIkyZNcqw/c+ZMnvoKKpe9JW1oaIhGo0EIkW86X0H1ZMfc3LzIEbfZSUlJwdz8v6kz49zCmXp96nFu8Tm6vN2l3CboLimKojBu87jM+X0rFVZWUqTy5ZflqNOvv5bTC/bqJR17SQZTfv217F/Zvj3vyOJyQVGkCI6bG3z2GYSEYJArMaG0qFx37mNm4MCBLF++nISMgQJBQUGEhYXlW27hwoVZPygfH58C69OnXCadO3fmyJEj3LlzByAr5KJPPY0bNyZAzzw+IQQPHjyoVK3z0qb9zPbE3Y/jxvYb5W1KsRBCEHs/FqjcYzgsLWWuuL+/fDm/cUPOxNezp8yQ0fdZdf269JnjxsmEkwqDoshRcUuWSC3kMvquVIdeCAMGDGDChAl07tyZVq1aMXbsWOLj877if/TRR6Snp9O6dWtatmzJRwUo5utbLhMnJyeWLl3K6NGjcXd3Z1yGfKA+9VhaWtKgQYMcnaB169blzTffZMWKFbi5uXH1qsy/9vLyolOnThiVtGexCtBkWBNsatlwblEZp16UMgGHAvihzg/47y+TKXwfOxYW8PrrUndl4UL5t18/GYLZt69wx67TyYFDlpb5TzZeIXjxRThyBF1Z6SUVpAlQ1kt+Wi5X9RSBqEzaKEKUn72bNm0SH3zwQZHlXnvtNbF//34hRPleW32//+yU5pR5l/++LHz/8S21+nJTFtP7bXhqg/jK7iuRlpRW6nVXhOkIk5OF+PlnIdzc5CxwnTpJKZzcck+HDh0SS5bIMsuXl4+txeE/oeWiUrqMGjVKrzBKy5Yt6du3b9kbVMFpOb4lzcc0L28z9CYxLJFrm6/hPqXydIYWFzMzGV/385PRiuBgOS93x45SXiCzxR4RYcI770CfPnL0/X8V1aFXcaZNm1ZkmczBRyrSSR757Agpsfp3KJcXF1ZcQJeuw3P6o6VtVgZMTWW04tYtma4aESEHJ7VrB1u3wk8/NSItTXasVuKuhEdGdegqKtmIC4zj8MeHufjnxfI2pVCEEFxYcYE6Perg1KxqDI7SBxMTmZJ444acOSk2VsoJHDvmxNy55TfRRkVBdegqKtmo0bYGbp3dOLvoLEJXcdMAFUVhysEpDP55cHmbUi4YG8v5Ta9fl9K448bd4403ytuq8kd16CoquegwswNRt6K4/e/t8jalUKyqW1Uo3ZbywMhIqm/OmOFPAZNd/adQHbqKSi6aj22OpYtlhU1hTHiQwMp+KwnxDilvU1QqGKpDLyGVTT7333//xdPTk1atWuHp6cnBgwezylUW+dzHhaGJIe1eaoehiSE6TcGKm+XFhRUXuHPgDsaWapNUJSf/3ZEkRZCV11mAIv7ixYvZvXt3ls5KUWg0msc+cCe7fK6joyPbt2/H1dWVK1euMHDgQIKCgoCH8rmVSW2xrOn5cc8KOfJS6ATey7yp26sujk0cy9sclQpGhXXos/bM4sKDC/lu02q1GJZAPtejugc/DPqhwO1VWT43U2AMoEWLFqSkpJCamoqpqWmllM8tazKdeZRfFNau1hhbVIzWsP9+f6L9o+nzeZ/yNkWlAlJhHXp58V+Qz924cSNt2rTJ2lYZ5XMfB2FXwvil9S8M/XUoni9UjFxvr6VeWDha0HTU45h+R6WyUWEdemEt6XhVPrfE8rm+vr68++677Nu3L8f6yiifW9Y4tXDCpbUL5xado+20thUiBFOvTz1qd6+NkWmF/emqlCPqXZGLqiyfGxgYyKhRo1i5ciUNGjTIse2/LJ9bEIqi0GFmB7a/sJ17x+5Rp0ed8jaJ9i+3L28TVCowapZLIVQl+dyYmBiGDBnCl19+SdeuXXOUFap8boG0mtAKMzszzi56vJP95kboBJf+ukRaYlq52qFSsVEdeiFUJfncRYsW4efnx2effYaHhwceHh5ZDydVPrdgjC2MafN8G27tukVq3OOb7Dc3t/fdZvOkzdzccbPcbFCpBBQkw5h9AQYBNwA/4L0CyvQCLgC+wJGi6lTlc8seVT63dEgISxAJYQmPXM+j2Lp25FrxtdPXQpOqeWQ79KUiyOfqS2WyVYiyk88tskmmKIoh8DPQHwgEzimKsk0IcTVbGVtgMTBICHFPUZT/9njkCsKoUaOIjIwsspwqn1s42SeOFgX0a5Ql8cHx3Nh+g85vdcbQpPjpuir/HfQJuXQA/IQQ/kKINGAtkDvpeQKwSQhxD0AIkTfQrFIuqPK5pUNiWCLLuy7n8urLj/3Y3r97I7SiwqROqlRc9Ama1gTuZ/scCHTMVaYxYKwoymHAGvhRCLEyd0WKokwHpgO4uLhw+PDhHNurVauWb4w6N1qtVq9yFYXKZG952pqSkpLnniiKhISEYu9TEoROEHE/gv1f7CfKLapEdZTUVt9/fbFta8ulwEvy1/eYeFzXtjSoTLZC2dmrj0PP7/0yt66oEeAJ9AXMgVOKopwWQuTowRFCLAWWArRr1070yjWl97Vr1/TKLy/LPPSyoDLZW562mpmZ5RjRqg+HDx8m931UVlj8z4I9r+2hkWUjaravWez9S2prr6O9SI1PxdQ67yCxsuRxXttHpTLZCmVnrz4hl0CgVrbPbkBwPmX2CCEShRARwFHAvXRMVFGpGHhM8cDEyuSxqjCmJ6cDPHZnrlI50cehnwMaKYpST1EUE2A8sC1Xma1Ad0VRjBRFsUCGZK6VrqkqKuWLqY0prSe35sraKySGJ5b58eIC4/jG5Ruu/nO16MIqKujh0IUQGmAmsBfppNcLIXwVRZmhKMqMjDLXgD3AJeAs8JsQ4krZmV3+VDb53LNnz2bln7u7u7N58+ascqp8rv50er0TA38Y+FjEunyW+5AWn0b1NtXL/FgqVQO9RpIIIXYBu3KtW5Lr8wJgQemZVr5k5nVWFfncli1bcv78eYyMjAgJCcHd3Z1hw4ZhZGSkyucWA4fGDjg0dijz4+i0Orx/86Z+//rYN7Av8+OpVA0q7NDAWbPgwoX8t2m15pRAPRcPD/jhh4K3V2X5XAsLi6z1KSkpOXKpVfnc4qFN0+Kz3Af7RvbU71u/TI7ht9uPuPtxDPx+YJnUr1I1qbAOvbyoyvK5Z86c4bnnnuPu3busWrUq641Blc8tHoqBwvEvj2PXwK7MHLrXUi+sqlvRZHjBAmwqKrmpsA69sJZ0fHyyKp9bAvncjh074uvry7Vr15gyZQpPPPEEZmZmgCqfWxwMjAxo93I7Drx3gLArYWUyUXO/+f2IuRODobE6MlRFfyqsQy8vqrJ8bibNmjXD0tKSK1eu0K5dO0CVzy0ubZ9vy+FPDnP257MM/WVoqdfv1MwJp2Z59exVVApDVVsshKokn3vnzh00Gg0Ad+/e5caNG1mtcaHK5xYbC0cLWk1oxaWVl0iJyf/BWRJ0Gh3bX9xOiHdIqdWp8t9BdeiFUJXkc48fP467uzseHh6MGjWKxYsX4+goJxlW5XNLRoeZHXBp7ULCg4RSq/PWrlt4L/Um9l5sqdWp8h+iIBnGsl5U+dyyR5XPrVjoY+vqIavFNzW+EZq0xyeTWxBV7dpWJMpKPldtoVdhRo0apVcYRZXPfTSSIpKI8iuZYFd2Yu/F4rfbjzbPt1E7Q1VKhOrQqziqfG7ZIoRgWYdl7Jm155Hr8v7NGyEEbae1LQXLVP6LqA5dReURUBQF98nu3Np1i6jbj9ZKN7Mzw2OKB7Z1bEvHOJX/HKpDV1F5RDyne2JgaMC5xY+mwtj5jc6M+CPviF8VFX1RHbqKyiNi7WpNszHNuLD8AmmJaSWqI/BMIDqtrpQtU/mvoTp0FZVSoMPMDqTEpBBwKKDY+8YExPB75985ueBk6Rum8p9CdeglpLLJ52Zy7949rKyssmQDQJXPLQ1qda3Fa/6v0Xho42Lv6/2bN4qi0GpCqzKwTOW/hOrQC0AIgU5X8Cvw4sWL2bVrF6tXr9arvsxRmo+T7PK5mbzxxhs88cQTOdZlyueqlBxFUbCrZwfI+Uf1RZuuxed3Hxo+0ZBqtauVlXkq/xEq7NDAPbP28ODCg3y3abVaDEugn1vdozqDfhhU4PaqLJ8LsGXLFurXr59DXwZU+dzSZNu0baQlpDF27Vi9yt/cfpOEBwl4vuhZxpap/BeosA69vKiq8rmJiYnMnz+ff//9N0e4BVT53NLE3N6cCysuEHs/lmq1im5xX99yHRs3Gxo90egxWKdS1amwDr2wlnRZzkxfVeVzP/nkE9544w2srKzyPW9VPrd0aPdSO05+cxKvX73oM69PkeVH/DGC2LuxGBip0U+VR6fCOvTyoqrK5545c4Z//vmHd955h5iYGAwMDDAzM2PmzJmAKp9bWtjVs6PJsCZ4LfWix0c9MDIt+CcmhMDA0AC7+naP0UKVqozaLCiEqiSfe+zYMQICAggICGDWrFnMnj07y5kLVT63VGk/sz1J4Ulc3XC1wDLadC2/evzKxVUXH6NlKlUd1aEXQlWSzy0MVT63dKnfrz4DvhtAvb4FTyB+Y+sNQi+FYm6vvhWplCIFyTCW9aLK55Y9qnxuxSK7rSv7rxTf1fpOaDXa8jOoCCrrta0MqPK5KsVGlc8tX27uvMmJBSfyrI+6HYX/v/60ndYWA0P1J6hSeqh3UxVHlc8tP/x2+3How0MkhiXmWO+9zBvFUKHN823KyTKVqorq0FVUyogOMzugTdPi/Zt3jvVNRjSh/9f9salpU06WqVRVVIeuolJGODZ1pH6/+pz/5Tw6zUMZiVqda9H5zc7laJlKVUV16CoqZUiHVzsQFxjH9a3XATiz8AzhV8PL2SqVqorq0FVUypBGQxplpS8mByWz57U9XNt8rZytUqmqqA69EObMmZM1vP7jjz9m//79BZbdsmULV68WPJCktPcraAh/cnIyPXv2RKvVAjBo0CBsbW3zyOiOHz+eW7duFfu4KsXDwNCAyfsn03xMc4K3B8vO0OfUzlCVskF16Hry6aefZglp5UdJHLNGoymxQy+I5cuXM3r06Cw1yv/973+sWrUqT7mXXnopS9FRpexJiU0hcF0gTYY3wbpG2egQqahU7KGBvXrlXffUUzBpEiQlweDBebdPnSqXiAgYm0vC9PDhIg/5+eefs3LlSmrVqoWTkxOenp4Z1U5l6NChjB07lvfee49t27ZhZGTEgAEDGD16NNu2bePIkSPMmzePjRs3Eh8fz4wZM0hKSqJOnTqsXLkSOzs7evXqRZcuXThx4gQDBgzIsx/AK6+8Qnh4OBYWFixbtoymTZty584dJkyYgEajYdCggoXLVq9ezZo1a7I+9+3bl8P5nHf37t2ZOnUqGo1GHSH6GNg4Xn63qkyuSlmi/pKz4eXlxdq1a/Hx8UGj0dC2bdssh55JVFQUmzdv5vr16yiKQkxMDLa2tgwfPjzL4QO0bt2ahQsX0rNnT959913mzp3LDz/8AEBMTAxHjhwB4NatWzn269u3L0uWLKFRo0acOXOGl19+mYMHD/L666/z0ksvMXnyZH7++ed87U9LS8Pf31+vwUQGBgY0bNiQixcv5jlHldJn2G/D2Pr5Vhr0b1DepqhUYSq2Qy+oRR0fDxYWhbe4HR31apFn59ixY4waNQoLCwtATvyQGxsbG8zMzJg2bRpDhgzJE5sGiI2NJSYmhp49ewIwYcIEnn322aztmZosuUlISODkyZM8+eSTWetSU1MBOHHiRFYLftKkSbz77rt59o+IiMDW1lbPs30omas69LLHpqYNtZ6qhWKQVz1TRaW00CuGrijKIEVRbiiK4qcoynuFlGuvKIpWURT9pmupgOQnV5sdIyMjzp49y5gxY9iyZUuh4Y+CyD1jUCY6nQ5bW1suXLiQtVy79jAjoijbckvmFoUqmauiUrUo0qErimII/Aw8ATQHnlYUpXkB5eYDe0vbyMdFjx492Lx5M8nJycTHx7N9+/Y8ZRISEoiNjWXw4MH88MMPXLhwAQBra+ssJcZq1aphZ2fHsWPHAFi7dm1Waz032fezsbGhXr16bNiwAZDCaRcvSnnVrl27snbtWoAC5zG1s7NDq9Xq7dRv3rxJixYt9CqroqJS8dGnhd4B8BNC+Ash0oC1QN4JLOFVYCOQVzC8ktC2bVvGjRuHh4cHY8aMoXv37nnKxMfHM3ToUFq3bk3Pnj35/vvvAZkGuGDBAtq0acPt27f5888/+d///kfr1q25fPkyH3/8cb7HzL3f6tWr+f3333F3d6dFixZs3boVgB9//JGff/6Z9u3bExsbW+A5DBgwgOPHj2d97t69O08++SQHDhzAzc2NvXvl8zY0NBRzc3Nq1KhR4uuloqJSsVCEKHyG8ozwySAhxLSMz5OAjkKImdnK1ATWAH2A34EdQoh/8qlrOjAdwMXFxTOzxZlJtWrVaNiwYZFGl3SS6PLicdp78eJFFi1axLJlywott2jRImxsbJg8eXKO9eV5bf38/Ap9WOVHQkJCgTn5FY3KZCtULnsrk63waPb27t3bSwjRLr9t+nSK5he4zf0U+AF4VwihLSzOK4RYCiwFaNeuneiVKy3x2rVres0VWpZzipYFj9Pebt26cfPmTSwsLAp1zNWrV2fSpEl5UhbL89qamZllzd+qL4cPHyb3fVRRqUy2QuWytzLZCmVnrz4OPRCole2zGxCcq0w7YG2GM3cEBiuKohFCbCkNI1WKx3PPPVdkmexZNyoqKlUDfRz6OaCRoij1gCBgPDAhewEhRNZcW4qirECGXLaUnpkqKioqKkVRpEMXQmgURZmJzF4xBJYLIXwVRZmRsX1JGduooqKioqIHeg0sEkLsAnblWpevIxdCTH10s1RUVFRUiosqzqWioqJSRVAdeiFUdvncCxcu0LlzZ1q0aEHr1q1Zt25dVjlVPldFpeqhOnQ9qYzyuRYWFqxcuRJfX1/27NnDrFmziImJAVT5XBWVqkiFFufqtaJXnnVPtXiKSU0nkZSexODVeeVzp3pMZarHVCKSIhi7PqekzOGph4s8ZlWSz23cuHHWeldXV5ydnQkPD8fW1laVz1VRqYKov+RsVGX53LNnz5KWlkaDBlK+VZXPVVGpelRoh15Qizo+Ph4LY4tCW9yOFo56tcizU1Xlc0NCQpg0aRJ//vknBgYPo2yqfK6KStWiQjv08kBf+dwDBw6wdu1aFi1axMGDB4t1DH3kc0tiW37yuXFxcQwZMoR58+bRqVOnHNtU+VwVlaqF2imajaomn5uWlsaoUaOYPHlyjlZ/Jqp8ropK1UJ16NmoavK569ev5+jRo6xYsQIPDw88PDyyHkCqfK6KShVECFEui6enp8jN1atX86zLj7i4OL3KVRQep73e3t7imWeeKbLcd999J3777bc868vz2ur7/Wfn0KFDpW9IGVGZbBWictlbmWwV4tHsBc6LAvyq2kKvYrRp04bevXuj1WoLLWdra8uUKVMek1UqKiqPA7VTtAqiyueqqPw3UVvoKioqKlUE1aGrqKioVBFUh66ioqJSRVAduoqKikoVQXXohVDZ5XPv3r2Lp6cnHh4etGjRgiVLHs5JosrnqqhUPVSHrieVUT63Ro0anDx5kgsXLnDmzBm++uorgoPl/N6qfK6KStWjQqct9uqVd91TT8GkSZCUBIPzqucydapcIiJgbE71XA4fLvqYVUk+18TEJGt9amoqOp0u67Mqn6uiUvVQf8nZqIryuffv32fIkCH4+fmxYMECXF1dAVU+V0WlKlKhHXpBLer4eLCwKLzF7eioX4s8O1VRPrdWrVpcunSJ4OBgRo4cydixY3FxcQFU+VwVlaqGGkPPhb7yuWPGjGHLli2Fhj8KQh/53Mzl2rVretuWn3xuJq6urrRo0SJLARJU+VwVlaqG6tCzUdXkcwMDA0lOTgYgOjqaEydO0KRJk6zyqnyuikrVQnXo2ahq8rnXrl2jY8eOuLu707NnT95++21atWoFqPK5KipVkoJkGMt6UeVzywZVPrfiUplsFaJy2VuZbBVClc9V0RNVPldF5b9Lhc5yUSkZqnyuisp/E7WFrqKiolJFUB26ioqKShVBdegqKioqVQTVoauoqKhUEVSHXgiVXT43k7i4OGrWrMnMmTOz1qnyuSoqVQ/VoetJZZTPzeSjjz7KM1JVlc9VUal66JW2qCjKIOBHwBD4TQjxVa7tE4FMtagE4CUhxMVHNW5FrxV51rV4qgVNJzUlPSmd1YPzDoH3mOqBx1QPkiKSWD92fY5tUw9PLfKYVUk+F6SCZGhoKIMGDeL8+fNZ61X5XBWVqkeRv2RFUQyBn4H+QCBwTlGUbUKI7M3KO0BPIUS0oihPAEuBjmVhcFlS1eRzdTodb731FqtWreLAgQM5yqryuSoqVQ99mmYdAD8hhD+AoihrgRFAlkMXQpzMVv404FYaxhXUoo6Pj8fYwrjQFreFo4VeLfLsVDX53MWLFzN48GBq1aqV7/FU+VwVlaqFPg69JnA/2+dACm99Pw/sfhSjyhN95XMPHDjA2rVrWbRoEQcPHizWMfSRzy2Jbbnlc0+dOsWxY8dYvHgxCQkJpKWlYWVlxVdfyYiZKp+rolK10Meh5+dFRL4FFaU30qF3K2D7dGA6gIuLC4dzzUBRrVq1LCnZwtBqtXqVKy6enp689NJLvPLKK2g0GrZu3cpzzz1HfHw86enpJCcnExISQnJyMt27d6dFixZ4eHgQHx+Pqakp4eHhxMfHY2BgQLVq1di7dy9dunTh77//pnPnzsTHx6PVaklMTMyyP/t+iqJQu3ZtVq5cyahRoxBCcOXKFVq1akXHjh35448/GD9+PL///jtAnmtgZGSERqMhPDwcMzOzHJNCr169Gm9vbz744IOs/a5fv06dOnVy1FNW11YfUlJS8twTRZGQkFDsfcqLymQrVC57K5OtUIb2FqTalbkAnYG92T6/D7yfT7nWwG2gcVF1igqstjhv3jzRuHFj0b9/f/Hss8+KBQsWCCGEmDJlitiwYYMIDg4W7du3F61atRItW7YUK1asEEIIcfz4cdGsWTPh4eEh/Pz8hI+Pj+jYsaNo1aqVGDJkiIiKihJCCNGzZ09x7ty5rOPl3s/f318MHDhQtG7dWjRr1kzMnTtXCCGEv7+/6NSpk2jXrp348ssvhaWlZb72P/fcc+Lff//Ns/6PP/4Qr7zyStbnBw8eiPbt2+cpp6otlh2VyVYhKpe9lclWIcpObVEfh24E+AP1ABPgItAiV5nagB/Qpaj6RAV36GWBKp+rH6pDr1hUJnsrk61ClJ1DLzLkIoTQKIoyE9iLTFtcLoTwVRRlRsb2JcDHgAOwOCPOqxFCtCuFFwiVYpJdPjd7LnpubG1tmTRp0mO0TEVFpazRKwFZCLEL2JVr3ZJs/08DppWuaSolRZXPVVH5b6KOFFVRUVGpIqgOXUVFRaWKoDp0FRUVlSqC6tBVVFRUqgiqQy8hP/30E82aNWPixInlbYqKiooKoE4SXSCZeZ0GBvk/8xYvXszu3bupV6+eXvVVBVXDoq6JiopK+VJhPczc7b5cDY7Ld1tROdYF0dzVhk+GtShwe0BAAE888QS9e/fm1KlTbNmyhfXr17N+/XpSU1MZNWoUc+fOZcaMGfj7+zN8+HCee+45pk+fzquvvsrly5fRaDTMmTOHESNGsGLFCnbu3ElCQgKpqals3769wHLbtm0jKSmJ27dvM2rUqCyt8j179jB79my0Wi2Ojo4cOHCAxMTEfOvJTkJCAiNGjCA6Opr09HTmzZvHiBEjePfdd6lTpw4vv/wyICfxsLa25q233mLBggX8/fffaDSarHPN75p89dVXnDt3juTkZMaOHcvcuXMB2LVrF2+++SaOjo60bdsWf39/duzYoZe9Kioqj06FdejlxY0bN/jjjz9YvHgx+/bt49atW5w9exYhBMOHD+fo0aMsWbKEPXv2cOjQIRwdHZk9ezZ9+vRh+fLlxMTE0KFDh6zJME6dOsWJEyeoU6dOoeUuXLiAj48PpqamNGnShFdffRUzMzNeeOEFjh49Sr169YiKigKkZnt+9WQX/TIzM2Pz5s3Y2NgQERFBp06dGD58OOPHj2fWrFlZDn39+vXs2bMn61wPHz6MlZVV1rnWrl07xzXJPL69vT1arZa+ffty6dIlGjduzIsvvphl69NPP51liz72qqioPDoV1qEX1pKOj4/H2tq6TI5bp04dOnXqBMC+ffvYt28fbdq0AWSr99atW/To0SPHPvv27WPbtm1Z09WlpKRw7949APr374+9vX2R5fr27Uu1atUAaN68OXfv3iU6OpoePXpkhXWKqqdZs2ZZNgkhmD17NkePHsXAwICgoCBCQ0Np06YNYWFhBAcHEx4ejp2dHbVr1+ann35i3759dOvWDQMDg6xzrV27do5rAvIhsHTpUjQaDSEhIVy9ehWdTkf9+vWzbH366adZunSp3vaqqKg8OhXWoZcX2VuNQgjef/99XnzxxUL3EUKwceNGmjRpkmP9mTNn8tRXUDlTU9Osz4aGhmg0GoQQ+UrmFlRPdlavXk14eDheXl4YGxtTt27dLGndsWPH8s8///DgwQPGjx+f41wnTJiQ42EZEBCQ4xzu3LnDN998w7lz57Czs2Pq1KmkpKRkavoU6/qoqKiULmrvViEMHDiQ5cuXk5CQAEBQUBBhYWH5llu4cGGWU/Px8SmwPn3KZdK5c2eOHDnCnTt3ALJCLvrUExsbi7OzM8bGxhw6dIi7d+9mbRs/fjxr167ln3/+yZopSd9zjYuLw9LSkmrVqhEaGsru3VL6vmnTpvj7+xMQEADAunXrSnzeKioqJUNtoRfCgAEDuHbtGp07dwbAysqKv/76C2dn5xzlPvroI2bNmkXr1q0RQlC3bl127NiRpz59y2Xi5OTE0qVLGT16NDqdDmdnZ/7991+96pk4cSLDhg2jXbt2eHh40LRp06xtLVq0ID4+npo1a1KjRo0c59qvXz8MDAyyzjV357O7uztt2rShRYsW1K9fn65duwJyco3FixczaNAgHB0d6dChQ4nPW0VFpYQUJMNY1osqn1sxeRRb4+PjhRBC6HQ68dJLL4nvvvuuWPur8rkVi8pkb2WyVYiyk89VQy4qpcayZcvw8PCgRYsWxMbGFtn3oKKiUrqoIReVUuONN97gjTfeKG8zVFT+s6gtdBUVFZUqgurQVVRUVKoIqkNXUVFRqSKoDl1FRUWliqA69EKYM2dO1nD1jz/+mP379xdYdsuWLVy9erXYxyjpflZWVsXeR0VFpWqjOnQ9+fTTT7OEtPKjJI5Zo9GU2KE/TrRabXmboKKiogcVO23xjyF517UYCc3GQ1oSrH4y73aPCdBmIiRGwvrJObc9u7PIQ37++eesXLmSWrVq4eTkhKenJwBTp05l6NChjB07lvfee49t27ZhZGTEgAEDGD16NNu2bePIkSPMmzePjRs3Eh8fz4wZM0hKSqJOnTqsXLkSOzs7evXqRZcuXThx4gQDBgzIsx/AK6+8Qnh4OBYWFixbtoymTZty584dJkyYgEajYdCgQQXaP3LkSO7fv09KSgqvv/4606dP55dffuHOnTtZkrwrVqzAy8uLhQsX8tdff/HTTz+RlpZGx44dmT9/PiDfAN5880327t3Lt99+y8GDB9m+fTvJycl06dKFX3/9FUVROHfuHM8//zyWlpZ069aN3bt3c+XKFbRaLe+99x6HDx8mNTWVV155Rc1LV1EpY9QWeja8vLxYu3YtPj4+bNq0iXPnzuUpExUVxebNm/H19eXSpUt8+OGHdOnSheHDh7NgwQIuXLhAgwYNmDx5MvPnz+fSpUs0b948SzMcICYmhiNHjvDBBx/k2W/69OksXLgQLy8vvvnmmyyZ29dff52XXnqJc+fOUb169QLPYfny5Xh5eXH+/Hl++uknIiMjGTt2LJs2bcoqs27dOsaNG8e1a9dYt24dJ06c4MKFCxgaGmZpsCQmJtKyZUvOnDlDt27dmPn/9s49yqrqvuOfrzycTMJjFtjWCkGxNDjgAFMxPMIjJSoiMQJ1TaPLsGgRLKU+0rhsk6XFLrtIJKk8ZEFFDCSLMgUMqMvGElAiFUYHDI9RXqKugtFooExnZDBM+PWPs+/lMsyduczr3Dv8PmudNfvss8/e3zuP3+zzO+d89+zZlJeXU1FRQU1NTfLV/WnTprF06VK2b99+jk3A8uXL6datG+Xl5ZSXl7Ns2bKkJ43jOK1Dds/Q082oq6qgc37DM+7P98hoRp7K1q1bmTRpEvn5+QDceuut57Xp2rUreXl5TJ8+nVtuuYWJEyee16ayspITJ04wZswYAO644w6mTZuWPF5SUlLv+NXV1Wzbto3bbz975fHZZ58B8NprryVn8HfddRcPPfRQvX0sXLiQ9evXA3DkyBEOHTrEsGHD6Nu3L2VlZfTr148DBw4wcuRIFi9ezM6dOxk6dCgANTU1SQvfDh06MGXKlGS/r7zyCo8//jgnT57k+PHjDBgwgFGjRlFVVcWIESOSnzMR6Ddu3MiePXtYt25d8nty6NChjFd4chznwsnugB4D9dnVptKxY0feeOMNNm/eTGlpKU8++SQvv/zyBY2RbmGHM2fO0L17d3bt2tUkbVu2bGHTpk1s376d/Px8xo4dm7TMLSkpYc2aNfTv359JkyYhCTNj6tSpzJ07N9lHVVUVEC2QkZhxnzp1ilmzZrFjxw569+7NnDlzMrLMXbRoETfddFODmh3HaTk85ZLC6NGjWb9+PTU1NVRVVfHCCy+c16a6uprKykomTJjA/Pnzk8G3S5cuyWDYrVs3CgoK2Lp1KwClpaXJ2XpdUs/r2rUrV111FWvXrgWioLh7924ARo4cSWlpKRB5nddHZWUlBQUF5Ofns3//fsrKypLHJk+ezIYNG1i9enXyCmHcuHGsW7cuaZN7/Pjx5IIbqST+KfTs2ZPq6urkrLugoIAuXbokx0nog8gyd8mSJZw+fRqAgwcP8umnn9ar23GclsEDegrFxcWUlJQwePBgpkyZwqhRo85rU1VVxcSJEykqKmLMmDE88cQTQOQxPm/ePIYMGcLhw4dZuXIlDz74IEVFRezdu5dHHnmk3jHrnrdq1SqWL1/OoEGDGDBgAM899xwACxYsYPHixQwdOpTKysp6+xo/fjy1tbUUFRXx8MMPn7PKUEFBQXIlpIS1bWFhIY899hg33ngjRUVF3HDDDXz00Ufn9du9e3fuvvturr32Wm677bZkigaiXPmMGTMYPnw4ZpZM2UyfPp3CwkKKi4sZOHAgM2fOpLa2NpMfg+M4TSWdDWNrb26fm51cqNaEZa6Z2dy5c+3ee+9t8thun5td5JLeXNJq1nr2uZ5Dd5rFiy++yNy5c6mtraVPnz6sWLEibkmOc9HiAd1pFiUlJWmf2nEcp23Juhy6NfDkhNN+8Z+74zSfrAroeXl5HDt2zP+4LzLMjGPHjpGXlxe3FMfJabIq5dKrVy+OHj3KJ5980mC7U6dO5dQffy7pjUtrXl4evXr1avNxHac9kVUBvVOnThm9SbhlyxaGDBnSBopahlzSm0taHcc5l4xSLpLGSzog6R1J/1DPcUlaGI7vkVTc8lIdx3Gchmg0oEvqACwGbgYKgW9KKqzT7GagX9hmAEtaWKfjOI7TCJnM0K8H3jGzd83sd0Ap8I06bb4B/CQ8914GdJd0eQtrdRzHcRogkxz6FcCRlP2jwJczaHMF8GFqI0kziGbwANWSDlyQ2rP0BH7bxHPjIJf05pJWyC29uaQVcktvLmmF5untk+5AJgG9Pou/us8VZtIGM3sKeCqDMRsWJO0ws+ua209bkUt6c0kr5JbeXNIKuaU3l7RC6+nNJOVyFOidst8L+HUT2jiO4zitSCYBvRzoJ+kqSZ2BvwSer9PmeeBb4WmXYUClmX1YtyPHcRyn9Wg05WJmtZJmA/8FdACeMbO3JN0Tji8F/hOYALwDnASmpeuvhWh22qaNySW9uaQVcktvLmmF3NKbS1qhlfTKX7N3HMdpH2SVl4vjOI7TdDygO47jtBNyLqA3ZkOQLUjKk/SGpN2S3pL0aNyaGkNSd0nrJO2XtE/S8Lg1pUPSfZIqwvf2/rj11EXSM5I+llSRUjcvfG/3SFovqXuMEs8hjd45kj6QtCtsE+LUmCCN1sGSyoLOHZKuj1NjAkm9Jb0S/p7eknRfqL897J+R1HKPL6ZbyigbN6KbsoeBvkBnYDdQGLeuNFoFfCGUOwGvA8Pi1tWI5pXA9FDuDHSPW1ManQOBCiCf6Mb+JqBf3LrqaBwNFAMVKXU3Ah1D+QfAD+LW2YjeOcB34taWodaNwM2hPAHYErfOoOVyoDiUuwAHiSxUrgG+BGwBrmup8XJthp6JDUFWYBHVYbdT2LL2DrSkrkR/KMsBzOx3ZnYiVlHpuQYoM7OTZlYL/BKYFLOmczCzV4Hjdeo2Br0AZUTva2QF9enNVtJoNaBrKHcjS96DMbMPzezNUK4C9gFXmNk+M2vqm/JpybWAns5iICuR1EHSLuBj4Bdm9nrMkhqiL/AJ8GNJv5L0tKTPxy0qDRXAaEk9JOUTzch6N3JOtvFXwM/jFpEBs0OK6BlJBXGLaYD7gXmSjgA/BP4xXjnnI+lKYAjR1XqrkGsBPSOLgWzBzH5vZoOJZmLXSxoYs6SG6Eh0GbvEzIYAnwJZeY/CzPYRpSx+AbxElHqrbfCkLELS94j0ropbSyMsAa4GBhP5Mv0oVjUN8zfAA2bWG3iAcKWZLUj6AvAscL+Z/V9rjZNrAT0nLQZC6mILMD5eJQ1yFDiachWxjijAZyVmttzMis1sNNHl96G4NWWCpKnAROBOC4nVbMXMfhMmJWeAZUQpz2xlKvCzUF5LFmmV1IkomK8ys5811r455FpAz8SGICuQdFniKQZJnwO+BuyPVVQDmNlHwBFJXwpV44C3Y5TUIJL+IHz9IjAZWB2vosaRNB54CLjVzE7Gracx6lhgTyJKdWUrvwbGhPKfkyX/4CWJ6Gphn5n9a6uPl+WThPMIj07N56wNwb/Eq6h+JBURPTXSgegf5xoz++d4VTWMpMHA00RPuLwLTDOz/41VVBokbQV6AKeBb5vZ5pglnYOk1cBYIpvU3wD/RJTXvRQ4FpqVmdk9sQisQxq9Y4nSLQa8D8y0LPBoSqP1ALCAKHV4CphlZjvj0phA0leArcBe4Eyo/i7R78Ei4DLgBLDLzG5q9ni5FtAdx3Gc+sm1lIvjOI6TBg/ojuM47QQP6I7jOO0ED+iO4zjtBA/ojuM47QQP6E6rIKm68VYX3Of7knrWU//dOvvbWnrs0O8QSU+3Rt8pY4yVNCJlf4Wkv7iA8zdl+Sv6TiviAd1pD5wT0M1sRLqGLTDOolbqO8FYoDn6fwrMahkpTq7hAd1pMyRdLeklSTslbZXUP9R/XdLrwRRsk6Q/DPU9JG0M9f9GPV4+kr4PfC74YK8KddXh61hJv5S0RtJBSd+XdGfwqd8r6erQ7jJJz0oqD9vIesbpAhSZ2e6wP0fSyqDvfUmTJT0e+n0pvO6NpHFB/95gcHVpqH9f0qOS3gzH+gfzpnuAB8LnGRWGHy1pm6R3E7N1SZdLejW0q0hp+zzwzRb4cTm5SNx+wb61zw2orqduM8G3HPgy8HIoF3D2JbfpwI9CeSHwSCjfQvTGYs/GxkrsE812TxB5Ul8KfAA8Go7dB8wP5X8HvhLKXyR6TbvuGF8Fnk3ZnwP8N5Et8iCixdETftzrgduAPCJ30D8N9T8hMmeC6M3LvwvlWcDTKf1+J2WcFUTeJJcQ+Wi/E+r/HvheKHcAuqSccwjoEffvgG9tv3XMMO47TrMIbnMjgLWRvQUQBVmITNb+I3iHdAbeC/WjiXxaMLMXJTXFhqDcwuvqkg4TLYQA0avYXw3lrwGFKbq6SupikX91gsuJ7IVT+bmZnZa0lyiovpTS95VECxi8Z2YHQ/1K4G+JrCvgrJnUzsTnTMMGiwyy3k5cvRD5Gj0TrgQ2mNmulPYfA3/MWYsB5yLBUy5OW3EJcMLMBqds14Rji4AnzexaYCbRzDZBc70pPkspn0nZPwPJCc0lwPAUXVfUCeYANXV0JfsOwfa0mSW0Jvquz+65Pm2/T9HS2GdQGPNVon94HwA/lfStlDZ5Qa9zkeEB3WkTLPKAfk/S7RC50EkaFA53IwpMENmgJngVuDO0v5koNVMfpxM56yayEZid2AkmZXXZB/zJBfa7H7hSUuK8u4hWV2qIKqKlyhpEUh/gYzNbRuTmVxzqBfwRUUrHucjwgO60FvmSjqZs3yYKzn8taTfwFmeXD5xDlIrZCvw2pY9HiW4Ivkm0Huf/pBnrKWBP4qZoE7gXuE7RyjxvE92YPAcz2w90CzdHM8LMTgHTiD5bwm1vaSOnvQBMqnNTtD7GArsk/QqYQuQ0CPBnRC6OObPgh9NyuNui42SIpAeAKjNr1WfRm4OkBcDzlmV2wk7b4DN0x8mcJZybz85GKjyYX7z4DN1xHKed4DN0x3GcdoIHdMdxnHaCB3THcZx2ggd0x3GcdoIHdMdxnHbC/wMMSTWW6+FqMAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ninolearn.plot.evaluation import ACC_skill_comparison_ZC\n",
    "\n",
    "ACC_skill_comparison_ZC(r, rref, lead_times, train_version, test_version, plot_individual = True, plot_avg = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make predictions for the test data set\n",
    "Now we can use the trained models to make predicitons on the test data set to evaluate how good the model perfoms on a data set that it never saw before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-79f7c372ada1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpred_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_std\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "pred_mean, pred_std = model.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ninolearn.learn.fit import cross_hindcast_dem, cross_hindcast\n",
    "# cross_hindcast(model, pipeline, 'DEM')\n",
    "# # cross_hindcast_dem(model, pipeline, 'DEM')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the prediction\n",
    "Let's see how the predicion is looking like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from ninolearn.plot.prediction import plot_prediction\n",
    "import pandas as pd\n",
    "from ninolearn.pathes import plotdir\n",
    "\n",
    "from os.path import join\n",
    "\n",
    "\n",
    "plt.subplots(figsize=(15,3.5))\n",
    "plt.axhspan(-0.5,\n",
    "            -6,\n",
    "            facecolor='blue',\n",
    "            alpha=0.1,zorder=0)\n",
    "\n",
    "plt.axhspan(0.5,\n",
    "            6,\n",
    "            facecolor='red',\n",
    "            alpha=0.1,zorder=0)\n",
    "\n",
    "plt.xlim(testtimey[0], testtimey[-1])\n",
    "plt.ylim(-3,3)\n",
    "\n",
    "# plot the prediction\n",
    "plot_prediction(testtimey, pred_mean, std=pred_std, facecolor='royalblue', line_color='navy')\n",
    "\n",
    "# plot the observation\n",
    "plt.plot(timey, y, \"r\", label = 'observation')\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(join(plotdir, f'predicVSobs_{version}_{lead_time}lead'))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model\n",
    "\n",
    "We can evaluate the model a bit more quantitatively using the loss function that was used to train the model, namely the negative-log-likelihood of the Gaussian and the correlation between the predicted mean and the observed ONI index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ninolearn.plot.evaluation import plot_correlation, plot_confMat, plot_seasonal_skill\n",
    "\n",
    "# loss = model.evaluate(testy, pred_mean, pred_std)\n",
    "# print(f\"Loss (Negative-Log-Likelihood): {loss}\")\n",
    "\n",
    "# # make a plot of the seasonal correaltion\n",
    "# # note: - pd.tseries.offsets.MonthBegin(1) appears to ensure that the correlations are plotted\n",
    "# # agains the correct season\n",
    "# plot_correlation(testy, pred_mean, testtimey - pd.tseries.offsets.MonthBegin(1), title=\"\")\n",
    "\n",
    "# # plot_seasonal_skill(leadtime, r_seas)\n",
    "\n",
    "# # plt.savefig(join(plotdir, f'correlation_{version}_{lead_time}lead'))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_seasonal_skill_ZC(lead_times, r,  vmin=0, vmax=1)\n",
    "plt.contour(np.arange(1,5),lead_times, p, linestyles=['solid', 'dashed', 'dotted'], colors='k')\n",
    "plt.title('Correlation skill')\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
