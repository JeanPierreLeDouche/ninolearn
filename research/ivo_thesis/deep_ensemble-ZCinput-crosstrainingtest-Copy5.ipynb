{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep ensemble for ENSO-forecasting\n",
    "\n",
    "In this tutorial you learn how to use a neural network model called Deep Ensemble (DE) for the ENSO forecasting. This network architecture was initially developed [Lakshminarayanan et al. (2017)](https://papers.nips.cc/paper/7219-simple-and-scalable-predictive-uncertainty-estimation-using-deep-ensembles.pdf). \n",
    "\n",
    "DEs are feed foreword neural networks that predict the mean and the standard deviation of a Gaussian. Hence, their predicion comes with an uncertainty estimation which is a valuable feature for ENSO-forecasting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a data pipe line\n",
    "\n",
    "At first, we define a data pipeline. This is in general quite useful to keep your code clean and also to reuse the pipeline for later purpose.\n",
    "\n",
    "The data pipeline generates returns:\n",
    "\n",
    "1. The feature array\n",
    "\n",
    "2. The label array\n",
    "\n",
    "3. The time  array corresponding to the time of the label\n",
    "\n",
    "NOTE (again): Lead time is defined as the time that passed between the last observed and the first date of the target season. Hence, negative appear, e.g. if you compare the DJF season with the target season JFM, you have a lead time of -2 month (Last observed date: Feburary 28/29, First date of the target season January 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ninolearn.IO.read_processed import data_reader\n",
    "from ninolearn.IO.read_raw import ZC_simple_read\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from ninolearn.learn.fit import n_decades, lead_times, decade_color, decade_name\n",
    "from ninolearn.learn.evaluation import evaluation_correlation, evaluation_decadal_correlation, evaluation_seasonal_correlation, evaluation_decadal_correlation_ZC\n",
    "from ninolearn.learn.fit import cross_hindcast_dem\n",
    "from ninolearn.plot.evaluation import plot_seasonal_skill_ZC\n",
    "import matplotlib.pyplot as plt\n",
    "from ninolearn.learn.fit import cross_training\n",
    "from ninolearn.learn.fit import cross_hindcast_dem\n",
    "from ninolearn.learn.models import DEM\n",
    "\n",
    "oneyear= pd.Timedelta(365, 'D')\n",
    "\n",
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tstart = 1952-04-07 14:17:30 and tend = 1994-08-26 03:33:20 (train)\n",
      "tstart = 1952-04-07 14:17:30 and tend = 1994-08-26 03:33:20 (test)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "train_version = 'dt13nosc'\n",
    "test_version = 'mu28v4'\n",
    "name = 'dem' + '_'+ train_version  + '_' + test_version\n",
    "# leadtime = 12\n",
    "\n",
    "# t_start is defined using a funky timedelta because the starting date of the network analysis data is the last month\n",
    "# of its start year which is 1951-12 therefore the time must start in 1952 with some months added for values lost in \n",
    "# interpolation. TODO: fix this by backwards interpolating the first values of the year and finding out what is happening \n",
    "# with the nms\n",
    "train_times = np.unique(ZC_simple_read(train_version)['time'])\n",
    "test_times = np.unique(ZC_simple_read(test_version)['time'])\n",
    "\n",
    "train_t_start = train_times[0] + pd.Timedelta((2*365 + 90),'D')\n",
    "train_t_end = train_times[-1] - pd.Timedelta(90,'D')\n",
    "\n",
    "test_t_start = test_times[0] + pd.Timedelta((2*365 + 90),'D')\n",
    "test_t_end = test_times[-1] - pd.Timedelta(90,'D')\n",
    "\n",
    "print(f'tstart = {train_t_start} and tend = {train_t_end} (train)')\n",
    "print(f'tstart = {test_t_start} and tend = {test_t_end} (test)')\n",
    "\n",
    "t_start = train_t_start\n",
    "t_end = train_t_end\n",
    "times = train_times\n",
    "\n",
    "if train_t_end < pd.Timestamp('1990-01-01') or test_t_end < pd.Timestamp('1990-01-01'):\n",
    "    raise ValueError('one or both timeseries are too short!')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using dimensions ('lat', 'lon') from data variable temperature as the horizontal dimensions for this dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ivo/anaconda3/envs/ninolearn/lib/python3.6/site-packages/xesmf/frontend.py:524: FutureWarning: ``output_sizes`` should be given in the ``dask_gufunc_kwargs`` parameter. It will be removed as direct parameter in a future version.\n",
      "  keep_attrs=keep_attrs\n",
      "/home/ivo/anaconda3/envs/ninolearn/lib/python3.6/site-packages/xesmf/smm.py:93: UserWarning: Input array is not C_CONTIGUOUS. Will affect performance.\n",
      "  warnings.warn(\"Input array is not C_CONTIGUOUS. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Read sst climatetology\n",
      "using dimensions ('lat', 'lon') from data variable temperature as the horizontal dimensions for this dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ivo/anaconda3/envs/ninolearn/lib/python3.6/site-packages/xesmf/frontend.py:524: FutureWarning: ``output_sizes`` should be given in the ``dask_gufunc_kwargs`` parameter. It will be removed as direct parameter in a future version.\n",
      "  keep_attrs=keep_attrs\n",
      "WARNING:Wrong input for computation of hamming distance.\n",
      "WARNING:Wrong input for computation of corrected hamming distance.\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using dimensions ('lat', 'lon') from data variable thermocline_height as the horizontal dimensions for this dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ivo/anaconda3/envs/ninolearn/lib/python3.6/site-packages/xesmf/frontend.py:524: FutureWarning: ``output_sizes`` should be given in the ``dask_gufunc_kwargs`` parameter. It will be removed as direct parameter in a future version.\n",
      "  keep_attrs=keep_attrs\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:Wrong input for computation of hamming distance.\n",
      "WARNING:Wrong input for computation of corrected hamming distance.\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n"
     ]
    }
   ],
   "source": [
    "from ninolearn.IO.read_raw import ZC_raw, ZC_h, ZC_oni\n",
    "from ninolearn.preprocess.prepare import prep_nms\n",
    "from ninolearn.plot.ZC_dem_plots import nms_plots\n",
    "## read raw ZC data and save to 1x1 grid file in processeddir\n",
    "## also makes field of h and sst\n",
    "ZC_raw(train_version)\n",
    "\n",
    "## calculates monthly averaged (?) fields of thermocline height within region \n",
    "## of interest. cacluate ONI in region of interest. calculate network metrics \n",
    "## from sst (Henk's suggestion) or thermocline height (like Paul)\n",
    "\n",
    "ZC_h(train_version)\n",
    "ZC_oni(train_version)\n",
    "\n",
    "prep_nms(train_version, 0.99, t_start, t_end, variable = 'sst')\n",
    "prep_nms(train_version, 0.99, t_start, t_end, variable = 'h')\n",
    "\n",
    "# make plots\n",
    "# nms_plots(train_version)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using dimensions ('lat', 'lon') from data variable temperature as the horizontal dimensions for this dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ivo/anaconda3/envs/ninolearn/lib/python3.6/site-packages/xesmf/frontend.py:524: FutureWarning: ``output_sizes`` should be given in the ``dask_gufunc_kwargs`` parameter. It will be removed as direct parameter in a future version.\n",
      "  keep_attrs=keep_attrs\n",
      "/home/ivo/anaconda3/envs/ninolearn/lib/python3.6/site-packages/xesmf/smm.py:93: UserWarning: Input array is not C_CONTIGUOUS. Will affect performance.\n",
      "  warnings.warn(\"Input array is not C_CONTIGUOUS. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Read sst climatetology\n",
      "using dimensions ('lat', 'lon') from data variable temperature as the horizontal dimensions for this dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ivo/anaconda3/envs/ninolearn/lib/python3.6/site-packages/xesmf/frontend.py:524: FutureWarning: ``output_sizes`` should be given in the ``dask_gufunc_kwargs`` parameter. It will be removed as direct parameter in a future version.\n",
      "  keep_attrs=keep_attrs\n",
      "WARNING:Wrong input for computation of hamming distance.\n",
      "WARNING:Wrong input for computation of corrected hamming distance.\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n"
     ]
    }
   ],
   "source": [
    "ZC_raw(test_version)\n",
    "ZC_h(test_version)\n",
    "ZC_oni(test_version)\n",
    "prep_nms(test_version, 0.99, t_start, t_end, variable = 'sst')\n",
    "# prep_nms(test_version, 0.99, t_start, t_end, variable = 'h')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "reader = data_reader(startdate=(t_start + pd.Timedelta(365,'D')) , enddate=(t_end - pd.Timedelta(2*365, 'D')) , lon_min = 124, lon_max = 280,\n",
    "                         lat_min = -19, lat_max = 19)\n",
    "\n",
    "oni = reader.read_csv(('oni_ZC_' +train_version))\n",
    "h = reader.read_csv(('h_mean_ZC_' + train_version))\n",
    "\n",
    "nms_sst = reader.read_statistic('network_metrics', variable='sst', dataset=('ZC_25x25_' + train_version), processed=\"anom\")\n",
    "nms_h = reader.read_statistic('network_metrics', variable='h', dataset=('ZC_25x25_' + train_version), processed=\"anom\")\n",
    "\n",
    "c2_sst = nms_sst['fraction_clusters_size_2']\n",
    "H_sst = nms_sst['corrected_hamming_distance']\n",
    "\n",
    "c2_h = nms_h['fraction_clusters_size_2']\n",
    "H_h = nms_h['corrected_hamming_distance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All datasets are of equal length\n"
     ]
    }
   ],
   "source": [
    "c2 = c2_h\n",
    "H = H_h\n",
    "\n",
    "if h.shape[0] + c2.shape[0] - H.shape[0] - oni.shape[0] == 0:\n",
    "    print('All datasets are of equal length')\n",
    "else:\n",
    "    print('warning: datasets not of equal size')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from ninolearn.utils import include_time_lag\n",
    "from ninolearn.IO.read_processed import data_reader\n",
    "\n",
    "version = train_version\n",
    "\n",
    "def train_pipeline(lead_time):\n",
    "    version = train_version\n",
    "    \"\"\"\n",
    "    Data pipeline for the processing of the data before the Deep Ensemble\n",
    "    is trained.\n",
    "\n",
    "    :type lead_time: int\n",
    "    :param lead_time: The lead time in month.\n",
    "\n",
    "    :returns: The feature \"X\" (at observation time), the label \"y\" (at lead\n",
    "    time), the target season \"timey\" (least month)\n",
    "    \"\"\"\n",
    "    timelag=False\n",
    "#     reader = data_reader(startdate='1952-01', enddate='1992-12', lon_min = 124, lon_max = 280,\n",
    "#                          lat_min = -19, lat_max = 19)\n",
    "    reader = data_reader(startdate=(t_start + oneyear), enddate=(t_end - 2*oneyear), lon_min = 124, lon_max = 280,\n",
    "                         lat_min = -19, lat_max = 19)\n",
    "\n",
    "    # indeces\n",
    "    oni = reader.read_csv(('oni_ZC_' +version))\n",
    "    h = reader.read_csv(('h_mean_ZC_' + version))\n",
    "    #IOD unavailable in ZC87 model \n",
    "    \n",
    "    # seasonal cycle\n",
    "    sc = np.cos(np.arange(len(oni))/12*2*np.pi)\n",
    "\n",
    "    # network metrics\n",
    "#     network_ssh = reader.read_statistic('network_metrics', variable='sst', dataset=('ZC_25x25_'+version), processed=\"anom\")\n",
    "#     c2 = network_ssh['fraction_clusters_size_2']\n",
    "#     H = network_ssh['corrected_hamming_distance']\n",
    "\n",
    "    nms_sst = reader.read_statistic('network_metrics', variable='sst', dataset=('ZC_25x25_' + train_version), processed=\"anom\")\n",
    "    nms_h = reader.read_statistic('network_metrics', variable='h', dataset=('ZC_25x25_' + train_version), processed=\"anom\")\n",
    "\n",
    "    c2_sst = nms_sst['fraction_clusters_size_2']\n",
    "    H_sst = nms_sst['corrected_hamming_distance']\n",
    "\n",
    "    c2_h = nms_h['fraction_clusters_size_2']\n",
    "    H_h = nms_h['corrected_hamming_distance']\n",
    "\n",
    "    # time lag\n",
    "    time_lag = 12\n",
    "\n",
    "    # shift such that lead time corresponds to the definition of lead time\n",
    "    shift = 3\n",
    "\n",
    "    # process features\n",
    "    feature_unscaled = np.stack((oni, h, sc,\n",
    "                                 c2_sst, H_sst, c2_h, c2_sst ), axis=1)\n",
    "\n",
    "    # scale each feature\n",
    "    scalerX = StandardScaler()\n",
    "    Xorg = scalerX.fit_transform(feature_unscaled)\n",
    "\n",
    "    # set nans to 0.\n",
    "    Xorg = np.nan_to_num(Xorg)\n",
    "\n",
    "    # arange the feature array\n",
    "    X = Xorg[:-lead_time-shift,:] # this chops of a bit at the end because matching labels will be offset by \n",
    "    # this amount. e.g. if our data runs until 2012 we need to remove X values for 2012 because we will use december 2011\n",
    "    # to predict december 2012 \n",
    "    \n",
    "#     X = include_time_lag(X, max_lag=time_lag)\n",
    "    X = include_time_lag(X, n_lags =time_lag)  # staggers the data with 1 month shifts so at each moment of input also\n",
    "    # nlags amount of months before is available to the AI\n",
    "        \n",
    "    # arange label\n",
    "    yorg = oni.values\n",
    "    y = yorg[lead_time + time_lag + shift:] # labels offset by lead_time to predict into the future and time_lag \n",
    "    # because the include_time_lag function shifts X values forward by an amount n_lags=time_lag\n",
    "    \n",
    "    # get the time axis of the label\n",
    "    timey = oni.index[lead_time + time_lag + shift:]\n",
    "\n",
    "    if timelag == False:\n",
    "        X = Xorg\n",
    "        y = yorg\n",
    "        timey = oni.index\n",
    "        \n",
    "    return X, y, timey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = test_version\n",
    "\n",
    "def test_pipeline(lead_time):\n",
    "    version = test_version\n",
    "\n",
    "    \"\"\"\n",
    "    Data pipeline for the processing of the data before the Deep Ensemble\n",
    "    is trained.\n",
    "\n",
    "    :type lead_time: int\n",
    "    :param lead_time: The lead time in month.\n",
    "\n",
    "    :returns: The feature \"X\" (at observation time), the label \"y\" (at lead\n",
    "    time), the target season \"timey\" (least month)\n",
    "    \"\"\"\n",
    "    timelag=False\n",
    "#     reader = data_reader(startdate='1952-01', enddate='1992-12', lon_min = 124, lon_max = 280,\n",
    "#                          lat_min = -19, lat_max = 19)\n",
    "    reader = data_reader(startdate=(t_start + oneyear), enddate=(t_end - 2*oneyear), lon_min = 124, lon_max = 280,\n",
    "                         lat_min = -19, lat_max = 19)\n",
    "\n",
    "    # indeces\n",
    "    oni = reader.read_csv(('oni_ZC_' +version))\n",
    "    h = reader.read_csv(('h_mean_ZC_' + version))\n",
    "    #IOD unavailable in ZC87 model \n",
    "    \n",
    "    # seasonal cycle\n",
    "    sc = np.cos(np.arange(len(oni))/12*2*np.pi)\n",
    "\n",
    "    # network metrics\n",
    "    network_ssh = reader.read_statistic('network_metrics', variable='sst', dataset=('ZC_25x25_'+version), processed=\"anom\")\n",
    "    c2 = network_ssh['fraction_clusters_size_2']\n",
    "    H = network_ssh['corrected_hamming_distance']\n",
    "\n",
    "    # time lag\n",
    "    time_lag = 12\n",
    "\n",
    "    # shift such that lead time corresponds to the definition of lead time\n",
    "    shift = 3\n",
    "\n",
    "    # process features\n",
    "    feature_unscaled = np.stack((oni, h,\n",
    "                                 c2, H, sc), axis=1)\n",
    "\n",
    "    # scale each feature\n",
    "    scalerX = StandardScaler()\n",
    "    Xorg = scalerX.fit_transform(feature_unscaled)\n",
    "\n",
    "    # set nans to 0.\n",
    "    Xorg = np.nan_to_num(Xorg)\n",
    "\n",
    "    # arange the feature array\n",
    "    X = Xorg[:-lead_time-shift,:] # this chops of a bit at the end because matching labels will be offset by \n",
    "    # this amount. e.g. if our data runs until 2012 we need to remove X values for 2012 because we will use december 2011\n",
    "    # to predict december 2012 \n",
    "    \n",
    "#     X = include_time_lag(X, max_lag=time_lag)\n",
    "    X = include_time_lag(X, n_lags =time_lag)  # staggers the data with 1 month shifts so at each moment of input also\n",
    "    # nlags amount of months before is available to the AI\n",
    "        \n",
    "    # arange label\n",
    "    yorg = oni.values\n",
    "    y = yorg[lead_time + time_lag + shift:] # labels offset by lead_time to predict into the future and time_lag \n",
    "    # because the include_time_lag function shifts X values forward by an amount n_lags=time_lag\n",
    "    \n",
    "    # get the time axis of the label\n",
    "    timey = oni.index[lead_time + time_lag + shift:]\n",
    "\n",
    "    if timelag == False:\n",
    "        X = Xorg\n",
    "        y = yorg\n",
    "        timey = oni.index\n",
    "        \n",
    "    return X, y, timey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0, _, _, x3, _, _= *train_pipeline(0), *train_pipeline(3)\n",
    "if x0.shape != x3.shape:\n",
    "    print(\"WARNING: shape mismatch between inputs for different lead times (traindata)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0, _, _, x3, _, _= *test_pipeline(0), *test_pipeline(3)\n",
    "if x0.shape != x3.shape:\n",
    "    print(\"WARNING: shape mismatch between inputs for different lead times (testdata)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the data set\n",
    "\n",
    "For the training and testing of machine learning models it is crucial to split the data set into:\n",
    "\n",
    "1. __Train data set__ which is used to train the weights of the neural network\n",
    "\n",
    "2. __Validation data set__ which is used to check for overfitting (e.g. when using early stopping) and to optimize the hyperparameters \n",
    "\n",
    "3. __Test data set__ which is used to to evaluate the trained model. \n",
    "\n",
    "__NOTE:__ It is important to understand that hyperparamters must be tuned so that the result is best for the Validation data set and __not__ for the test data set. Otherwise you can not rule out the case that the specific hyperparameter setting just works good for the specific test data set but is not generally a good hyperparameter setting.\n",
    "\n",
    "In the following cell the train and the validation data set are still one data set, because this array will be later splitted into two arrays when th model is fitted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import keras.backend as K\n",
    "# from ninolearn.learn.models.dem import DEM\n",
    "\n",
    "# # clear memory from previous sessions\n",
    "# K.clear_session()\n",
    "\n",
    "# # define the lead time\n",
    "# lead_time = leadtime\n",
    "\n",
    "# # get the features (X), the label (y) and \n",
    "# # the time axis of the label (timey)\n",
    "# X, y, timey = pipeline(lead_time)\n",
    "\n",
    "# # split the data set into \n",
    "# # test_indeces = (timey>='1987-01-01') & (timey<='1993-12-01')\n",
    "# test_indeces = (timey>=t_end - pd.Timedelta(5*365, 'D')) & (timey<=t_end)\n",
    "\n",
    "# train_val_indeces = np.invert(test_indeces)\n",
    "\n",
    "# train_val_X, train_val_y, train_val_timey = X[train_val_indeces,:], y[train_val_indeces], timey[train_val_indeces]\n",
    "# testX, testy, testtimey = X[test_indeces,:], y[test_indeces], timey[test_indeces]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(y.shape, X.shape, timey.shape)\n",
    "# print('shapes of the data, labels and time axis is predictable, since there are now 4 features and 12 lags \\\n",
    "#     making for 48 columns. The labels are offset from the input data by the lead time ')\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the model\n",
    "\n",
    "Now it is time to train the model! For this a random search is used for all keyword arguments that are passed in a *list* to the DEM.set_parameters() method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # initiated an instance of the DEM (Deep Ensemble Model) class\n",
    "# model = DEM()\n",
    "\n",
    "# # Set parameters\n",
    "# model.set_hyperparameters(searchtype='linear', layers=1, neurons=16, dropout=[0.1, 0.5], noise_in=[0.1,0.5], noise_sigma=[0.1,0.5],\n",
    "#                      noise_mu=[0.1,0.5], l1_hidden=[0.0, 0.2], l2_hidden=[0., 0.2],\n",
    "#                      l1_mu=[0.0, 0.2], l2_mu=[0.0, 0.2], l1_sigma=[0.0, 0.2],\n",
    "#                      l2_sigma=[0.0, 0.2], lr=[0.0001,0.01], batch_size=100, epochs=500, n_segments=5,\n",
    "#                      n_members_segment=1, patience=30, verbose=0, pdf='normal', activation = 'relu')\n",
    "\n",
    "# # Use a random search to find the optimal hyperparameters\n",
    "\n",
    "# model.fit_RandomizedSearch(train_val_X, train_val_y, train_val_timey, n_iter=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##################################################################\n",
      "Lead time: 0 month\n",
      "##################################################################\n",
      "\n",
      "Test period: 1953-01-01 till 1961-12-01\n",
      "--------------------------------------\n",
      "Search iteration Nr 1/1\n",
      "build\n",
      "Train member Nr 1/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00130: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.8499 - nll_gaussian: 0.4870\n",
      "build\n",
      "Train member Nr 2/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00368: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2961 - nll_gaussian: 0.0049\n",
      "build\n",
      "Train member Nr 3/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00291: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2663 - nll_gaussian: -0.0989\n",
      "build\n",
      "Train member Nr 4/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00172: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.9293 - nll_gaussian: 0.5276\n",
      "build\n",
      "Train member Nr 5/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00053: early stopping\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.5410 - nll_gaussian: 0.1699\n",
      "Loss: 0.21811389429494737\n",
      "Computation time: 92.2s\n",
      "New best hyperparameters\n",
      "Mean loss: 0.21811389429494737\n",
      "{'layers': 1, 'neurons': 16, 'dropout': 0.21277647438831668, 'noise_in': 0.13127673749215438, 'noise_mu': 0.29607409992774136, 'noise_sigma': 0.21756010150296468, 'noise_alpha': 0.0, 'l1_hidden': 0.12092587943075904, 'l2_hidden': 0.10103913661084059, 'l1_mu': 0.08524527918950148, 'l2_mu': 0.13390107642999893, 'l1_sigma': 0.0716656431589968, 'l2_sigma': 0.05207334010957254, 'l1_alpha': 0.0, 'l2_alpha': 0.0, 'batch_size': 100, 'n_segments': 5, 'n_members_segment': 1, 'lr': 0.0002736108099660439, 'patience': 30, 'epochs': 500, 'verbose': 0, 'pdf': 'normal', 'activation': 'relu', 'name': 'dem_dt13nosc_mu28v4', 'n_members': 5}\n",
      "Test period: 1962-01-01 till 1971-12-01\n",
      "--------------------------------------\n",
      "Search iteration Nr 1/1\n",
      "build\n",
      "Train member Nr 1/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00161: early stopping\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7940 - nll_gaussian: 0.4269\n",
      "build\n",
      "Train member Nr 2/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00089: early stopping\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5239 - nll_gaussian: 0.0954\n",
      "build\n",
      "Train member Nr 3/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00192: early stopping\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.3501 - nll_gaussian: 0.3375\n",
      "build\n",
      "Train member Nr 4/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00106: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.9693 - nll_gaussian: 0.6766\n",
      "build\n",
      "Train member Nr 5/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00186: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6031 - nll_gaussian: 0.1231\n",
      "Loss: 0.33189324140548704\n",
      "Computation time: 71.8s\n",
      "New best hyperparameters\n",
      "Mean loss: 0.33189324140548704\n",
      "{'layers': 1, 'neurons': 16, 'dropout': 0.1786811549368601, 'noise_in': 0.1637713237992683, 'noise_mu': 0.3775763587312747, 'noise_sigma': 0.3284873973008169, 'noise_alpha': 0.0, 'l1_hidden': 0.06087965715413839, 'l2_hidden': 0.09550532524011013, 'l1_mu': 0.06886264324455342, 'l2_mu': 0.1732554836595468, 'l1_sigma': 0.19483488153702275, 'l2_sigma': 0.0857035814192889, 'l1_alpha': 0.0, 'l2_alpha': 0.0, 'batch_size': 100, 'n_segments': 5, 'n_members_segment': 1, 'lr': 0.0004692559739587163, 'patience': 30, 'epochs': 500, 'verbose': 0, 'pdf': 'normal', 'activation': 'relu', 'name': 'dem_dt13nosc_mu28v4', 'n_members': 5}\n",
      "Test period: 1972-01-01 till 1981-12-01\n",
      "--------------------------------------\n",
      "Search iteration Nr 1/1\n",
      "build\n",
      "Train member Nr 1/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00059: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.0187 - nll_gaussian: 0.3479\n",
      "build\n",
      "Train member Nr 2/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00153: early stopping\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.5537 - nll_gaussian: 0.3495\n",
      "build\n",
      "Train member Nr 3/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00031: early stopping\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4786 - nll_gaussian: 0.1919\n",
      "build\n",
      "Train member Nr 4/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00167: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.3025 - nll_gaussian: 0.3775\n",
      "build\n",
      "Train member Nr 5/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00044: early stopping\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6207 - nll_gaussian: 0.0975\n",
      "Loss: 0.27286399304866793\n",
      "Computation time: 48.6s\n",
      "New best hyperparameters\n",
      "Mean loss: 0.27286399304866793\n",
      "{'layers': 1, 'neurons': 16, 'dropout': 0.246578901074862, 'noise_in': 0.10833028069235003, 'noise_mu': 0.3264971583652595, 'noise_sigma': 0.30823929333573863, 'noise_alpha': 0.0, 'l1_hidden': 0.07606811833998287, 'l2_hidden': 0.012803291625120884, 'l1_mu': 0.12473736934474303, 'l2_mu': 0.04614808795192907, 'l1_sigma': 0.1940891681139105, 'l2_sigma': 0.19145316408966156, 'l1_alpha': 0.0, 'l2_alpha': 0.0, 'batch_size': 100, 'n_segments': 5, 'n_members_segment': 1, 'lr': 0.0037121386982803444, 'patience': 30, 'epochs': 500, 'verbose': 0, 'pdf': 'normal', 'activation': 'relu', 'name': 'dem_dt13nosc_mu28v4', 'n_members': 5}\n",
      "Test period: 1982-01-01 till 1991-12-01\n",
      "--------------------------------------\n",
      "Search iteration Nr 1/1\n",
      "build\n",
      "Train member Nr 1/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00060: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4363 - nll_gaussian: 0.3911\n",
      "build\n",
      "Train member Nr 2/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00094: early stopping\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5800 - nll_gaussian: 0.5693\n",
      "build\n",
      "Train member Nr 3/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00033: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2849 - nll_gaussian: 0.1912\n",
      "build\n",
      "Train member Nr 4/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00031: early stopping\n",
      "3/3 [==============================] - 0s 4ms/step - loss: -0.0156 - nll_gaussian: -0.1577\n",
      "build\n",
      "Train member Nr 5/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00031: early stopping\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2806 - nll_gaussian: 0.0542\n",
      "Loss: 0.2096203677356243\n",
      "Computation time: 29.3s\n",
      "New best hyperparameters\n",
      "Mean loss: 0.2096203677356243\n",
      "{'layers': 1, 'neurons': 16, 'dropout': 0.17389211363230386, 'noise_in': 0.34253392416715855, 'noise_mu': 0.424114651304177, 'noise_sigma': 0.10035467999509776, 'noise_alpha': 0.0, 'l1_hidden': 0.09372539363197058, 'l2_hidden': 0.1924789809138455, 'l1_mu': 0.1091624189412007, 'l2_mu': 0.1327522517663214, 'l1_sigma': 0.06862314571892565, 'l2_sigma': 0.09188358821755271, 'l1_alpha': 0.0, 'l2_alpha': 0.0, 'batch_size': 100, 'n_segments': 5, 'n_members_segment': 1, 'lr': 0.008782149145403786, 'patience': 30, 'epochs': 500, 'verbose': 0, 'pdf': 'normal', 'activation': 'relu', 'name': 'dem_dt13nosc_mu28v4', 'n_members': 5}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##################################################################\n",
      "Lead time: 3 month\n",
      "##################################################################\n",
      "\n",
      "Test period: 1953-01-01 till 1961-12-01\n",
      "--------------------------------------\n",
      "Search iteration Nr 1/1\n",
      "build\n",
      "Train member Nr 1/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00084: early stopping\n",
      "3/3 [==============================] - 0s 4ms/step - loss: -0.0608 - nll_gaussian: -0.2732\n",
      "build\n",
      "Train member Nr 2/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00070: early stopping\n",
      "3/3 [==============================] - 0s 4ms/step - loss: -0.1616 - nll_gaussian: -0.3829\n",
      "build\n",
      "Train member Nr 3/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00110: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -0.1856 - nll_gaussian: -0.4162\n",
      "build\n",
      "Train member Nr 4/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00094: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0813 - nll_gaussian: -0.1348\n",
      "build\n",
      "Train member Nr 5/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00224: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -0.0309 - nll_gaussian: -0.2224\n",
      "Loss: -0.28590668439865113\n",
      "Computation time: 58.6s\n",
      "New best hyperparameters\n",
      "Mean loss: -0.28590668439865113\n",
      "{'layers': 1, 'neurons': 16, 'dropout': 0.4466704391917439, 'noise_in': 0.22700734966018268, 'noise_mu': 0.42370082305492585, 'noise_sigma': 0.10564624901172803, 'noise_alpha': 0.0, 'l1_hidden': 0.009788071484833849, 'l2_hidden': 0.015295934892364183, 'l1_mu': 0.11294906818327217, 'l2_mu': 0.19904507804706742, 'l1_sigma': 0.01773840983375623, 'l2_sigma': 0.0348246501207228, 'l1_alpha': 0.0, 'l2_alpha': 0.0, 'batch_size': 100, 'n_segments': 5, 'n_members_segment': 1, 'lr': 0.006010052338579382, 'patience': 30, 'epochs': 500, 'verbose': 0, 'pdf': 'normal', 'activation': 'relu', 'name': 'dem_dt13nosc_mu28v4', 'n_members': 5}\n",
      "Test period: 1962-01-01 till 1971-12-01\n",
      "--------------------------------------\n",
      "Search iteration Nr 1/1\n",
      "build\n",
      "Train member Nr 1/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00038: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.9977 - nll_gaussian: 0.4521\n",
      "build\n",
      "Train member Nr 2/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00052: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.7481 - nll_gaussian: 0.0945\n",
      "build\n",
      "Train member Nr 3/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00064: early stopping\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7864 - nll_gaussian: 0.3735\n",
      "build\n",
      "Train member Nr 4/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00031: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.1496 - nll_gaussian: 0.6829\n",
      "build\n",
      "Train member Nr 5/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00044: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.8121 - nll_gaussian: 0.1072\n",
      "Loss: 0.3420442551374435\n",
      "Computation time: 28.8s\n",
      "New best hyperparameters\n",
      "Mean loss: 0.3420442551374435\n",
      "{'layers': 1, 'neurons': 16, 'dropout': 0.2334077912892068, 'noise_in': 0.4432001768418615, 'noise_mu': 0.1459660369497494, 'noise_sigma': 0.3638089650460371, 'noise_alpha': 0.0, 'l1_hidden': 0.15116256529632807, 'l2_hidden': 0.19035727248901002, 'l1_mu': 0.05237146811786202, 'l2_mu': 0.0487201034190744, 'l1_sigma': 0.11100222635737014, 'l2_sigma': 0.18729984898700047, 'l1_alpha': 0.0, 'l2_alpha': 0.0, 'batch_size': 100, 'n_segments': 5, 'n_members_segment': 1, 'lr': 0.0027442368925368436, 'patience': 30, 'epochs': 500, 'verbose': 0, 'pdf': 'normal', 'activation': 'relu', 'name': 'dem_dt13nosc_mu28v4', 'n_members': 5}\n",
      "Test period: 1972-01-01 till 1981-12-01\n",
      "--------------------------------------\n",
      "Search iteration Nr 1/1\n",
      "build\n",
      "Train member Nr 1/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00141: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.3962 - nll_gaussian: -0.1548\n",
      "build\n",
      "Train member Nr 2/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00095: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.7196 - nll_gaussian: -0.3858\n",
      "build\n",
      "Train member Nr 3/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00055: early stopping\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2808 - nll_gaussian: -0.2735\n",
      "build\n",
      "Train member Nr 4/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00067: early stopping\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.2806 - nll_gaussian: -0.4961\n",
      "build\n",
      "Train member Nr 5/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00085: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.5486 - nll_gaussian: -0.6513\n",
      "Loss: -0.3922947108745575\n",
      "Computation time: 49.6s\n",
      "New best hyperparameters\n",
      "Mean loss: -0.3922947108745575\n",
      "{'layers': 1, 'neurons': 16, 'dropout': 0.24253167532705247, 'noise_in': 0.11534634747013169, 'noise_mu': 0.33072221963894244, 'noise_sigma': 0.20703109761064656, 'noise_alpha': 0.0, 'l1_hidden': 0.10050532554243251, 'l2_hidden': 0.08547854439731915, 'l1_mu': 0.003428355820495477, 'l2_mu': 0.11589022226224387, 'l1_sigma': 0.026955871622017537, 'l2_sigma': 0.17167494901099511, 'l1_alpha': 0.0, 'l2_alpha': 0.0, 'batch_size': 100, 'n_segments': 5, 'n_members_segment': 1, 'lr': 0.00950326098068965, 'patience': 30, 'epochs': 500, 'verbose': 0, 'pdf': 'normal', 'activation': 'relu', 'name': 'dem_dt13nosc_mu28v4', 'n_members': 5}\n",
      "Test period: 1982-01-01 till 1991-12-01\n",
      "--------------------------------------\n",
      "Search iteration Nr 1/1\n",
      "build\n",
      "Train member Nr 1/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00078: early stopping\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.9873 - nll_gaussian: 0.4093\n",
      "build\n",
      "Train member Nr 2/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00096: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.1622 - nll_gaussian: 0.5490\n",
      "build\n",
      "Train member Nr 3/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00124: early stopping\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.8940 - nll_gaussian: 0.1156\n",
      "build\n",
      "Train member Nr 4/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00050: early stopping\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3204 - nll_gaussian: -0.1889\n",
      "build\n",
      "Train member Nr 5/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00151: early stopping\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.1481 - nll_gaussian: -0.0472\n",
      "Loss: 0.16757532805204392\n",
      "Computation time: 55.4s\n",
      "New best hyperparameters\n",
      "Mean loss: 0.16757532805204392\n",
      "{'layers': 1, 'neurons': 16, 'dropout': 0.11184976944046734, 'noise_in': 0.30176110088685393, 'noise_mu': 0.30225075727236367, 'noise_sigma': 0.343212188297943, 'noise_alpha': 0.0, 'l1_hidden': 0.07915613609692228, 'l2_hidden': 0.024910280615722914, 'l1_mu': 0.05695557246765264, 'l2_mu': 0.12220367690883116, 'l1_sigma': 0.0960195394607569, 'l2_sigma': 0.016714225710074814, 'l1_alpha': 0.0, 'l2_alpha': 0.0, 'batch_size': 100, 'n_segments': 5, 'n_members_segment': 1, 'lr': 0.005701856507969596, 'patience': 30, 'epochs': 500, 'verbose': 0, 'pdf': 'normal', 'activation': 'relu', 'name': 'dem_dt13nosc_mu28v4', 'n_members': 5}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##################################################################\n",
      "Lead time: 6 month\n",
      "##################################################################\n",
      "\n",
      "Test period: 1953-01-01 till 1961-12-01\n",
      "--------------------------------------\n",
      "Search iteration Nr 1/1\n",
      "build\n",
      "Train member Nr 1/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00081: early stopping\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.0275 - nll_gaussian: 0.1572\n",
      "build\n",
      "Train member Nr 2/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00047: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.0666 - nll_gaussian: -0.0225\n",
      "build\n",
      "Train member Nr 3/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00054: early stopping\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 1.1550 - nll_gaussian: -0.1993\n",
      "build\n",
      "Train member Nr 4/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00081: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 2.3059 - nll_gaussian: 0.2105\n",
      "build\n",
      "Train member Nr 5/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00045: early stopping\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 1.3370 - nll_gaussian: 0.0219\n",
      "Loss: 0.03356287069618702\n",
      "Computation time: 35.2s\n",
      "New best hyperparameters\n",
      "Mean loss: 0.03356287069618702\n",
      "{'layers': 1, 'neurons': 16, 'dropout': 0.3113365496846572, 'noise_in': 0.1725117803867598, 'noise_mu': 0.43082512945589924, 'noise_sigma': 0.3627075960139122, 'noise_alpha': 0.0, 'l1_hidden': 0.117685896028242, 'l2_hidden': 0.07212708714606744, 'l1_mu': 0.1630559102868259, 'l2_mu': 0.06520291126842863, 'l1_sigma': 0.13163646272473237, 'l2_sigma': 0.1410524569087721, 'l1_alpha': 0.0, 'l2_alpha': 0.0, 'batch_size': 100, 'n_segments': 5, 'n_members_segment': 1, 'lr': 0.009887788763707554, 'patience': 30, 'epochs': 500, 'verbose': 0, 'pdf': 'normal', 'activation': 'relu', 'name': 'dem_dt13nosc_mu28v4', 'n_members': 5}\n",
      "Test period: 1962-01-01 till 1971-12-01\n",
      "--------------------------------------\n",
      "Search iteration Nr 1/1\n",
      "build\n",
      "Train member Nr 1/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00131: early stopping\n",
      "3/3 [==============================] - 0s 4ms/step - loss: -0.1484 - nll_gaussian: -0.5505\n",
      "build\n",
      "Train member Nr 2/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00063: early stopping\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -0.0601 - nll_gaussian: -0.3194\n",
      "build\n",
      "Train member Nr 3/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00060: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -0.0959 - nll_gaussian: -0.3260\n",
      "build\n",
      "Train member Nr 4/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00124: early stopping\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -0.0594 - nll_gaussian: -0.4896\n",
      "build\n",
      "Train member Nr 5/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00110: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -0.1373 - nll_gaussian: -0.3798\n",
      "Loss: -0.4130756139755249\n",
      "Computation time: 51.8s\n",
      "New best hyperparameters\n",
      "Mean loss: -0.4130756139755249\n",
      "{'layers': 1, 'neurons': 16, 'dropout': 0.19445154263134953, 'noise_in': 0.3507824168338177, 'noise_mu': 0.2697384397594009, 'noise_sigma': 0.17725981678823768, 'noise_alpha': 0.0, 'l1_hidden': 0.0059970165677634135, 'l2_hidden': 0.18768515550803702, 'l1_mu': 0.00056028309905094, 'l2_mu': 0.1382211164091721, 'l1_sigma': 0.06332970651431967, 'l2_sigma': 0.025690949605014193, 'l1_alpha': 0.0, 'l2_alpha': 0.0, 'batch_size': 100, 'n_segments': 5, 'n_members_segment': 1, 'lr': 0.0038621274337978214, 'patience': 30, 'epochs': 500, 'verbose': 0, 'pdf': 'normal', 'activation': 'relu', 'name': 'dem_dt13nosc_mu28v4', 'n_members': 5}\n",
      "Test period: 1972-01-01 till 1981-12-01\n",
      "--------------------------------------\n",
      "Search iteration Nr 1/1\n",
      "build\n",
      "Train member Nr 1/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00031: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6700 - nll_gaussian: 0.4638\n",
      "build\n",
      "Train member Nr 2/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00039: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.8682 - nll_gaussian: 0.6962\n",
      "build\n",
      "Train member Nr 3/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00220: early stopping\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.3505 - nll_gaussian: 0.1857\n",
      "build\n",
      "Train member Nr 4/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00039: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.7171 - nll_gaussian: 0.5977\n",
      "build\n",
      "Train member Nr 5/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00085: early stopping\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4162 - nll_gaussian: 0.1199\n",
      "Loss: 0.4126469776034355\n",
      "Computation time: 44.1s\n",
      "New best hyperparameters\n",
      "Mean loss: 0.4126469776034355\n",
      "{'layers': 1, 'neurons': 16, 'dropout': 0.22117447450449537, 'noise_in': 0.30149730104813566, 'noise_mu': 0.3710719435719153, 'noise_sigma': 0.47116437667940125, 'noise_alpha': 0.0, 'l1_hidden': 0.007473593632371345, 'l2_hidden': 0.07662406398525086, 'l1_mu': 0.13428716989735678, 'l2_mu': 0.10935583378722245, 'l1_sigma': 0.16656265365285378, 'l2_sigma': 0.03150397578904984, 'l1_alpha': 0.0, 'l2_alpha': 0.0, 'batch_size': 100, 'n_segments': 5, 'n_members_segment': 1, 'lr': 0.00036235142862889997, 'patience': 30, 'epochs': 500, 'verbose': 0, 'pdf': 'normal', 'activation': 'relu', 'name': 'dem_dt13nosc_mu28v4', 'n_members': 5}\n",
      "Test period: 1982-01-01 till 1991-12-01\n",
      "--------------------------------------\n",
      "Search iteration Nr 1/1\n",
      "build\n",
      "Train member Nr 1/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00047: early stopping\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.4361 - nll_gaussian: 0.3927\n",
      "build\n",
      "Train member Nr 2/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00065: early stopping\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5761 - nll_gaussian: 0.5695\n",
      "build\n",
      "Train member Nr 3/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00101: early stopping\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0274 - nll_gaussian: -0.5318\n",
      "build\n",
      "Train member Nr 4/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00031: early stopping\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -0.0531 - nll_gaussian: -0.1613\n",
      "build\n",
      "Train member Nr 5/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00033: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2188 - nll_gaussian: 0.0604\n",
      "Loss: 0.06590396165847778\n",
      "Computation time: 30.8s\n",
      "New best hyperparameters\n",
      "Mean loss: 0.06590396165847778\n",
      "{'layers': 1, 'neurons': 16, 'dropout': 0.3411205660204121, 'noise_in': 0.11041602051825761, 'noise_mu': 0.3105940431754516, 'noise_sigma': 0.1519689336882422, 'noise_alpha': 0.0, 'l1_hidden': 0.03689950985219881, 'l2_hidden': 0.03397508886165292, 'l1_mu': 0.07507093441944171, 'l2_mu': 0.13930426649574237, 'l1_sigma': 0.15694533299626348, 'l2_sigma': 0.00978859726659085, 'l1_alpha': 0.0, 'l2_alpha': 0.0, 'batch_size': 100, 'n_segments': 5, 'n_members_segment': 1, 'lr': 0.008339259232933511, 'patience': 30, 'epochs': 500, 'verbose': 0, 'pdf': 'normal', 'activation': 'relu', 'name': 'dem_dt13nosc_mu28v4', 'n_members': 5}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##################################################################\n",
      "Lead time: 9 month\n",
      "##################################################################\n",
      "\n",
      "Test period: 1953-01-01 till 1961-12-01\n",
      "--------------------------------------\n",
      "Search iteration Nr 1/1\n",
      "build\n",
      "Train member Nr 1/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00125: early stopping\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.4864 - nll_gaussian: 0.4000\n",
      "build\n",
      "Train member Nr 2/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00031: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2974 - nll_gaussian: 0.0063\n",
      "build\n",
      "Train member Nr 3/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00031: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.1930 - nll_gaussian: -0.0944\n",
      "build\n",
      "Train member Nr 4/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00100: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6010 - nll_gaussian: 0.4535\n",
      "build\n",
      "Train member Nr 5/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00044: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.3062 - nll_gaussian: 0.1779\n",
      "Loss: 0.18865494029596447\n",
      "Computation time: 36.4s\n",
      "New best hyperparameters\n",
      "Mean loss: 0.18865494029596447\n",
      "{'layers': 1, 'neurons': 16, 'dropout': 0.28358323998058976, 'noise_in': 0.3882787007739624, 'noise_mu': 0.20375510722027254, 'noise_sigma': 0.16299714949919702, 'noise_alpha': 0.0, 'l1_hidden': 0.17358515626371698, 'l2_hidden': 0.02589932472554011, 'l1_mu': 0.026887441571574546, 'l2_mu': 0.00756458814539791, 'l1_sigma': 0.15624690876049918, 'l2_sigma': 0.19543225157929278, 'l1_alpha': 0.0, 'l2_alpha': 0.0, 'batch_size': 100, 'n_segments': 5, 'n_members_segment': 1, 'lr': 0.005362611484942837, 'patience': 30, 'epochs': 500, 'verbose': 0, 'pdf': 'normal', 'activation': 'relu', 'name': 'dem_dt13nosc_mu28v4', 'n_members': 5}\n",
      "Test period: 1962-01-01 till 1971-12-01\n",
      "--------------------------------------\n",
      "Search iteration Nr 1/1\n",
      "build\n",
      "Train member Nr 1/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00099: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.7856 - nll_gaussian: 0.4434\n",
      "build\n",
      "Train member Nr 2/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00037: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4644 - nll_gaussian: 0.1027\n",
      "build\n",
      "Train member Nr 3/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00068: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.3077 - nll_gaussian: 0.3310\n",
      "build\n",
      "Train member Nr 4/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00044: early stopping\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.9403 - nll_gaussian: 0.6478\n",
      "build\n",
      "Train member Nr 5/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00090: early stopping\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.6161 - nll_gaussian: 0.1105\n",
      "Loss: 0.3270541369915009\n",
      "Computation time: 38.5s\n",
      "New best hyperparameters\n",
      "Mean loss: 0.3270541369915009\n",
      "{'layers': 1, 'neurons': 16, 'dropout': 0.281150031365086, 'noise_in': 0.16894003610514885, 'noise_mu': 0.3849725219555177, 'noise_sigma': 0.4440723859739808, 'noise_alpha': 0.0, 'l1_hidden': 0.04589933653540832, 'l2_hidden': 0.08195494568549347, 'l1_mu': 0.13264145311773415, 'l2_mu': 0.06291223390957867, 'l1_sigma': 0.15247223852304476, 'l2_sigma': 0.1285964445221017, 'l1_alpha': 0.0, 'l2_alpha': 0.0, 'batch_size': 100, 'n_segments': 5, 'n_members_segment': 1, 'lr': 0.0015991931672665054, 'patience': 30, 'epochs': 500, 'verbose': 0, 'pdf': 'normal', 'activation': 'relu', 'name': 'dem_dt13nosc_mu28v4', 'n_members': 5}\n",
      "Test period: 1972-01-01 till 1981-12-01\n",
      "--------------------------------------\n",
      "Search iteration Nr 1/1\n",
      "build\n",
      "Train member Nr 1/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00038: early stopping\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5363 - nll_gaussian: 0.4618\n",
      "build\n",
      "Train member Nr 2/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00154: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6576 - nll_gaussian: 0.5346\n",
      "build\n",
      "Train member Nr 3/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00032: early stopping\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.4292 - nll_gaussian: 0.1996\n",
      "build\n",
      "Train member Nr 4/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00186: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4713 - nll_gaussian: 0.4548\n",
      "build\n",
      "Train member Nr 5/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00081: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.3730 - nll_gaussian: 0.1318\n",
      "Loss: 0.35651436150074006\n",
      "Computation time: 54.5s\n",
      "New best hyperparameters\n",
      "Mean loss: 0.35651436150074006\n",
      "{'layers': 1, 'neurons': 16, 'dropout': 0.3448642826775302, 'noise_in': 0.18631549633032596, 'noise_mu': 0.40424995848978085, 'noise_sigma': 0.1969379384906058, 'noise_alpha': 0.0, 'l1_hidden': 0.18243401205482523, 'l2_hidden': 0.12186270196176424, 'l1_mu': 0.13744418172116718, 'l2_mu': 0.05422324557442844, 'l1_sigma': 0.112082742836889, 'l2_sigma': 0.12171526799452462, 'l1_alpha': 0.0, 'l2_alpha': 0.0, 'batch_size': 100, 'n_segments': 5, 'n_members_segment': 1, 'lr': 0.0037254411369142108, 'patience': 30, 'epochs': 500, 'verbose': 0, 'pdf': 'normal', 'activation': 'relu', 'name': 'dem_dt13nosc_mu28v4', 'n_members': 5}\n",
      "Test period: 1982-01-01 till 1991-12-01\n",
      "--------------------------------------\n",
      "Search iteration Nr 1/1\n",
      "build\n",
      "Train member Nr 1/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00061: early stopping\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7433 - nll_gaussian: 0.3871\n",
      "build\n",
      "Train member Nr 2/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00111: early stopping\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.8214 - nll_gaussian: 0.5755\n",
      "build\n",
      "Train member Nr 3/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00092: early stopping\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5899 - nll_gaussian: 0.1070\n",
      "build\n",
      "Train member Nr 4/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00031: early stopping\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0498 - nll_gaussian: -0.1699\n",
      "build\n",
      "Train member Nr 5/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00075: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.3572 - nll_gaussian: 0.0449\n",
      "Loss: 0.1889230065047741\n",
      "Computation time: 41.9s\n",
      "New best hyperparameters\n",
      "Mean loss: 0.1889230065047741\n",
      "{'layers': 1, 'neurons': 16, 'dropout': 0.30958285306459987, 'noise_in': 0.3830531266212308, 'noise_mu': 0.3728053780703744, 'noise_sigma': 0.26600958875009295, 'noise_alpha': 0.0, 'l1_hidden': 0.017897364216991663, 'l2_hidden': 0.16972058806355012, 'l1_mu': 0.16962030468551592, 'l2_mu': 0.08622997326107325, 'l1_sigma': 0.14769377593950844, 'l2_sigma': 0.08818202522114237, 'l1_alpha': 0.0, 'l2_alpha': 0.0, 'batch_size': 100, 'n_segments': 5, 'n_members_segment': 1, 'lr': 0.0035832291041328445, 'patience': 30, 'epochs': 500, 'verbose': 0, 'pdf': 'normal', 'activation': 'relu', 'name': 'dem_dt13nosc_mu28v4', 'n_members': 5}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##################################################################\n",
      "Lead time: 12 month\n",
      "##################################################################\n",
      "\n",
      "Test period: 1953-01-01 till 1961-12-01\n",
      "--------------------------------------\n",
      "Search iteration Nr 1/1\n",
      "build\n",
      "Train member Nr 1/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00032: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.1871 - nll_gaussian: 0.4980\n",
      "build\n",
      "Train member Nr 2/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00074: early stopping\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.8190 - nll_gaussian: -0.0012\n",
      "build\n",
      "Train member Nr 3/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00148: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.1961 - nll_gaussian: -0.1253\n",
      "build\n",
      "Train member Nr 4/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00031: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.2219 - nll_gaussian: 0.5366\n",
      "build\n",
      "Train member Nr 5/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00145: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.2940 - nll_gaussian: 0.0687\n",
      "Loss: 0.19538040806073695\n",
      "Computation time: 44.7s\n",
      "New best hyperparameters\n",
      "Mean loss: 0.19538040806073695\n",
      "{'layers': 1, 'neurons': 16, 'dropout': 0.3510953320145451, 'noise_in': 0.27563382677438436, 'noise_mu': 0.11949249189875806, 'noise_sigma': 0.43705427016258247, 'noise_alpha': 0.0, 'l1_hidden': 0.16912193617430188, 'l2_hidden': 0.01530559112224752, 'l1_mu': 0.1898696434424263, 'l2_mu': 0.07659008149425545, 'l1_sigma': 0.054674797240843766, 'l2_sigma': 0.08507462060639204, 'l1_alpha': 0.0, 'l2_alpha': 0.0, 'batch_size': 100, 'n_segments': 5, 'n_members_segment': 1, 'lr': 0.00378288048115141, 'patience': 30, 'epochs': 500, 'verbose': 0, 'pdf': 'normal', 'activation': 'relu', 'name': 'dem_dt13nosc_mu28v4', 'n_members': 5}\n",
      "Test period: 1962-01-01 till 1971-12-01\n",
      "--------------------------------------\n",
      "Search iteration Nr 1/1\n",
      "build\n",
      "Train member Nr 1/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00116: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4435 - nll_gaussian: 0.4231\n",
      "build\n",
      "Train member Nr 2/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00148: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -0.1516 - nll_gaussian: -0.4185\n",
      "build\n",
      "Train member Nr 3/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00124: early stopping\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -0.2783 - nll_gaussian: -0.5041\n",
      "build\n",
      "Train member Nr 4/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00106: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.5392 - nll_gaussian: 0.5205\n",
      "build\n",
      "Train member Nr 5/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00040: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2643 - nll_gaussian: 0.1352\n",
      "Loss: 0.031214138865470885\n",
      "Computation time: 56.1s\n",
      "New best hyperparameters\n",
      "Mean loss: 0.031214138865470885\n",
      "{'layers': 1, 'neurons': 16, 'dropout': 0.19008459083273804, 'noise_in': 0.18789235982623867, 'noise_mu': 0.2727836732786085, 'noise_sigma': 0.11495861636469457, 'noise_alpha': 0.0, 'l1_hidden': 0.0021887771915863443, 'l2_hidden': 0.16677583602997156, 'l1_mu': 0.08965763597932562, 'l2_mu': 0.03993964008853079, 'l1_sigma': 0.1106271566655622, 'l2_sigma': 0.09789010345709047, 'l1_alpha': 0.0, 'l2_alpha': 0.0, 'batch_size': 100, 'n_segments': 5, 'n_members_segment': 1, 'lr': 0.005393816716829782, 'patience': 30, 'epochs': 500, 'verbose': 0, 'pdf': 'normal', 'activation': 'relu', 'name': 'dem_dt13nosc_mu28v4', 'n_members': 5}\n",
      "Test period: 1972-01-01 till 1981-12-01\n",
      "--------------------------------------\n",
      "Search iteration Nr 1/1\n",
      "build\n",
      "Train member Nr 1/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00094: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4530 - nll_gaussian: 0.4195\n",
      "build\n",
      "Train member Nr 2/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00126: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.5455 - nll_gaussian: 0.5270\n",
      "build\n",
      "Train member Nr 3/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00031: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4314 - nll_gaussian: 0.1998\n",
      "build\n",
      "Train member Nr 4/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00143: early stopping\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.4533 - nll_gaussian: 0.4528\n",
      "build\n",
      "Train member Nr 5/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00038: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.3097 - nll_gaussian: 0.1368\n",
      "Loss: 0.3471755176782608\n",
      "Computation time: 46.7s\n",
      "New best hyperparameters\n",
      "Mean loss: 0.3471755176782608\n",
      "{'layers': 1, 'neurons': 16, 'dropout': 0.16491972290458662, 'noise_in': 0.48361975568033433, 'noise_mu': 0.2698006458400052, 'noise_sigma': 0.12240246217610724, 'noise_alpha': 0.0, 'l1_hidden': 0.13552749495519742, 'l2_hidden': 0.11012733481284585, 'l1_mu': 0.08884267920017064, 'l2_mu': 0.18845163178096155, 'l1_sigma': 0.021426185180751636, 'l2_sigma': 0.18079998282388277, 'l1_alpha': 0.0, 'l2_alpha': 0.0, 'batch_size': 100, 'n_segments': 5, 'n_members_segment': 1, 'lr': 0.004678499337294577, 'patience': 30, 'epochs': 500, 'verbose': 0, 'pdf': 'normal', 'activation': 'relu', 'name': 'dem_dt13nosc_mu28v4', 'n_members': 5}\n",
      "Test period: 1982-01-01 till 1991-12-01\n",
      "--------------------------------------\n",
      "Search iteration Nr 1/1\n",
      "build\n",
      "Train member Nr 1/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00066: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.9104 - nll_gaussian: 0.3329\n",
      "build\n",
      "Train member Nr 2/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00099: early stopping\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.0208 - nll_gaussian: 0.3979\n",
      "build\n",
      "Train member Nr 3/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00036: early stopping\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5168 - nll_gaussian: 0.1519\n",
      "build\n",
      "Train member Nr 4/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00031: early stopping\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0449 - nll_gaussian: -0.1719\n",
      "build\n",
      "Train member Nr 5/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00059: early stopping\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.6209 - nll_gaussian: 0.0334\n",
      "Loss: 0.14882128909230233\n",
      "Computation time: 32.5s\n",
      "New best hyperparameters\n",
      "Mean loss: 0.14882128909230233\n",
      "{'layers': 1, 'neurons': 16, 'dropout': 0.20293668886791905, 'noise_in': 0.17943388756423695, 'noise_mu': 0.4015994533884045, 'noise_sigma': 0.4643109163751129, 'noise_alpha': 0.0, 'l1_hidden': 0.04418589854010642, 'l2_hidden': 0.04874862778856617, 'l1_mu': 0.06303779509895578, 'l2_mu': 0.15508431721988608, 'l1_sigma': 0.06324834284381697, 'l2_sigma': 0.0313262582100476, 'l1_alpha': 0.0, 'l2_alpha': 0.0, 'batch_size': 100, 'n_segments': 5, 'n_members_segment': 1, 'lr': 0.00960556694893568, 'patience': 30, 'epochs': 500, 'verbose': 0, 'pdf': 'normal', 'activation': 'relu', 'name': 'dem_dt13nosc_mu28v4', 'n_members': 5}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##################################################################\n",
      "Lead time: 15 month\n",
      "##################################################################\n",
      "\n",
      "Test period: 1953-01-01 till 1961-12-01\n",
      "--------------------------------------\n",
      "Search iteration Nr 1/1\n",
      "build\n",
      "Train member Nr 1/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00033: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.8033 - nll_gaussian: 0.4727\n",
      "build\n",
      "Train member Nr 2/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00084: early stopping\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.8827 - nll_gaussian: -0.0339\n",
      "build\n",
      "Train member Nr 3/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00138: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.7849 - nll_gaussian: -0.2210\n",
      "build\n",
      "Train member Nr 4/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00041: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.9818 - nll_gaussian: 0.4783\n",
      "build\n",
      "Train member Nr 5/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00064: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.9135 - nll_gaussian: 0.0942\n",
      "Loss: 0.15804168507456778\n",
      "Computation time: 40.7s\n",
      "New best hyperparameters\n",
      "Mean loss: 0.15804168507456778\n",
      "{'layers': 1, 'neurons': 16, 'dropout': 0.45887426221482075, 'noise_in': 0.4745941441776246, 'noise_mu': 0.38430056193925644, 'noise_sigma': 0.3146234698938889, 'noise_alpha': 0.0, 'l1_hidden': 0.060674306657842174, 'l2_hidden': 0.16907110516046905, 'l1_mu': 0.1313922036144354, 'l2_mu': 0.17828119400095235, 'l1_sigma': 0.16782363954531812, 'l2_sigma': 0.023343926359059644, 'l1_alpha': 0.0, 'l2_alpha': 0.0, 'batch_size': 100, 'n_segments': 5, 'n_members_segment': 1, 'lr': 0.005860981404582441, 'patience': 30, 'epochs': 500, 'verbose': 0, 'pdf': 'normal', 'activation': 'relu', 'name': 'dem_dt13nosc_mu28v4', 'n_members': 5}\n",
      "Test period: 1962-01-01 till 1971-12-01\n",
      "--------------------------------------\n",
      "Search iteration Nr 1/1\n",
      "build\n",
      "Train member Nr 1/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00039: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.1985 - nll_gaussian: 0.4127\n",
      "build\n",
      "Train member Nr 2/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00081: early stopping\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4276 - nll_gaussian: -0.0281\n",
      "build\n",
      "Train member Nr 3/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00050: early stopping\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7411 - nll_gaussian: 0.3353\n",
      "build\n",
      "Train member Nr 4/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00031: early stopping\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.0803 - nll_gaussian: 0.6898\n",
      "build\n",
      "Train member Nr 5/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00096: early stopping\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1.4750 - nll_gaussian: -0.1194\n",
      "Loss: 0.258061857521534\n",
      "Computation time: 34.7s\n",
      "New best hyperparameters\n",
      "Mean loss: 0.258061857521534\n",
      "{'layers': 1, 'neurons': 16, 'dropout': 0.23701012858107845, 'noise_in': 0.4582398021550198, 'noise_mu': 0.20887485047443066, 'noise_sigma': 0.4574064614590275, 'noise_alpha': 0.0, 'l1_hidden': 0.11010333850474226, 'l2_hidden': 0.006205341596082126, 'l1_mu': 0.18783846041077396, 'l2_mu': 0.052511227640743875, 'l1_sigma': 0.0688057839403, 'l2_sigma': 0.1351344085300198, 'l1_alpha': 0.0, 'l2_alpha': 0.0, 'batch_size': 100, 'n_segments': 5, 'n_members_segment': 1, 'lr': 0.007356947941174606, 'patience': 30, 'epochs': 500, 'verbose': 0, 'pdf': 'normal', 'activation': 'relu', 'name': 'dem_dt13nosc_mu28v4', 'n_members': 5}\n",
      "Test period: 1972-01-01 till 1981-12-01\n",
      "--------------------------------------\n",
      "Search iteration Nr 1/1\n",
      "build\n",
      "Train member Nr 1/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00057: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.0234 - nll_gaussian: 0.3560\n",
      "build\n",
      "Train member Nr 2/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00134: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.1239 - nll_gaussian: 0.4855\n",
      "build\n",
      "Train member Nr 3/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00189: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.5476 - nll_gaussian: 0.0078\n",
      "build\n",
      "Train member Nr 4/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00055: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.1534 - nll_gaussian: 0.3372\n",
      "build\n",
      "Train member Nr 5/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00170: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.3143 - nll_gaussian: -0.0457\n",
      "Loss: 0.2281518249772489\n",
      "Computation time: 64.3s\n",
      "New best hyperparameters\n",
      "Mean loss: 0.2281518249772489\n",
      "{'layers': 1, 'neurons': 16, 'dropout': 0.10209867892269658, 'noise_in': 0.4354208557689999, 'noise_mu': 0.30876936853329606, 'noise_sigma': 0.3193113398978915, 'noise_alpha': 0.0, 'l1_hidden': 0.0794602176890068, 'l2_hidden': 0.14402374594833464, 'l1_mu': 0.07496579709817248, 'l2_mu': 0.14136478320263998, 'l1_sigma': 0.14401721940759024, 'l2_sigma': 0.08775591755743134, 'l1_alpha': 0.0, 'l2_alpha': 0.0, 'batch_size': 100, 'n_segments': 5, 'n_members_segment': 1, 'lr': 0.005063186429932509, 'patience': 30, 'epochs': 500, 'verbose': 0, 'pdf': 'normal', 'activation': 'relu', 'name': 'dem_dt13nosc_mu28v4', 'n_members': 5}\n",
      "Test period: 1982-01-01 till 1991-12-01\n",
      "--------------------------------------\n",
      "Search iteration Nr 1/1\n",
      "build\n",
      "Train member Nr 1/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00072: early stopping\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.4677 - nll_gaussian: 0.4007\n",
      "build\n",
      "Train member Nr 2/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00067: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.7365 - nll_gaussian: 0.5096\n",
      "build\n",
      "Train member Nr 3/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00033: early stopping\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2652 - nll_gaussian: 0.1860\n",
      "build\n",
      "Train member Nr 4/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00031: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -8.6665e-04 - nll_gaussian: -0.1601\n",
      "build\n",
      "Train member Nr 5/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00031: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2906 - nll_gaussian: 0.0560\n",
      "Loss: 0.19844356402754784\n",
      "Computation time: 28.2s\n",
      "New best hyperparameters\n",
      "Mean loss: 0.19844356402754784\n",
      "{'layers': 1, 'neurons': 16, 'dropout': 0.3913917933704799, 'noise_in': 0.4396222348387533, 'noise_mu': 0.15718743041492234, 'noise_sigma': 0.18675957406617033, 'noise_alpha': 0.0, 'l1_hidden': 0.06723923517568205, 'l2_hidden': 0.18741251992425567, 'l1_mu': 0.13410885275291742, 'l2_mu': 0.17782272605916047, 'l1_sigma': 0.07353666382618118, 'l2_sigma': 0.07910194163398528, 'l1_alpha': 0.0, 'l2_alpha': 0.0, 'batch_size': 100, 'n_segments': 5, 'n_members_segment': 1, 'lr': 0.007572017486158075, 'patience': 30, 'epochs': 500, 'verbose': 0, 'pdf': 'normal', 'activation': 'relu', 'name': 'dem_dt13nosc_mu28v4', 'n_members': 5}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##################################################################\n",
      "Lead time: 18 month\n",
      "##################################################################\n",
      "\n",
      "Test period: 1953-01-01 till 1961-12-01\n",
      "--------------------------------------\n",
      "Search iteration Nr 1/1\n",
      "build\n",
      "Train member Nr 1/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00095: early stopping\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.4159 - nll_gaussian: 0.3756\n",
      "build\n",
      "Train member Nr 2/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00068: early stopping\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.3708 - nll_gaussian: 0.0150\n",
      "build\n",
      "Train member Nr 3/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00031: early stopping\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.3380 - nll_gaussian: -0.0924\n",
      "build\n",
      "Train member Nr 4/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00035: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.8067 - nll_gaussian: 0.5172\n",
      "build\n",
      "Train member Nr 5/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00084: early stopping\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.0974 - nll_gaussian: 0.0401\n",
      "Loss: 0.17109529692679643\n",
      "Computation time: 35.9s\n",
      "New best hyperparameters\n",
      "Mean loss: 0.17109529692679643\n",
      "{'layers': 1, 'neurons': 16, 'dropout': 0.4116911160322606, 'noise_in': 0.3372474976178239, 'noise_mu': 0.37914590040315443, 'noise_sigma': 0.2484840890815285, 'noise_alpha': 0.0, 'l1_hidden': 0.19178295577856902, 'l2_hidden': 0.049515845380301626, 'l1_mu': 0.047625283931054675, 'l2_mu': 0.1844562505045736, 'l1_sigma': 0.15596260109859758, 'l2_sigma': 0.18867830329163132, 'l1_alpha': 0.0, 'l2_alpha': 0.0, 'batch_size': 100, 'n_segments': 5, 'n_members_segment': 1, 'lr': 0.005662833141863798, 'patience': 30, 'epochs': 500, 'verbose': 0, 'pdf': 'normal', 'activation': 'relu', 'name': 'dem_dt13nosc_mu28v4', 'n_members': 5}\n",
      "Test period: 1962-01-01 till 1971-12-01\n",
      "--------------------------------------\n",
      "Search iteration Nr 1/1\n",
      "build\n",
      "Train member Nr 1/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00137: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4521 - nll_gaussian: 0.4324\n",
      "build\n",
      "Train member Nr 2/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00055: early stopping\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2327 - nll_gaussian: 0.1175\n",
      "build\n",
      "Train member Nr 3/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00032: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.1843 - nll_gaussian: 0.3359\n",
      "build\n",
      "Train member Nr 4/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00152: early stopping\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.5465 - nll_gaussian: 0.5241\n",
      "build\n",
      "Train member Nr 5/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00055: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2640 - nll_gaussian: 0.1368\n",
      "Loss: 0.3093376994132996\n",
      "Computation time: 48.3s\n",
      "New best hyperparameters\n",
      "Mean loss: 0.3093376994132996\n",
      "{'layers': 1, 'neurons': 16, 'dropout': 0.22119542373850415, 'noise_in': 0.2157013406343948, 'noise_mu': 0.26011341834035956, 'noise_sigma': 0.10694583822721944, 'noise_alpha': 0.0, 'l1_hidden': 0.05351039745853106, 'l2_hidden': 0.015061588217513534, 'l1_mu': 0.15306825274667502, 'l2_mu': 0.06588757090776963, 'l1_sigma': 0.053391635922781025, 'l2_sigma': 0.09081262425047816, 'l1_alpha': 0.0, 'l2_alpha': 0.0, 'batch_size': 100, 'n_segments': 5, 'n_members_segment': 1, 'lr': 0.0023146074375726892, 'patience': 30, 'epochs': 500, 'verbose': 0, 'pdf': 'normal', 'activation': 'relu', 'name': 'dem_dt13nosc_mu28v4', 'n_members': 5}\n",
      "Test period: 1972-01-01 till 1981-12-01\n",
      "--------------------------------------\n",
      "Search iteration Nr 1/1\n",
      "build\n",
      "Train member Nr 1/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00066: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.2120 - nll_gaussian: 0.2977\n",
      "build\n",
      "Train member Nr 2/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00050: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.3623 - nll_gaussian: 0.5993\n",
      "build\n",
      "Train member Nr 3/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00046: early stopping\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.9684 - nll_gaussian: 0.2017\n",
      "build\n",
      "Train member Nr 4/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00368: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 2.1727 - nll_gaussian: 0.0241\n",
      "build\n",
      "Train member Nr 5/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00275: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 2.3008 - nll_gaussian: -0.2338\n",
      "Loss: 0.17780721187591553\n",
      "Computation time: 80.7s\n",
      "New best hyperparameters\n",
      "Mean loss: 0.17780721187591553\n",
      "{'layers': 1, 'neurons': 16, 'dropout': 0.35331523413479193, 'noise_in': 0.3330400048562441, 'noise_mu': 0.11516694384546865, 'noise_sigma': 0.3419704677584968, 'noise_alpha': 0.0, 'l1_hidden': 0.1080317933995836, 'l2_hidden': 0.1847646013126747, 'l1_mu': 0.12325931051992055, 'l2_mu': 0.07080566961435562, 'l1_sigma': 0.09765287912503694, 'l2_sigma': 0.07929205193591722, 'l1_alpha': 0.0, 'l2_alpha': 0.0, 'batch_size': 100, 'n_segments': 5, 'n_members_segment': 1, 'lr': 0.00623759758951601, 'patience': 30, 'epochs': 500, 'verbose': 0, 'pdf': 'normal', 'activation': 'relu', 'name': 'dem_dt13nosc_mu28v4', 'n_members': 5}\n",
      "Test period: 1982-01-01 till 1991-12-01\n",
      "--------------------------------------\n",
      "Search iteration Nr 1/1\n",
      "build\n",
      "Train member Nr 1/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00045: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6320 - nll_gaussian: 0.3084\n",
      "build\n",
      "Train member Nr 2/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00383: early stopping\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.8007 - nll_gaussian: 0.0268\n",
      "build\n",
      "Train member Nr 3/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00125: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.3314 - nll_gaussian: -0.1575\n",
      "build\n",
      "Train member Nr 4/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00094: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.1930 - nll_gaussian: -0.3856\n",
      "build\n",
      "Train member Nr 5/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00078: early stopping\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.4759 - nll_gaussian: -0.0395\n",
      "Loss: -0.049480844661593436\n",
      "Computation time: 72.5s\n",
      "New best hyperparameters\n",
      "Mean loss: -0.049480844661593436\n",
      "{'layers': 1, 'neurons': 16, 'dropout': 0.11093818150274215, 'noise_in': 0.4259911542345062, 'noise_mu': 0.4166618753372364, 'noise_sigma': 0.2387090196884051, 'noise_alpha': 0.0, 'l1_hidden': 0.010307008693292286, 'l2_hidden': 0.008857591200807957, 'l1_mu': 0.13100900731233653, 'l2_mu': 0.06559018396126219, 'l1_sigma': 0.1490188069849478, 'l2_sigma': 0.1319898091916478, 'l1_alpha': 0.0, 'l2_alpha': 0.0, 'batch_size': 100, 'n_segments': 5, 'n_members_segment': 1, 'lr': 0.007025560695309456, 'patience': 30, 'epochs': 500, 'verbose': 0, 'pdf': 'normal', 'activation': 'relu', 'name': 'dem_dt13nosc_mu28v4', 'n_members': 5}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##################################################################\n",
      "Lead time: 21 month\n",
      "##################################################################\n",
      "\n",
      "Test period: 1953-01-01 till 1961-12-01\n",
      "--------------------------------------\n",
      "Search iteration Nr 1/1\n",
      "build\n",
      "Train member Nr 1/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00050: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6833 - nll_gaussian: 0.4775\n",
      "build\n",
      "Train member Nr 2/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00054: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.1399 - nll_gaussian: -0.0582\n",
      "build\n",
      "Train member Nr 3/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00057: early stopping\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.1103 - nll_gaussian: -0.1395\n",
      "build\n",
      "Train member Nr 4/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00197: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6622 - nll_gaussian: 0.2189\n",
      "build\n",
      "Train member Nr 5/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00123: early stopping\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4021 - nll_gaussian: 0.0292\n",
      "Loss: 0.10558101758360863\n",
      "Computation time: 52.1s\n",
      "New best hyperparameters\n",
      "Mean loss: 0.10558101758360863\n",
      "{'layers': 1, 'neurons': 16, 'dropout': 0.3785655983571812, 'noise_in': 0.4150339610803149, 'noise_mu': 0.1159303081654048, 'noise_sigma': 0.2652643653632134, 'noise_alpha': 0.0, 'l1_hidden': 0.035046907848399034, 'l2_hidden': 0.0982300002786815, 'l1_mu': 0.0038270151700779743, 'l2_mu': 0.11011800983661049, 'l1_sigma': 0.033446115890430186, 'l2_sigma': 0.03473879442400194, 'l1_alpha': 0.0, 'l2_alpha': 0.0, 'batch_size': 100, 'n_segments': 5, 'n_members_segment': 1, 'lr': 0.004496699936630343, 'patience': 30, 'epochs': 500, 'verbose': 0, 'pdf': 'normal', 'activation': 'relu', 'name': 'dem_dt13nosc_mu28v4', 'n_members': 5}\n",
      "Test period: 1962-01-01 till 1971-12-01\n",
      "--------------------------------------\n",
      "Search iteration Nr 1/1\n",
      "build\n",
      "Train member Nr 1/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00091: early stopping\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.8466 - nll_gaussian: 0.4284\n",
      "build\n",
      "Train member Nr 2/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00031: early stopping\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.6011 - nll_gaussian: 0.0958\n",
      "build\n",
      "Train member Nr 3/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00046: early stopping\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.4021 - nll_gaussian: 0.3506\n",
      "build\n",
      "Train member Nr 4/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00219: early stopping\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 1.3905 - nll_gaussian: 0.5659\n",
      "build\n",
      "Train member Nr 5/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00039: early stopping\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.4289 - nll_gaussian: 0.1255\n",
      "Loss: 0.31323911249637604\n",
      "Computation time: 46.1s\n",
      "New best hyperparameters\n",
      "Mean loss: 0.31323911249637604\n",
      "{'layers': 1, 'neurons': 16, 'dropout': 0.4933984957393932, 'noise_in': 0.3824683536035215, 'noise_mu': 0.3439670289882398, 'noise_sigma': 0.2354203621651433, 'noise_alpha': 0.0, 'l1_hidden': 0.1316996545930032, 'l2_hidden': 0.17689169637375768, 'l1_mu': 0.1564700659262067, 'l2_mu': 0.013354907189540645, 'l1_sigma': 0.14601695394139005, 'l2_sigma': 0.12190496238679178, 'l1_alpha': 0.0, 'l2_alpha': 0.0, 'batch_size': 100, 'n_segments': 5, 'n_members_segment': 1, 'lr': 0.0041705912967099365, 'patience': 30, 'epochs': 500, 'verbose': 0, 'pdf': 'normal', 'activation': 'relu', 'name': 'dem_dt13nosc_mu28v4', 'n_members': 5}\n",
      "Test period: 1972-01-01 till 1981-12-01\n",
      "--------------------------------------\n",
      "Search iteration Nr 1/1\n",
      "build\n",
      "Train member Nr 1/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00048: early stopping\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.7080 - nll_gaussian: 0.4681\n",
      "build\n",
      "Train member Nr 2/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00053: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.9062 - nll_gaussian: 0.6943\n",
      "build\n",
      "Train member Nr 3/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00139: early stopping\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.4268 - nll_gaussian: 0.1938\n",
      "build\n",
      "Train member Nr 4/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00099: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.7637 - nll_gaussian: 0.5750\n",
      "build\n",
      "Train member Nr 5/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00112: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4695 - nll_gaussian: 0.1181\n",
      "Loss: 0.40985365509986876\n",
      "Computation time: 48.5s\n",
      "New best hyperparameters\n",
      "Mean loss: 0.40985365509986876\n",
      "{'layers': 1, 'neurons': 16, 'dropout': 0.1613953671583075, 'noise_in': 0.19997204077557248, 'noise_mu': 0.23134651101941422, 'noise_sigma': 0.37420101647915527, 'noise_alpha': 0.0, 'l1_hidden': 0.02996908210460283, 'l2_hidden': 0.1963500078482323, 'l1_mu': 0.07037983405366165, 'l2_mu': 0.18840205032794033, 'l1_sigma': 0.15924508344981395, 'l2_sigma': 0.031566838909795815, 'l1_alpha': 0.0, 'l2_alpha': 0.0, 'batch_size': 100, 'n_segments': 5, 'n_members_segment': 1, 'lr': 0.0005116874859735315, 'patience': 30, 'epochs': 500, 'verbose': 0, 'pdf': 'normal', 'activation': 'relu', 'name': 'dem_dt13nosc_mu28v4', 'n_members': 5}\n",
      "Test period: 1982-01-01 till 1991-12-01\n",
      "--------------------------------------\n",
      "Search iteration Nr 1/1\n",
      "build\n",
      "Train member Nr 1/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00107: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6133 - nll_gaussian: 0.3672\n",
      "build\n",
      "Train member Nr 2/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00031: early stopping\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.8182 - nll_gaussian: 0.7088\n",
      "build\n",
      "Train member Nr 3/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00095: early stopping\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.3462 - nll_gaussian: 0.1643\n",
      "build\n",
      "Train member Nr 4/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00031: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -0.0295 - nll_gaussian: -0.1650\n",
      "build\n",
      "Train member Nr 5/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00098: early stopping\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.3294 - nll_gaussian: 0.0338\n",
      "Loss: 0.22181650698184968\n",
      "Computation time: 38.8s\n",
      "New best hyperparameters\n",
      "Mean loss: 0.22181650698184968\n",
      "{'layers': 1, 'neurons': 16, 'dropout': 0.11960656258817344, 'noise_in': 0.49669495839699385, 'noise_mu': 0.11836366598134195, 'noise_sigma': 0.36373188492119257, 'noise_alpha': 0.0, 'l1_hidden': 0.012863083548133104, 'l2_hidden': 0.08753457778862431, 'l1_mu': 0.07684747733508457, 'l2_mu': 0.07887586000700966, 'l1_sigma': 0.06635478938834287, 'l2_sigma': 0.10348805186470578, 'l1_alpha': 0.0, 'l2_alpha': 0.0, 'batch_size': 100, 'n_segments': 5, 'n_members_segment': 1, 'lr': 0.0026440726402685117, 'patience': 30, 'epochs': 500, 'verbose': 0, 'pdf': 'normal', 'activation': 'relu', 'name': 'dem_dt13nosc_mu28v4', 'n_members': 5}\n"
     ]
    }
   ],
   "source": [
    "cross_training(DEM, train_pipeline, n_iter = 1 , modelname = name, layers=1, neurons=16, dropout=[0.1, 0.5], noise_in=[0.1,0.5], noise_sigma=[0.1,0.5],\n",
    "                     noise_mu=[0.1,0.5], l1_hidden=[0.0, 0.2], l2_hidden=[0., 0.2],\n",
    "                     l1_mu=[0.0, 0.2], l2_mu=[0.0, 0.2], l1_sigma=[0.0, 0.2],\n",
    "                     l2_sigma=[0.0, 0.2], lr=[0.0001,0.01], batch_size=100, epochs = 500, n_segments = 5,\n",
    "                    n_members_segment =1, patience=30, verbose = 0, pdf='normal', activation='relu')\n",
    "# cross_training(DEM, pipeline, n_iter = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decades: [1953, 1962, 1972, 1982, 1992]\n",
      "\n",
      "##################################################################\n",
      "Lead time: 0 months\n",
      "##################################################################\n",
      "\n",
      "Predict: 1953-01-01 till 1961-12-01\n",
      "--------------------------------------\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 7) for input Tensor(\"input_2:0\", shape=(None, 7), dtype=float32), but it was called on an input with incompatible shape (None, 5).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:Model was constructed with shape (None, 7) for input Tensor(\"input_2:0\", shape=(None, 7), dtype=float32), but it was called on an input with incompatible shape (None, 5).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /home/ivo/anaconda3/envs/ninolearn/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py:1147 predict_function  *\n        outputs = self.distribute_strategy.run(\n    /home/ivo/anaconda3/envs/ninolearn/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py:951 run  **\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/ivo/anaconda3/envs/ninolearn/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py:2290 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/ivo/anaconda3/envs/ninolearn/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py:2649 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /home/ivo/anaconda3/envs/ninolearn/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py:1122 predict_step  **\n        return self(x, training=False)\n    /home/ivo/anaconda3/envs/ninolearn/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py:927 __call__\n        outputs = call_fn(cast_inputs, *args, **kwargs)\n    /home/ivo/anaconda3/envs/ninolearn/lib/python3.6/site-packages/tensorflow/python/keras/engine/network.py:719 call\n        convert_kwargs_to_constants=base_layer_utils.call_context().saving)\n    /home/ivo/anaconda3/envs/ninolearn/lib/python3.6/site-packages/tensorflow/python/keras/engine/network.py:888 _run_internal_graph\n        output_tensors = layer(computed_tensors, **kwargs)\n    /home/ivo/anaconda3/envs/ninolearn/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py:886 __call__\n        self.name)\n    /home/ivo/anaconda3/envs/ninolearn/lib/python3.6/site-packages/tensorflow/python/keras/engine/input_spec.py:216 assert_input_compatibility\n        ' but received input with shape ' + str(shape))\n\n    ValueError: Input 0 of layer hidden_0 is incompatible with the layer: expected axis -1 of input shape to have value 7 but received input with shape [None, 5]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-6ece785c971a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcross_hindcast_dem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_pipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/GitHub/ninolearn/ninolearn/learn/fit.py\u001b[0m in \u001b[0;36mcross_hindcast_dem\u001b[0;34m(model, pipeline, model_name)\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0mcross_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \"\"\"\n\u001b[0;32m--> 170\u001b[0;31m     \u001b[0mcross_hindcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;31m### TODO: unpack the std part from dem_forecasts.nc because this code is deprecated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/ninolearn/ninolearn/learn/fit.py\u001b[0m in \u001b[0;36mcross_hindcast\u001b[0;34m(model, pipeline, model_name, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0;31m# make prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/ninolearn/ninolearn/learn/models/dem.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'n_members'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 338\u001b[0;31m             \u001b[0mpred_ens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    339\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mixture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_ens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ninolearn/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[1;32m     87\u001b[0m           method.__name__))\n\u001b[0;32m---> 88\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m   return tf_decorator.make_decorator(\n",
      "\u001b[0;32m~/anaconda3/envs/ninolearn/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1266\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1267\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1268\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1269\u001b[0m             \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1270\u001b[0m             \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ninolearn/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ninolearn/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    625\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    628\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ninolearn/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    504\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    505\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 506\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ninolearn/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2444\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2445\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2446\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2447\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ninolearn/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2776\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2777\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2778\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2779\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ninolearn/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2665\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2666\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2667\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   2668\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2669\u001b[0m         \u001b[0;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ninolearn/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    979\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 981\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    982\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ninolearn/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ninolearn/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    966\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 968\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /home/ivo/anaconda3/envs/ninolearn/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py:1147 predict_function  *\n        outputs = self.distribute_strategy.run(\n    /home/ivo/anaconda3/envs/ninolearn/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py:951 run  **\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/ivo/anaconda3/envs/ninolearn/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py:2290 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/ivo/anaconda3/envs/ninolearn/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py:2649 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /home/ivo/anaconda3/envs/ninolearn/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py:1122 predict_step  **\n        return self(x, training=False)\n    /home/ivo/anaconda3/envs/ninolearn/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py:927 __call__\n        outputs = call_fn(cast_inputs, *args, **kwargs)\n    /home/ivo/anaconda3/envs/ninolearn/lib/python3.6/site-packages/tensorflow/python/keras/engine/network.py:719 call\n        convert_kwargs_to_constants=base_layer_utils.call_context().saving)\n    /home/ivo/anaconda3/envs/ninolearn/lib/python3.6/site-packages/tensorflow/python/keras/engine/network.py:888 _run_internal_graph\n        output_tensors = layer(computed_tensors, **kwargs)\n    /home/ivo/anaconda3/envs/ninolearn/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py:886 __call__\n        self.name)\n    /home/ivo/anaconda3/envs/ninolearn/lib/python3.6/site-packages/tensorflow/python/keras/engine/input_spec.py:216 assert_input_compatibility\n        ' but received input with shape ' + str(shape))\n\n    ValueError: Input 0 of layer hidden_0 is incompatible with the layer: expected axis -1 of input shape to have value 7 but received input with shape [None, 5]\n"
     ]
    }
   ],
   "source": [
    "cross_hindcast_dem(DEM, test_pipeline, name) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = train_version + '_' + test_version\n",
    "r, p  = evaluation_decadal_correlation_ZC(name, variable_name='mean', ZC_version=test_version)\n",
    "rref, pref = evaluation_decadal_correlation_ZC('dem_mu28v4_mu28v4', variable_name='mean', ZC_version=test_version)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rref)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The array r and p contain correlation and p values for each decade for lead times [0,3,6,9,12,15,18,21] as defined in lead_times. index [1,1] is the 3 month lead time prediction for the second decade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "from ninolearn.private import plotdir\n",
    "plot_seasonal_skill_ZC(lead_times, r,  vmin=-1, vmax=1)\n",
    "# plt.contour(np.arange(1,5),lead_times, p, [0.9, 0.95, 0.99], linestyles=['solid', 'dashed', 'dotted'], colors='k')\n",
    "plt.title('Correlation skill')\n",
    "# plt.tight_layout()\n",
    "plt.savefig(join(plotdir, 'TL_r_skill_' + train_version + '_' + test_version))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we also want to compare the skill of the reference case AI to that of the Distorted physics AI. This can be done by plotting the ACC skill of both DEM instances together as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ninolearn.plot.evaluation import ACC_skill_comparison_ZC\n",
    "\n",
    "ACC_skill_comparison_ZC(r, rref, lead_times, train_version, test_version, plot_individual = False, plot_avg = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make predictions for the test data set\n",
    "Now we can use the trained models to make predicitons on the test data set to evaluate how good the model perfoms on a data set that it never saw before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_mean, pred_std = model.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ninolearn.learn.fit import cross_hindcast_dem, cross_hindcast\n",
    "# cross_hindcast(model, pipeline, 'DEM')\n",
    "# # cross_hindcast_dem(model, pipeline, 'DEM')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the prediction\n",
    "Let's see how the predicion is looking like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from ninolearn.plot.prediction import plot_prediction\n",
    "import pandas as pd\n",
    "from ninolearn.pathes import plotdir\n",
    "\n",
    "from os.path import join\n",
    "\n",
    "\n",
    "plt.subplots(figsize=(15,3.5))\n",
    "plt.axhspan(-0.5,\n",
    "            -6,\n",
    "            facecolor='blue',\n",
    "            alpha=0.1,zorder=0)\n",
    "\n",
    "plt.axhspan(0.5,\n",
    "            6,\n",
    "            facecolor='red',\n",
    "            alpha=0.1,zorder=0)\n",
    "\n",
    "plt.xlim(testtimey[0], testtimey[-1])\n",
    "plt.ylim(-3,3)\n",
    "\n",
    "# plot the prediction\n",
    "plot_prediction(testtimey, pred_mean, std=pred_std, facecolor='royalblue', line_color='navy')\n",
    "\n",
    "# plot the observation\n",
    "plt.plot(timey, y, \"r\", label = 'observation')\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(join(plotdir, f'predicVSobs_{version}_{lead_time}lead'))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model\n",
    "\n",
    "We can evaluate the model a bit more quantitatively using the loss function that was used to train the model, namely the negative-log-likelihood of the Gaussian and the correlation between the predicted mean and the observed ONI index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ninolearn.plot.evaluation import plot_correlation, plot_confMat, plot_seasonal_skill\n",
    "\n",
    "# loss = model.evaluate(testy, pred_mean, pred_std)\n",
    "# print(f\"Loss (Negative-Log-Likelihood): {loss}\")\n",
    "\n",
    "# # make a plot of the seasonal correaltion\n",
    "# # note: - pd.tseries.offsets.MonthBegin(1) appears to ensure that the correlations are plotted\n",
    "# # agains the correct season\n",
    "# plot_correlation(testy, pred_mean, testtimey - pd.tseries.offsets.MonthBegin(1), title=\"\")\n",
    "\n",
    "# # plot_seasonal_skill(leadtime, r_seas)\n",
    "\n",
    "# # plt.savefig(join(plotdir, f'correlation_{version}_{lead_time}lead'))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_seasonal_skill_ZC(lead_times, r,  vmin=0, vmax=1)\n",
    "plt.contour(np.arange(1,5),lead_times, p, linestyles=['solid', 'dashed', 'dotted'], colors='k')\n",
    "plt.title('Correlation skill')\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
