{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep ensemble for ENSO-forecasting\n",
    "\n",
    "In this tutorial you learn how to use a neural network model called Deep Ensemble (DE) for the ENSO forecasting. This network architecture was initially developed [Lakshminarayanan et al. (2017)](https://papers.nips.cc/paper/7219-simple-and-scalable-predictive-uncertainty-estimation-using-deep-ensembles.pdf). \n",
    "\n",
    "DEs are feed foreword neural networks that predict the mean and the standard deviation of a Gaussian. Hence, their predicion comes with an uncertainty estimation which is a valuable feature for ENSO-forecasting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a data pipe line\n",
    "\n",
    "At first, we define a data pipeline. This is in general quite useful to keep your code clean and also to reuse the pipeline for later purpose.\n",
    "\n",
    "The data pipeline generates returns:\n",
    "\n",
    "1. The feature array\n",
    "\n",
    "2. The label array\n",
    "\n",
    "3. The time  array corresponding to the time of the label\n",
    "\n",
    "NOTE (again): Lead time is defined as the time that passed between the last observed and the first date of the target season. Hence, negative appear, e.g. if you compare the DJF season with the target season JFM, you have a lead time of -2 month (Last observed date: Feburary 28/29, First date of the target season January 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from ninolearn.IO.read_processed import data_reader\n",
    "from ninolearn.IO.read_raw import ZC_simple_read\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from ninolearn.learn.fit import n_decades, lead_times, decade_color, decade_name\n",
    "from ninolearn.learn.evaluation import evaluation_correlation, evaluation_decadal_correlation, evaluation_seasonal_correlation, evaluation_decadal_correlation_ZC\n",
    "from ninolearn.learn.fit import cross_hindcast_dem\n",
    "from ninolearn.plot.evaluation import plot_seasonal_skill_ZC\n",
    "import matplotlib.pyplot as plt\n",
    "from ninolearn.learn.fit import cross_training\n",
    "from ninolearn.learn.fit import cross_hindcast_dem\n",
    "from ninolearn.learn.models import DEM\n",
    "\n",
    "oneyear= pd.Timedelta(365, 'D')\n",
    "\n",
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tstart = 1952-04-07 14:17:30 and tend = 1994-08-26 03:33:20 (train)\n",
      "tstart = 1952-04-07 14:17:30 and tend = 1994-08-26 03:33:20 (test)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "train_version = 'de08v4'\n",
    "test_version = 'mu28v4'\n",
    "name = 'dem' + '_'+ train_version  + '_' + test_version\n",
    "# leadtime = 12\n",
    "\n",
    "# t_start is defined using a funky timedelta because the starting date of the network analysis data is the last month\n",
    "# of its start year which is 1951-12 therefore the time must start in 1952 with some months added for values lost in \n",
    "# interpolation. TODO: fix this by backwards interpolating the first values of the year and finding out what is happening \n",
    "# with the nms\n",
    "train_times = np.unique(ZC_simple_read(train_version)['time'])\n",
    "test_times = np.unique(ZC_simple_read(test_version)['time'])\n",
    "\n",
    "train_t_start = train_times[0] + pd.Timedelta((2*365 + 90),'D')\n",
    "train_t_end = train_times[-1] - pd.Timedelta(90,'D')\n",
    "\n",
    "test_t_start = test_times[0] + pd.Timedelta((2*365 + 90),'D')\n",
    "test_t_end = test_times[-1] - pd.Timedelta(90,'D')\n",
    "\n",
    "print(f'tstart = {train_t_start} and tend = {train_t_end} (train)')\n",
    "print(f'tstart = {test_t_start} and tend = {test_t_end} (test)')\n",
    "\n",
    "t_start = train_t_start\n",
    "t_end = train_t_end\n",
    "times = train_times\n",
    "\n",
    "if train_t_end < pd.Timestamp('1990-01-01') or test_t_end < pd.Timestamp('1990-01-01'):\n",
    "    raise ValueError('one or both timeseries are too short!')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using dimensions ('lat', 'lon') from data variable temperature as the horizontal dimensions for this dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ivo/anaconda3/envs/ninolearn/lib/python3.6/site-packages/xesmf/frontend.py:524: FutureWarning: ``output_sizes`` should be given in the ``dask_gufunc_kwargs`` parameter. It will be removed as direct parameter in a future version.\n",
      "  keep_attrs=keep_attrs\n",
      "/home/ivo/anaconda3/envs/ninolearn/lib/python3.6/site-packages/xesmf/smm.py:93: UserWarning: Input array is not C_CONTIGUOUS. Will affect performance.\n",
      "  warnings.warn(\"Input array is not C_CONTIGUOUS. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Read sst climatetology\n",
      "using dimensions ('lat', 'lon') from data variable temperature as the horizontal dimensions for this dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ivo/anaconda3/envs/ninolearn/lib/python3.6/site-packages/xesmf/frontend.py:524: FutureWarning: ``output_sizes`` should be given in the ``dask_gufunc_kwargs`` parameter. It will be removed as direct parameter in a future version.\n",
      "  keep_attrs=keep_attrs\n",
      "WARNING:Wrong input for computation of hamming distance.\n",
      "WARNING:Wrong input for computation of corrected hamming distance.\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using dimensions ('lat', 'lon') from data variable thermocline_height as the horizontal dimensions for this dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ivo/anaconda3/envs/ninolearn/lib/python3.6/site-packages/xesmf/frontend.py:524: FutureWarning: ``output_sizes`` should be given in the ``dask_gufunc_kwargs`` parameter. It will be removed as direct parameter in a future version.\n",
      "  keep_attrs=keep_attrs\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:Wrong input for computation of hamming distance.\n",
      "WARNING:Wrong input for computation of corrected hamming distance.\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n"
     ]
    }
   ],
   "source": [
    "from ninolearn.IO.read_raw import ZC_raw, ZC_h, ZC_oni\n",
    "from ninolearn.preprocess.prepare import prep_nms\n",
    "from ninolearn.plot.ZC_dem_plots import nms_plots\n",
    "## read raw ZC data and save to 1x1 grid file in processeddir\n",
    "## also makes field of h and sst\n",
    "ZC_raw(train_version)\n",
    "\n",
    "## calculates monthly averaged (?) fields of thermocline height within region \n",
    "## of interest. cacluate ONI in region of interest. calculate network metrics \n",
    "## from sst (Henk's suggestion) or thermocline height (like Paul)\n",
    "\n",
    "ZC_h(train_version)\n",
    "ZC_oni(train_version)\n",
    "\n",
    "prep_nms(train_version, 0.99, t_start, t_end, variable = 'sst')\n",
    "prep_nms(train_version, 0.99, t_start, t_end, variable = 'h')\n",
    "\n",
    "# make plots\n",
    "# nms_plots(train_version)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using dimensions ('lat', 'lon') from data variable temperature as the horizontal dimensions for this dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ivo/anaconda3/envs/ninolearn/lib/python3.6/site-packages/xesmf/frontend.py:524: FutureWarning: ``output_sizes`` should be given in the ``dask_gufunc_kwargs`` parameter. It will be removed as direct parameter in a future version.\n",
      "  keep_attrs=keep_attrs\n",
      "/home/ivo/anaconda3/envs/ninolearn/lib/python3.6/site-packages/xesmf/smm.py:93: UserWarning: Input array is not C_CONTIGUOUS. Will affect performance.\n",
      "  warnings.warn(\"Input array is not C_CONTIGUOUS. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Read sst climatetology\n",
      "using dimensions ('lat', 'lon') from data variable temperature as the horizontal dimensions for this dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ivo/anaconda3/envs/ninolearn/lib/python3.6/site-packages/xesmf/frontend.py:524: FutureWarning: ``output_sizes`` should be given in the ``dask_gufunc_kwargs`` parameter. It will be removed as direct parameter in a future version.\n",
      "  keep_attrs=keep_attrs\n",
      "WARNING:Wrong input for computation of hamming distance.\n",
      "WARNING:Wrong input for computation of corrected hamming distance.\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using dimensions ('lat', 'lon') from data variable thermocline_height as the horizontal dimensions for this dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ivo/anaconda3/envs/ninolearn/lib/python3.6/site-packages/xesmf/frontend.py:524: FutureWarning: ``output_sizes`` should be given in the ``dask_gufunc_kwargs`` parameter. It will be removed as direct parameter in a future version.\n",
      "  keep_attrs=keep_attrs\n",
      "WARNING:Wrong input for computation of hamming distance.\n",
      "WARNING:Wrong input for computation of corrected hamming distance.\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n",
      "WARNING:c2 variable equal to 0!\n"
     ]
    }
   ],
   "source": [
    "ZC_raw(test_version)\n",
    "ZC_h(test_version)\n",
    "ZC_oni(test_version)\n",
    "prep_nms(test_version, 0.99, t_start, t_end, variable = 'sst')\n",
    "prep_nms(test_version, 0.99, t_start, t_end, variable = 'h')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "reader = data_reader(startdate=(t_start + pd.Timedelta(365,'D')) , enddate=(t_end - pd.Timedelta(2*365, 'D')) , lon_min = 124, lon_max = 280,\n",
    "                         lat_min = -19, lat_max = 19)\n",
    "\n",
    "oni = reader.read_csv(('oni_ZC_' +train_version))\n",
    "h = reader.read_csv(('h_mean_ZC_' + train_version))\n",
    "\n",
    "nms_sst = reader.read_statistic('network_metrics', variable='sst', dataset=('ZC_25x25_' + train_version), processed=\"anom\")\n",
    "nms_h = reader.read_statistic('network_metrics', variable='h', dataset=('ZC_25x25_' + train_version), processed=\"anom\")\n",
    "\n",
    "c2_sst = nms_sst['fraction_clusters_size_2']\n",
    "H_sst = nms_sst['corrected_hamming_distance']\n",
    "\n",
    "c2_h = nms_h['fraction_clusters_size_2']\n",
    "H_h = nms_h['corrected_hamming_distance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All datasets are of equal length\n"
     ]
    }
   ],
   "source": [
    "c2 = c2_h\n",
    "H = H_h\n",
    "\n",
    "if h.shape[0] + c2.shape[0] - H.shape[0] - oni.shape[0] == 0:\n",
    "    print('All datasets are of equal length')\n",
    "else:\n",
    "    print('warning: datasets not of equal size')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from ninolearn.utils import include_time_lag\n",
    "from ninolearn.IO.read_processed import data_reader\n",
    "\n",
    "version = train_version\n",
    "\n",
    "def train_pipeline(lead_time):\n",
    "    version = train_version\n",
    "    \"\"\"\n",
    "    Data pipeline for the processing of the data before the Deep Ensemble\n",
    "    is trained.\n",
    "\n",
    "    :type lead_time: int\n",
    "    :param lead_time: The lead time in month.\n",
    "\n",
    "    :returns: The feature \"X\" (at observation time), the label \"y\" (at lead\n",
    "    time), the target season \"timey\" (least month)\n",
    "    \"\"\"\n",
    "    timelag=False\n",
    "#     reader = data_reader(startdate='1952-01', enddate='1992-12', lon_min = 124, lon_max = 280,\n",
    "#                          lat_min = -19, lat_max = 19)\n",
    "    reader = data_reader(startdate=(t_start + oneyear), enddate=(t_end - 2*oneyear), lon_min = 124, lon_max = 280,\n",
    "                         lat_min = -19, lat_max = 19)\n",
    "\n",
    "    # indeces\n",
    "    oni = reader.read_csv(('oni_ZC_' +version))\n",
    "    h = reader.read_csv(('h_mean_ZC_' + version))\n",
    "    #IOD unavailable in ZC87 model \n",
    "    \n",
    "    # seasonal cycle\n",
    "    sc = np.cos(np.arange(len(oni))/12*2*np.pi)\n",
    "\n",
    "    # network metrics\n",
    "#     network_ssh = reader.read_statistic('network_metrics', variable='sst', dataset=('ZC_25x25_'+version), processed=\"anom\")\n",
    "#     c2 = network_ssh['fraction_clusters_size_2']\n",
    "#     H = network_ssh['corrected_hamming_distance']\n",
    "\n",
    "    nms_sst = reader.read_statistic('network_metrics', variable='sst', dataset=('ZC_25x25_' + train_version), processed=\"anom\")\n",
    "    nms_h = reader.read_statistic('network_metrics', variable='h', dataset=('ZC_25x25_' + train_version), processed=\"anom\")\n",
    "\n",
    "    c2_sst = nms_sst['fraction_clusters_size_2']\n",
    "    H_sst = nms_sst['corrected_hamming_distance']\n",
    "\n",
    "    c2_h = nms_h['fraction_clusters_size_2']\n",
    "    H_h = nms_h['corrected_hamming_distance']\n",
    "\n",
    "    # time lag\n",
    "    time_lag = 12\n",
    "\n",
    "    # shift such that lead time corresponds to the definition of lead time\n",
    "    shift = 3\n",
    "\n",
    "    # process features\n",
    "    feature_unscaled = np.stack((oni, h, sc,\n",
    "                                 c2_sst, H_sst, c2_h, c2_sst ), axis=1)\n",
    "\n",
    "    # scale each feature\n",
    "    scalerX = StandardScaler()\n",
    "    Xorg = scalerX.fit_transform(feature_unscaled)\n",
    "\n",
    "    # set nans to 0.\n",
    "    Xorg = np.nan_to_num(Xorg)\n",
    "\n",
    "    # arange the feature array\n",
    "    X = Xorg[:-lead_time-shift,:] # this chops of a bit at the end because matching labels will be offset by \n",
    "    # this amount. e.g. if our data runs until 2012 we need to remove X values for 2012 because we will use december 2011\n",
    "    # to predict december 2012 \n",
    "    \n",
    "#     X = include_time_lag(X, max_lag=time_lag)\n",
    "    X = include_time_lag(X, n_lags =time_lag)  # staggers the data with 1 month shifts so at each moment of input also\n",
    "    # nlags amount of months before is available to the AI\n",
    "        \n",
    "    # arange label\n",
    "    yorg = oni.values\n",
    "    y = yorg[lead_time + time_lag + shift:] # labels offset by lead_time to predict into the future and time_lag \n",
    "    # because the include_time_lag function shifts X values forward by an amount n_lags=time_lag\n",
    "    \n",
    "    # get the time axis of the label\n",
    "    timey = oni.index[lead_time + time_lag + shift:]\n",
    "\n",
    "    if timelag == False:\n",
    "        X = Xorg\n",
    "        y = yorg\n",
    "        timey = oni.index\n",
    "        \n",
    "    return X, y, timey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = test_version\n",
    "\n",
    "def test_pipeline(lead_time):\n",
    "    version = test_version\n",
    "\n",
    "    \"\"\"\n",
    "    Data pipeline for the processing of the data before the Deep Ensemble\n",
    "    is trained.\n",
    "\n",
    "    :type lead_time: int\n",
    "    :param lead_time: The lead time in month.\n",
    "\n",
    "    :returns: The feature \"X\" (at observation time), the label \"y\" (at lead\n",
    "    time), the target season \"timey\" (least month)\n",
    "    \"\"\"\n",
    "    timelag=False\n",
    "#     reader = data_reader(startdate='1952-01', enddate='1992-12', lon_min = 124, lon_max = 280,\n",
    "#                          lat_min = -19, lat_max = 19)\n",
    "    reader = data_reader(startdate=(t_start + oneyear), enddate=(t_end - 2*oneyear), lon_min = 124, lon_max = 280,\n",
    "                         lat_min = -19, lat_max = 19)\n",
    "\n",
    "    # indeces\n",
    "    oni = reader.read_csv(('oni_ZC_' +version))\n",
    "    h = reader.read_csv(('h_mean_ZC_' + version))\n",
    "    #IOD unavailable in ZC87 model \n",
    "    \n",
    "    # seasonal cycle\n",
    "    sc = np.cos(np.arange(len(oni))/12*2*np.pi)\n",
    "\n",
    "    # network metrics\n",
    "#     network_ssh = reader.read_statistic('network_metrics', variable='sst', dataset=('ZC_25x25_'+version), processed=\"anom\")\n",
    "#     c2 = network_ssh['fraction_clusters_size_2']\n",
    "#     H = network_ssh['corrected_hamming_distance']\n",
    "    \n",
    "    nms_sst = reader.read_statistic('network_metrics', variable='sst', dataset=('ZC_25x25_' + test_version), processed=\"anom\")\n",
    "    nms_h = reader.read_statistic('network_metrics', variable='h', dataset=('ZC_25x25_' + test_version), processed=\"anom\")\n",
    "\n",
    "    c2_sst = nms_sst['fraction_clusters_size_2']\n",
    "    H_sst = nms_sst['corrected_hamming_distance']\n",
    "\n",
    "    c2_h = nms_h['fraction_clusters_size_2']\n",
    "    H_h = nms_h['corrected_hamming_distance']\n",
    "\n",
    "\n",
    "    # time lag\n",
    "    time_lag = 12\n",
    "\n",
    "    # shift such that lead time corresponds to the definition of lead time\n",
    "    shift = 3\n",
    "\n",
    "    # process features\n",
    "    feature_unscaled = np.stack((oni, h, sc,\n",
    "                                 c2_sst, H_sst, c2_h, c2_sst ), axis=1)\n",
    "\n",
    "    # scale each feature\n",
    "    scalerX = StandardScaler()\n",
    "    Xorg = scalerX.fit_transform(feature_unscaled)\n",
    "\n",
    "    # set nans to 0.\n",
    "    Xorg = np.nan_to_num(Xorg)\n",
    "\n",
    "    # arange the feature array\n",
    "    X = Xorg[:-lead_time-shift,:] # this chops of a bit at the end because matching labels will be offset by \n",
    "    # this amount. e.g. if our data runs until 2012 we need to remove X values for 2012 because we will use december 2011\n",
    "    # to predict december 2012 \n",
    "    \n",
    "#     X = include_time_lag(X, max_lag=time_lag)\n",
    "    X = include_time_lag(X, n_lags =time_lag)  # staggers the data with 1 month shifts so at each moment of input also\n",
    "    # nlags amount of months before is available to the AI\n",
    "        \n",
    "    # arange label\n",
    "    yorg = oni.values\n",
    "    y = yorg[lead_time + time_lag + shift:] # labels offset by lead_time to predict into the future and time_lag \n",
    "    # because the include_time_lag function shifts X values forward by an amount n_lags=time_lag\n",
    "    \n",
    "    # get the time axis of the label\n",
    "    timey = oni.index[lead_time + time_lag + shift:]\n",
    "\n",
    "    if timelag == False:\n",
    "        X = Xorg\n",
    "        y = yorg\n",
    "        timey = oni.index\n",
    "        \n",
    "    return X, y, timey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0, _, _, x3, _, _= *train_pipeline(0), *train_pipeline(3)\n",
    "if x0.shape != x3.shape:\n",
    "    print(\"WARNING: shape mismatch between inputs for different lead times (traindata)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0, _, _, x3, _, _= *test_pipeline(0), *test_pipeline(3)\n",
    "if x0.shape != x3.shape:\n",
    "    print(\"WARNING: shape mismatch between inputs for different lead times (testdata)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the data set\n",
    "\n",
    "For the training and testing of machine learning models it is crucial to split the data set into:\n",
    "\n",
    "1. __Train data set__ which is used to train the weights of the neural network\n",
    "\n",
    "2. __Validation data set__ which is used to check for overfitting (e.g. when using early stopping) and to optimize the hyperparameters \n",
    "\n",
    "3. __Test data set__ which is used to to evaluate the trained model. \n",
    "\n",
    "__NOTE:__ It is important to understand that hyperparamters must be tuned so that the result is best for the Validation data set and __not__ for the test data set. Otherwise you can not rule out the case that the specific hyperparameter setting just works good for the specific test data set but is not generally a good hyperparameter setting.\n",
    "\n",
    "In the following cell the train and the validation data set are still one data set, because this array will be later splitted into two arrays when th model is fitted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import keras.backend as K\n",
    "# from ninolearn.learn.models.dem import DEM\n",
    "\n",
    "# # clear memory from previous sessions\n",
    "# K.clear_session()\n",
    "\n",
    "# # define the lead time\n",
    "# lead_time = leadtime\n",
    "\n",
    "# # get the features (X), the label (y) and \n",
    "# # the time axis of the label (timey)\n",
    "# X, y, timey = pipeline(lead_time)\n",
    "\n",
    "# # split the data set into \n",
    "# # test_indeces = (timey>='1987-01-01') & (timey<='1993-12-01')\n",
    "# test_indeces = (timey>=t_end - pd.Timedelta(5*365, 'D')) & (timey<=t_end)\n",
    "\n",
    "# train_val_indeces = np.invert(test_indeces)\n",
    "\n",
    "# train_val_X, train_val_y, train_val_timey = X[train_val_indeces,:], y[train_val_indeces], timey[train_val_indeces]\n",
    "# testX, testy, testtimey = X[test_indeces,:], y[test_indeces], timey[test_indeces]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(y.shape, X.shape, timey.shape)\n",
    "# print('shapes of the data, labels and time axis is predictable, since there are now 4 features and 12 lags \\\n",
    "#     making for 48 columns. The labels are offset from the input data by the lead time ')\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the model\n",
    "\n",
    "Now it is time to train the model! For this a random search is used for all keyword arguments that are passed in a *list* to the DEM.set_parameters() method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # initiated an instance of the DEM (Deep Ensemble Model) class\n",
    "# model = DEM()\n",
    "\n",
    "# # Set parameters\n",
    "# model.set_hyperparameters(searchtype='linear', layers=1, neurons=16, dropout=[0.1, 0.5], noise_in=[0.1,0.5], noise_sigma=[0.1,0.5],\n",
    "#                      noise_mu=[0.1,0.5], l1_hidden=[0.0, 0.2], l2_hidden=[0., 0.2],\n",
    "#                      l1_mu=[0.0, 0.2], l2_mu=[0.0, 0.2], l1_sigma=[0.0, 0.2],\n",
    "#                      l2_sigma=[0.0, 0.2], lr=[0.0001,0.01], batch_size=100, epochs=500, n_segments=5,\n",
    "#                      n_members_segment=1, patience=30, verbose=0, pdf='normal', activation = 'relu')\n",
    "\n",
    "# # Use a random search to find the optimal hyperparameters\n",
    "\n",
    "# model.fit_RandomizedSearch(train_val_X, train_val_y, train_val_timey, n_iter=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##################################################################\n",
      "Lead time: 0 month\n",
      "##################################################################\n",
      "\n",
      "Test period: 1953-01-01 till 1961-12-01\n",
      "--------------------------------------\n",
      "Search iteration Nr 1/1\n",
      "build\n",
      "Train member Nr 1/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00059: early stopping\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.3146 - nll_gaussian: 0.0808\n",
      "build\n",
      "Train member Nr 2/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00031: early stopping\n",
      "3/3 [==============================] - 0s 5ms/step - loss: -0.1282 - nll_gaussian: -0.3050\n",
      "build\n",
      "Train member Nr 3/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00031: early stopping\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.4538 - nll_gaussian: 0.1075\n",
      "build\n",
      "Train member Nr 4/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00031: early stopping\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4490 - nll_gaussian: 0.1777\n",
      "build\n",
      "Train member Nr 5/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00039: early stopping\n",
      "3/3 [==============================] - 0s 4ms/step - loss: -0.0426 - nll_gaussian: -0.2169\n",
      "Loss: -0.031163205206394196\n",
      "Computation time: 20.1s\n",
      "New best hyperparameters\n",
      "Mean loss: -0.031163205206394196\n",
      "{'layers': 1, 'neurons': 16, 'dropout': 0.23259944185307654, 'noise_in': 0.18486209204804266, 'noise_mu': 0.48276617147059975, 'noise_sigma': 0.22456949647078794, 'noise_alpha': 0.0, 'l1_hidden': 0.13666602059177899, 'l2_hidden': 0.15708994147192157, 'l1_mu': 0.19027508135620033, 'l2_mu': 0.07619038048098566, 'l1_sigma': 0.19942385645825586, 'l2_sigma': 0.1943345257960693, 'l1_alpha': 0.0, 'l2_alpha': 0.0, 'batch_size': 100, 'n_segments': 5, 'n_members_segment': 1, 'lr': 0.007193352833071398, 'patience': 30, 'epochs': 500, 'verbose': 0, 'pdf': 'normal', 'activation': 'relu', 'name': 'dem_de08v4_mu28v4', 'n_members': 5}\n",
      "Test period: 1962-01-01 till 1971-12-01\n",
      "--------------------------------------\n",
      "Search iteration Nr 1/1\n",
      "build\n",
      "Train member Nr 1/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00033: early stopping\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.4620 - nll_gaussian: 0.1044\n",
      "build\n",
      "Train member Nr 2/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00031: early stopping\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4806 - nll_gaussian: 0.0538\n",
      "build\n",
      "Train member Nr 3/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00035: early stopping\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.3714 - nll_gaussian: 0.1934\n",
      "build\n",
      "Train member Nr 4/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00037: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.3508 - nll_gaussian: 0.1565\n",
      "build\n",
      "Train member Nr 5/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00031: early stopping\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.1326 - nll_gaussian: -0.2127\n",
      "Loss: 0.05910128206014633\n",
      "Computation time: 18.8s\n",
      "New best hyperparameters\n",
      "Mean loss: 0.05910128206014633\n",
      "{'layers': 1, 'neurons': 16, 'dropout': 0.23166567119837544, 'noise_in': 0.34905591459900087, 'noise_mu': 0.1374285820774025, 'noise_sigma': 0.15418768152739748, 'noise_alpha': 0.0, 'l1_hidden': 0.11341058811447002, 'l2_hidden': 0.12126407732303585, 'l1_mu': 0.016674662841695276, 'l2_mu': 0.17015430121535302, 'l1_sigma': 0.14086588143628562, 'l2_sigma': 0.10341744562131945, 'l1_alpha': 0.0, 'l2_alpha': 0.0, 'batch_size': 100, 'n_segments': 5, 'n_members_segment': 1, 'lr': 0.0011612723841580319, 'patience': 30, 'epochs': 500, 'verbose': 0, 'pdf': 'normal', 'activation': 'relu', 'name': 'dem_de08v4_mu28v4', 'n_members': 5}\n",
      "Test period: 1972-01-01 till 1981-12-01\n",
      "--------------------------------------\n",
      "Search iteration Nr 1/1\n",
      "build\n",
      "Train member Nr 1/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00031: early stopping\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2573 - nll_gaussian: 0.1035\n",
      "build\n",
      "Train member Nr 2/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00034: early stopping\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.2499 - nll_gaussian: 0.1445\n",
      "build\n",
      "Train member Nr 3/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00031: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -0.0751 - nll_gaussian: -0.1792\n",
      "build\n",
      "Train member Nr 4/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00031: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.1724 - nll_gaussian: 0.0726\n",
      "build\n",
      "Train member Nr 5/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00031: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -0.1260 - nll_gaussian: -0.2051\n",
      "Loss: -0.012733574211597442\n",
      "Computation time: 17.6s\n",
      "New best hyperparameters\n",
      "Mean loss: -0.012733574211597442\n",
      "{'layers': 1, 'neurons': 16, 'dropout': 0.20917234432584508, 'noise_in': 0.4791366453076754, 'noise_mu': 0.47916268536712414, 'noise_sigma': 0.1472852188655013, 'noise_alpha': 0.0, 'l1_hidden': 0.019846878293202933, 'l2_hidden': 0.060620921537668605, 'l1_mu': 0.0962453899986663, 'l2_mu': 0.14850506881307776, 'l1_sigma': 0.004494037504845272, 'l2_sigma': 0.1852388588066507, 'l1_alpha': 0.0, 'l2_alpha': 0.0, 'batch_size': 100, 'n_segments': 5, 'n_members_segment': 1, 'lr': 0.007072349573689932, 'patience': 30, 'epochs': 500, 'verbose': 0, 'pdf': 'normal', 'activation': 'relu', 'name': 'dem_de08v4_mu28v4', 'n_members': 5}\n",
      "Test period: 1982-01-01 till 1991-12-01\n",
      "--------------------------------------\n",
      "Search iteration Nr 1/1\n",
      "build\n",
      "Train member Nr 1/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00046: early stopping\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3045 - nll_gaussian: 0.1139\n",
      "build\n",
      "Train member Nr 2/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00034: early stopping\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2966 - nll_gaussian: 0.1292\n",
      "build\n",
      "Train member Nr 3/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00031: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0741 - nll_gaussian: -0.1857\n",
      "build\n",
      "Train member Nr 4/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00031: early stopping\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0244 - nll_gaussian: 0.0974\n",
      "build\n",
      "Train member Nr 5/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00061: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4406 - nll_gaussian: 0.0498\n",
      "Loss: 0.04089939966797829\n",
      "Computation time: 20.4s\n",
      "New best hyperparameters\n",
      "Mean loss: 0.04089939966797829\n",
      "{'layers': 1, 'neurons': 16, 'dropout': 0.28005460746791677, 'noise_in': 0.32188114135894774, 'noise_mu': 0.44128555921906165, 'noise_sigma': 0.24854051639509644, 'noise_alpha': 0.0, 'l1_hidden': 0.06162659814596563, 'l2_hidden': 0.09050646830924883, 'l1_mu': 0.07763426655229547, 'l2_mu': 0.06685480543883375, 'l1_sigma': 0.10552431270880708, 'l2_sigma': 0.13979780903322167, 'l1_alpha': 0.0, 'l2_alpha': 0.0, 'batch_size': 100, 'n_segments': 5, 'n_members_segment': 1, 'lr': 0.00235064175840003, 'patience': 30, 'epochs': 500, 'verbose': 0, 'pdf': 'normal', 'activation': 'relu', 'name': 'dem_de08v4_mu28v4', 'n_members': 5}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##################################################################\n",
      "Lead time: 3 month\n",
      "##################################################################\n",
      "\n",
      "Test period: 1953-01-01 till 1961-12-01\n",
      "--------------------------------------\n",
      "Search iteration Nr 1/1\n",
      "build\n",
      "Train member Nr 1/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00079: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.3997 - nll_gaussian: 0.0795\n",
      "build\n",
      "Train member Nr 2/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00064: early stopping\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.2079 - nll_gaussian: -0.3610\n",
      "build\n",
      "Train member Nr 3/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00103: early stopping\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.7574 - nll_gaussian: 0.0401\n",
      "build\n",
      "Train member Nr 4/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00036: early stopping\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5289 - nll_gaussian: 0.1744\n",
      "build\n",
      "Train member Nr 5/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00047: early stopping\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2076 - nll_gaussian: -0.2249\n",
      "Loss: -0.058397640287876126\n",
      "Computation time: 28.9s\n",
      "New best hyperparameters\n",
      "Mean loss: -0.058397640287876126\n",
      "{'layers': 1, 'neurons': 16, 'dropout': 0.499474691304335, 'noise_in': 0.3518670291559074, 'noise_mu': 0.25556736353013054, 'noise_sigma': 0.4348767206245715, 'noise_alpha': 0.0, 'l1_hidden': 0.052736180946167256, 'l2_hidden': 0.17544470942739077, 'l1_mu': 0.14364210945262973, 'l2_mu': 0.06838177491215473, 'l1_sigma': 0.12928564219440028, 'l2_sigma': 0.016522353931713, 'l1_alpha': 0.0, 'l2_alpha': 0.0, 'batch_size': 100, 'n_segments': 5, 'n_members_segment': 1, 'lr': 0.005137868399656584, 'patience': 30, 'epochs': 500, 'verbose': 0, 'pdf': 'normal', 'activation': 'relu', 'name': 'dem_de08v4_mu28v4', 'n_members': 5}\n",
      "Test period: 1962-01-01 till 1971-12-01\n",
      "--------------------------------------\n",
      "Search iteration Nr 1/1\n",
      "build\n",
      "Train member Nr 1/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00037: early stopping\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4484 - nll_gaussian: 0.1072\n",
      "build\n",
      "Train member Nr 2/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00193: early stopping\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.3386 - nll_gaussian: 0.0507\n",
      "build\n",
      "Train member Nr 3/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00428: early stopping\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.4036 - nll_gaussian: 0.1916\n",
      "build\n",
      "Train member Nr 4/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00032: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4763 - nll_gaussian: 0.1507\n",
      "build\n",
      "Train member Nr 5/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00087: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0351 - nll_gaussian: -0.2176\n",
      "Loss: 0.05652278885245323\n",
      "Computation time: 61.4s\n",
      "New best hyperparameters\n",
      "Mean loss: 0.05652278885245323\n",
      "{'layers': 1, 'neurons': 16, 'dropout': 0.11367020536922068, 'noise_in': 0.4912379886186262, 'noise_mu': 0.39910013389114185, 'noise_sigma': 0.2398524962476587, 'noise_alpha': 0.0, 'l1_hidden': 0.041221227122464454, 'l2_hidden': 0.1068137182136994, 'l1_mu': 0.17247670554586136, 'l2_mu': 0.1901646102559703, 'l1_sigma': 0.1449837689524984, 'l2_sigma': 0.17822910543433498, 'l1_alpha': 0.0, 'l2_alpha': 0.0, 'batch_size': 100, 'n_segments': 5, 'n_members_segment': 1, 'lr': 0.000248763147327598, 'patience': 30, 'epochs': 500, 'verbose': 0, 'pdf': 'normal', 'activation': 'relu', 'name': 'dem_de08v4_mu28v4', 'n_members': 5}\n",
      "Test period: 1972-01-01 till 1981-12-01\n",
      "--------------------------------------\n",
      "Search iteration Nr 1/1\n",
      "build\n",
      "Train member Nr 1/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00088: early stopping\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.4507 - nll_gaussian: 0.0985\n",
      "build\n",
      "Train member Nr 2/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00078: early stopping\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4191 - nll_gaussian: 0.1167\n",
      "build\n",
      "Train member Nr 3/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00149: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.1083 - nll_gaussian: -0.2026\n",
      "build\n",
      "Train member Nr 4/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00066: early stopping\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.3670 - nll_gaussian: 0.0569\n",
      "build\n",
      "Train member Nr 5/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00080: early stopping\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0773 - nll_gaussian: -0.2332\n",
      "Loss: -0.032746872305870055\n",
      "Computation time: 38.4s\n",
      "New best hyperparameters\n",
      "Mean loss: -0.032746872305870055\n",
      "{'layers': 1, 'neurons': 16, 'dropout': 0.35656338593220116, 'noise_in': 0.29521571665338864, 'noise_mu': 0.19161919941860694, 'noise_sigma': 0.4381206280907143, 'noise_alpha': 0.0, 'l1_hidden': 0.03322234981266608, 'l2_hidden': 0.10129019934401916, 'l1_mu': 0.13924756656509982, 'l2_mu': 0.13805675966998088, 'l1_sigma': 0.09176853755642711, 'l2_sigma': 0.06460882129618084, 'l1_alpha': 0.0, 'l2_alpha': 0.0, 'batch_size': 100, 'n_segments': 5, 'n_members_segment': 1, 'lr': 0.0015447791124674126, 'patience': 30, 'epochs': 500, 'verbose': 0, 'pdf': 'normal', 'activation': 'relu', 'name': 'dem_de08v4_mu28v4', 'n_members': 5}\n",
      "Test period: 1982-01-01 till 1991-12-01\n",
      "--------------------------------------\n",
      "Search iteration Nr 1/1\n",
      "build\n",
      "Train member Nr 1/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00035: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2425 - nll_gaussian: 0.1098\n",
      "build\n",
      "Train member Nr 2/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00053: early stopping\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2953 - nll_gaussian: 0.1303\n",
      "build\n",
      "Train member Nr 3/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00031: early stopping\n",
      "3/3 [==============================] - 0s 6ms/step - loss: -0.0747 - nll_gaussian: -0.1809\n",
      "build\n",
      "Train member Nr 4/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00031: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -0.1393 - nll_gaussian: 0.0951\n",
      "build\n",
      "Train member Nr 5/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00098: early stopping\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2630 - nll_gaussian: -0.1456\n",
      "Loss: 0.0017520874738693238\n",
      "Computation time: 23.4s\n",
      "New best hyperparameters\n",
      "Mean loss: 0.0017520874738693238\n",
      "{'layers': 1, 'neurons': 16, 'dropout': 0.3239147926411453, 'noise_in': 0.24705498904385514, 'noise_mu': 0.32885645525820073, 'noise_sigma': 0.1950397520214401, 'noise_alpha': 0.0, 'l1_hidden': 0.006184588366437116, 'l2_hidden': 0.15196161908918215, 'l1_mu': 0.10267612067288744, 'l2_mu': 0.14996533516252605, 'l1_sigma': 0.06147307422675268, 'l2_sigma': 0.1185043667547044, 'l1_alpha': 0.0, 'l2_alpha': 0.0, 'batch_size': 100, 'n_segments': 5, 'n_members_segment': 1, 'lr': 0.005999832704271619, 'patience': 30, 'epochs': 500, 'verbose': 0, 'pdf': 'normal', 'activation': 'relu', 'name': 'dem_de08v4_mu28v4', 'n_members': 5}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##################################################################\n",
      "Lead time: 6 month\n",
      "##################################################################\n",
      "\n",
      "Test period: 1953-01-01 till 1961-12-01\n",
      "--------------------------------------\n",
      "Search iteration Nr 1/1\n",
      "build\n",
      "Train member Nr 1/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00031: early stopping\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1886 - nll_gaussian: 0.1268\n",
      "build\n",
      "Train member Nr 2/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00052: early stopping\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2529 - nll_gaussian: -0.3442\n",
      "build\n",
      "Train member Nr 3/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00079: early stopping\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.5619 - nll_gaussian: 0.1149\n",
      "build\n",
      "Train member Nr 4/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00031: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4725 - nll_gaussian: 0.1780\n",
      "build\n",
      "Train member Nr 5/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00031: early stopping\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0710 - nll_gaussian: -0.1941\n",
      "Loss: -0.023697668313980104\n",
      "Computation time: 22.2s\n",
      "New best hyperparameters\n",
      "Mean loss: -0.023697668313980104\n",
      "{'layers': 1, 'neurons': 16, 'dropout': 0.2573003771802155, 'noise_in': 0.4225437525004062, 'noise_mu': 0.14303266051935404, 'noise_sigma': 0.24492947903982235, 'noise_alpha': 0.0, 'l1_hidden': 0.1353515911465642, 'l2_hidden': 0.014942040207569174, 'l1_mu': 0.19926324162491096, 'l2_mu': 0.19278161234643804, 'l1_sigma': 0.17672455854500607, 'l2_sigma': 0.09740993415551086, 'l1_alpha': 0.0, 'l2_alpha': 0.0, 'batch_size': 100, 'n_segments': 5, 'n_members_segment': 1, 'lr': 0.006092669298700075, 'patience': 30, 'epochs': 500, 'verbose': 0, 'pdf': 'normal', 'activation': 'relu', 'name': 'dem_de08v4_mu28v4', 'n_members': 5}\n",
      "Test period: 1962-01-01 till 1971-12-01\n",
      "--------------------------------------\n",
      "Search iteration Nr 1/1\n",
      "build\n",
      "Train member Nr 1/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00057: early stopping\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.7469 - nll_gaussian: 0.1181\n",
      "build\n",
      "Train member Nr 2/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00072: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.5895 - nll_gaussian: 0.0166\n",
      "build\n",
      "Train member Nr 3/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00113: early stopping\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.9397 - nll_gaussian: 0.0638\n",
      "build\n",
      "Train member Nr 4/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00085: early stopping\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.9968 - nll_gaussian: 0.0610\n",
      "build\n",
      "Train member Nr 5/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00065: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6312 - nll_gaussian: -0.5010\n",
      "Loss: -0.04828974120318889\n",
      "Computation time: 33.7s\n",
      "New best hyperparameters\n",
      "Mean loss: -0.04828974120318889\n",
      "{'layers': 1, 'neurons': 16, 'dropout': 0.13439012466357714, 'noise_in': 0.26088416067440356, 'noise_mu': 0.42161351372173594, 'noise_sigma': 0.3321428116706062, 'noise_alpha': 0.0, 'l1_hidden': 0.05339539729950946, 'l2_hidden': 0.1834933416780304, 'l1_mu': 0.07820593504383273, 'l2_mu': 0.05581240018276561, 'l1_sigma': 0.1626576021197636, 'l2_sigma': 0.005805573714716306, 'l1_alpha': 0.0, 'l2_alpha': 0.0, 'batch_size': 100, 'n_segments': 5, 'n_members_segment': 1, 'lr': 0.006065845826709917, 'patience': 30, 'epochs': 500, 'verbose': 0, 'pdf': 'normal', 'activation': 'relu', 'name': 'dem_de08v4_mu28v4', 'n_members': 5}\n",
      "Test period: 1972-01-01 till 1981-12-01\n",
      "--------------------------------------\n",
      "Search iteration Nr 1/1\n",
      "build\n",
      "Train member Nr 1/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00137: early stopping\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.4989 - nll_gaussian: 0.0891\n",
      "build\n",
      "Train member Nr 2/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00033: early stopping\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.3581 - nll_gaussian: 0.1342\n",
      "build\n",
      "Train member Nr 3/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00065: early stopping\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0342 - nll_gaussian: -0.2323\n",
      "build\n",
      "Train member Nr 4/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00054: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.3034 - nll_gaussian: 0.0405\n",
      "build\n",
      "Train member Nr 5/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00031: early stopping\n",
      "3/3 [==============================] - 0s 7ms/step - loss: -0.0291 - nll_gaussian: -0.2136\n",
      "Loss: -0.036439172178506854\n",
      "Computation time: 28.8s\n",
      "New best hyperparameters\n",
      "Mean loss: -0.036439172178506854\n",
      "{'layers': 1, 'neurons': 16, 'dropout': 0.1585477429214635, 'noise_in': 0.37356584331666354, 'noise_mu': 0.2647314255356348, 'noise_sigma': 0.4667942097972456, 'noise_alpha': 0.0, 'l1_hidden': 0.0206720588113692, 'l2_hidden': 0.027146946282548545, 'l1_mu': 0.07952631767265711, 'l2_mu': 0.08448705605929004, 'l1_sigma': 0.1263477932540354, 'l2_sigma': 0.16746593375086452, 'l1_alpha': 0.0, 'l2_alpha': 0.0, 'batch_size': 100, 'n_segments': 5, 'n_members_segment': 1, 'lr': 0.002729119964626425, 'patience': 30, 'epochs': 500, 'verbose': 0, 'pdf': 'normal', 'activation': 'relu', 'name': 'dem_de08v4_mu28v4', 'n_members': 5}\n",
      "Test period: 1982-01-01 till 1991-12-01\n",
      "--------------------------------------\n",
      "Search iteration Nr 1/1\n",
      "build\n",
      "Train member Nr 1/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00031: early stopping\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.4192 - nll_gaussian: 0.1106\n",
      "build\n",
      "Train member Nr 2/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00032: early stopping\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.3276 - nll_gaussian: 0.1389\n",
      "build\n",
      "Train member Nr 3/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00031: early stopping\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.0835 - nll_gaussian: -0.1840\n",
      "build\n",
      "Train member Nr 4/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00031: early stopping\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0078 - nll_gaussian: 0.0931\n",
      "build\n",
      "Train member Nr 5/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00031: early stopping\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.3834 - nll_gaussian: 0.0459\n",
      "Loss: 0.04088745787739754\n",
      "Computation time: 16.7s\n",
      "New best hyperparameters\n",
      "Mean loss: 0.04088745787739754\n",
      "{'layers': 1, 'neurons': 16, 'dropout': 0.21246343241758794, 'noise_in': 0.2576249996393377, 'noise_mu': 0.252193782476692, 'noise_sigma': 0.17692499661199804, 'noise_alpha': 0.0, 'l1_hidden': 0.07211824332333132, 'l2_hidden': 0.15548508551661264, 'l1_mu': 0.15846926412893322, 'l2_mu': 0.020246703751557994, 'l1_sigma': 0.09408678252763332, 'l2_sigma': 0.01789816762134564, 'l1_alpha': 0.0, 'l2_alpha': 0.0, 'batch_size': 100, 'n_segments': 5, 'n_members_segment': 1, 'lr': 0.003907308196081003, 'patience': 30, 'epochs': 500, 'verbose': 0, 'pdf': 'normal', 'activation': 'relu', 'name': 'dem_de08v4_mu28v4', 'n_members': 5}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##################################################################\n",
      "Lead time: 9 month\n",
      "##################################################################\n",
      "\n",
      "Test period: 1953-01-01 till 1961-12-01\n",
      "--------------------------------------\n",
      "Search iteration Nr 1/1\n",
      "build\n",
      "Train member Nr 1/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00031: early stopping\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.1056 - nll_gaussian: 0.1391  \n",
      "build\n",
      "Train member Nr 2/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00031: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -0.1288 - nll_gaussian: -0.3080\n",
      "build\n",
      "Train member Nr 3/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00033: early stopping\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.2457 - nll_gaussian: 0.1108\n",
      "build\n",
      "Train member Nr 4/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00037: early stopping\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.2753 - nll_gaussian: 0.1819\n",
      "build\n",
      "Train member Nr 5/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00031: early stopping\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0276 - nll_gaussian: -0.1934\n",
      "Loss: -0.013921479880809783\n",
      "Computation time: 17.6s\n",
      "New best hyperparameters\n",
      "Mean loss: -0.013921479880809783\n",
      "{'layers': 1, 'neurons': 16, 'dropout': 0.1452950250361374, 'noise_in': 0.32719921567623034, 'noise_mu': 0.26512130352190877, 'noise_sigma': 0.2128907096370639, 'noise_alpha': 0.0, 'l1_hidden': 0.111982502852364, 'l2_hidden': 0.11305800044779685, 'l1_mu': 0.08859277449754599, 'l2_mu': 0.06469020345347257, 'l1_sigma': 0.04919273767345376, 'l2_sigma': 0.0683457595044684, 'l1_alpha': 0.0, 'l2_alpha': 0.0, 'batch_size': 100, 'n_segments': 5, 'n_members_segment': 1, 'lr': 0.005804453560468413, 'patience': 30, 'epochs': 500, 'verbose': 0, 'pdf': 'normal', 'activation': 'relu', 'name': 'dem_de08v4_mu28v4', 'n_members': 5}\n",
      "Test period: 1962-01-01 till 1971-12-01\n",
      "--------------------------------------\n",
      "Search iteration Nr 1/1\n",
      "build\n",
      "Train member Nr 1/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00175: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -0.2862 - nll_gaussian: -0.4677\n",
      "build\n",
      "Train member Nr 2/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00159: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -0.2166 - nll_gaussian: -0.3657\n",
      "build\n",
      "Train member Nr 3/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00084: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -0.2958 - nll_gaussian: -0.4725\n",
      "build\n",
      "Train member Nr 4/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00134: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -0.1994 - nll_gaussian: -0.3457\n",
      "build\n",
      "Train member Nr 5/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00108: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -0.3739 - nll_gaussian: -0.5374\n",
      "Loss: -0.4378213107585907\n",
      "Computation time: 50.8s\n",
      "New best hyperparameters\n",
      "Mean loss: -0.4378213107585907\n",
      "{'layers': 1, 'neurons': 16, 'dropout': 0.20228041763666332, 'noise_in': 0.11911500843004373, 'noise_mu': 0.4006863527705905, 'noise_sigma': 0.1335398158290837, 'noise_alpha': 0.0, 'l1_hidden': 0.043620498143148216, 'l2_hidden': 0.026782198004896673, 'l1_mu': 0.017194653510969892, 'l2_mu': 0.13782883439148103, 'l1_sigma': 0.028112943656158997, 'l2_sigma': 0.049393107426034914, 'l1_alpha': 0.0, 'l2_alpha': 0.0, 'batch_size': 100, 'n_segments': 5, 'n_members_segment': 1, 'lr': 0.0037174947155065277, 'patience': 30, 'epochs': 500, 'verbose': 0, 'pdf': 'normal', 'activation': 'relu', 'name': 'dem_de08v4_mu28v4', 'n_members': 5}\n",
      "Test period: 1972-01-01 till 1981-12-01\n",
      "--------------------------------------\n",
      "Search iteration Nr 1/1\n",
      "build\n",
      "Train member Nr 1/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00070: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.6283 - nll_gaussian: 0.0362\n",
      "build\n",
      "Train member Nr 2/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00175: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.7018 - nll_gaussian: -0.2493\n",
      "build\n",
      "Train member Nr 3/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00031: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.3911 - nll_gaussian: -0.1716\n",
      "build\n",
      "Train member Nr 4/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00036: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.8565 - nll_gaussian: 0.0814\n",
      "build\n",
      "Train member Nr 5/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00053: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.7978 - nll_gaussian: -0.2342\n",
      "Loss: -0.10749604031443596\n",
      "Computation time: 32.0s\n",
      "New best hyperparameters\n",
      "Mean loss: -0.10749604031443596\n",
      "{'layers': 1, 'neurons': 16, 'dropout': 0.36016772580614786, 'noise_in': 0.2173344970967111, 'noise_mu': 0.4662192131705182, 'noise_sigma': 0.4830723879443023, 'noise_alpha': 0.0, 'l1_hidden': 0.11946584433568919, 'l2_hidden': 0.12801315405415256, 'l1_mu': 0.14517648467154157, 'l2_mu': 0.048013253360434896, 'l1_sigma': 0.07389437982247658, 'l2_sigma': 0.16978024261220925, 'l1_alpha': 0.0, 'l2_alpha': 0.0, 'batch_size': 100, 'n_segments': 5, 'n_members_segment': 1, 'lr': 0.008506900888537741, 'patience': 30, 'epochs': 500, 'verbose': 0, 'pdf': 'normal', 'activation': 'relu', 'name': 'dem_de08v4_mu28v4', 'n_members': 5}\n",
      "Test period: 1982-01-01 till 1991-12-01\n",
      "--------------------------------------\n",
      "Search iteration Nr 1/1\n",
      "build\n",
      "Train member Nr 1/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00081: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.0445 - nll_gaussian: 0.0914\n",
      "build\n",
      "Train member Nr 2/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00085: early stopping\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9827 - nll_gaussian: 0.0870\n",
      "build\n",
      "Train member Nr 3/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00050: early stopping\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5705 - nll_gaussian: -0.2048\n",
      "build\n",
      "Train member Nr 4/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00110: early stopping\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.5950 - nll_gaussian: -0.0042\n",
      "build\n",
      "Train member Nr 5/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00055: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.9112 - nll_gaussian: 0.0263\n",
      "Loss: -0.0008628208190202713\n",
      "Computation time: 32.9s\n",
      "New best hyperparameters\n",
      "Mean loss: -0.0008628208190202713\n",
      "{'layers': 1, 'neurons': 16, 'dropout': 0.3513749314919511, 'noise_in': 0.1827101579429518, 'noise_mu': 0.1565585680442746, 'noise_sigma': 0.3425774369680586, 'noise_alpha': 0.0, 'l1_hidden': 0.19690500688048485, 'l2_hidden': 0.134603760146669, 'l1_mu': 0.07972334520959062, 'l2_mu': 0.1605072693834619, 'l1_sigma': 0.096986006707244, 'l2_sigma': 0.0642819917815414, 'l1_alpha': 0.0, 'l2_alpha': 0.0, 'batch_size': 100, 'n_segments': 5, 'n_members_segment': 1, 'lr': 0.004257467799563812, 'patience': 30, 'epochs': 500, 'verbose': 0, 'pdf': 'normal', 'activation': 'relu', 'name': 'dem_de08v4_mu28v4', 'n_members': 5}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##################################################################\n",
      "Lead time: 12 month\n",
      "##################################################################\n",
      "\n",
      "Test period: 1953-01-01 till 1961-12-01\n",
      "--------------------------------------\n",
      "Search iteration Nr 1/1\n",
      "build\n",
      "Train member Nr 1/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00061: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.3084 - nll_gaussian: 0.1245\n",
      "build\n",
      "Train member Nr 2/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00099: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.5292 - nll_gaussian: -0.4467\n",
      "build\n",
      "Train member Nr 3/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00219: early stopping\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.8058 - nll_gaussian: 0.0788\n",
      "build\n",
      "Train member Nr 4/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00133: early stopping\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.9398 - nll_gaussian: 0.1037\n",
      "build\n",
      "Train member Nr 5/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00046: early stopping\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.1981 - nll_gaussian: -0.2298\n",
      "Loss: -0.07389848828315734\n",
      "Computation time: 46.1s\n",
      "New best hyperparameters\n",
      "Mean loss: -0.07389848828315734\n",
      "{'layers': 1, 'neurons': 16, 'dropout': 0.24321512996875222, 'noise_in': 0.2664238047845765, 'noise_mu': 0.39982441220754394, 'noise_sigma': 0.3779320137385652, 'noise_alpha': 0.0, 'l1_hidden': 0.07065345803719492, 'l2_hidden': 0.02123526507530431, 'l1_mu': 0.16076900205096323, 'l2_mu': 0.029370431897151897, 'l1_sigma': 0.18183731224147698, 'l2_sigma': 0.09065450203466055, 'l1_alpha': 0.0, 'l2_alpha': 0.0, 'batch_size': 100, 'n_segments': 5, 'n_members_segment': 1, 'lr': 0.0033257983646190503, 'patience': 30, 'epochs': 500, 'verbose': 0, 'pdf': 'normal', 'activation': 'relu', 'name': 'dem_de08v4_mu28v4', 'n_members': 5}\n",
      "Test period: 1962-01-01 till 1971-12-01\n",
      "--------------------------------------\n",
      "Search iteration Nr 1/1\n",
      "build\n",
      "Train member Nr 1/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00415: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0555 - nll_gaussian: -0.2009\n",
      "build\n",
      "Train member Nr 2/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00208: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -0.0046 - nll_gaussian: -0.2415\n",
      "build\n",
      "Train member Nr 3/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00220: early stopping\n",
      "3/3 [==============================] - 0s 6ms/step - loss: -0.0212 - nll_gaussian: -0.2066\n",
      "build\n",
      "Train member Nr 4/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00235: early stopping\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.0441 - nll_gaussian: -0.1274\n",
      "build\n",
      "Train member Nr 5/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00031: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -0.0752 - nll_gaussian: -0.2135\n",
      "Loss: -0.1979864716529846\n",
      "Computation time: 80.6s\n",
      "New best hyperparameters\n",
      "Mean loss: -0.1979864716529846\n",
      "{'layers': 1, 'neurons': 16, 'dropout': 0.23882676321712873, 'noise_in': 0.4192636043737018, 'noise_mu': 0.3548980044285156, 'noise_sigma': 0.18205564102282865, 'noise_alpha': 0.0, 'l1_hidden': 0.03196424735415795, 'l2_hidden': 0.17802868489912593, 'l1_mu': 0.006756408848017027, 'l2_mu': 0.18716270272705898, 'l1_sigma': 0.004486874485621595, 'l2_sigma': 0.1262529218341989, 'l1_alpha': 0.0, 'l2_alpha': 0.0, 'batch_size': 100, 'n_segments': 5, 'n_members_segment': 1, 'lr': 0.0014694949680101371, 'patience': 30, 'epochs': 500, 'verbose': 0, 'pdf': 'normal', 'activation': 'relu', 'name': 'dem_de08v4_mu28v4', 'n_members': 5}\n",
      "Test period: 1972-01-01 till 1981-12-01\n",
      "--------------------------------------\n",
      "Search iteration Nr 1/1\n",
      "build\n",
      "Train member Nr 1/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00078: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.1937 - nll_gaussian: 0.0140\n",
      "build\n",
      "Train member Nr 2/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00056: early stopping\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.8562 - nll_gaussian: 0.1160\n",
      "build\n",
      "Train member Nr 3/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00033: early stopping\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.1470 - nll_gaussian: -0.1947\n",
      "build\n",
      "Train member Nr 4/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00033: early stopping\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5434 - nll_gaussian: 0.0683\n",
      "build\n",
      "Train member Nr 5/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00055: early stopping\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7843 - nll_gaussian: -0.2745\n",
      "Loss: -0.05416019167751074\n",
      "Computation time: 25.4s\n",
      "New best hyperparameters\n",
      "Mean loss: -0.05416019167751074\n",
      "{'layers': 1, 'neurons': 16, 'dropout': 0.49805193068073694, 'noise_in': 0.3445251987998031, 'noise_mu': 0.4364059942455404, 'noise_sigma': 0.4020630721802496, 'noise_alpha': 0.0, 'l1_hidden': 0.11464843740803593, 'l2_hidden': 0.18257128814135667, 'l1_mu': 0.014524615091934746, 'l2_mu': 0.1597355324177478, 'l1_sigma': 0.13113423337576902, 'l2_sigma': 0.166003512283039, 'l1_alpha': 0.0, 'l2_alpha': 0.0, 'batch_size': 100, 'n_segments': 5, 'n_members_segment': 1, 'lr': 0.0059348792734004235, 'patience': 30, 'epochs': 500, 'verbose': 0, 'pdf': 'normal', 'activation': 'relu', 'name': 'dem_de08v4_mu28v4', 'n_members': 5}\n",
      "Test period: 1982-01-01 till 1991-12-01\n",
      "--------------------------------------\n",
      "Search iteration Nr 1/1\n",
      "build\n",
      "Train member Nr 1/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00063: early stopping\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.9803 - nll_gaussian: 0.0806\n",
      "build\n",
      "Train member Nr 2/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00048: early stopping\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.7915 - nll_gaussian: 0.1137\n",
      "build\n",
      "Train member Nr 3/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00123: early stopping\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.6286 - nll_gaussian: -0.2466\n",
      "build\n",
      "Train member Nr 4/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00035: early stopping\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 0.2113 - nll_gaussian: 0.0724\n",
      "build\n",
      "Train member Nr 5/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00086: early stopping\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.8130 - nll_gaussian: -0.0196\n",
      "Loss: 0.00013876818120479585\n",
      "Computation time: 32.4s\n",
      "New best hyperparameters\n",
      "Mean loss: 0.00013876818120479585\n",
      "{'layers': 1, 'neurons': 16, 'dropout': 0.24554932754887662, 'noise_in': 0.34124925854095967, 'noise_mu': 0.46982172332522065, 'noise_sigma': 0.49496305517319017, 'noise_alpha': 0.0, 'l1_hidden': 0.10208366654690888, 'l2_hidden': 0.1403278171794174, 'l1_mu': 0.0552424218914466, 'l2_mu': 0.0403027581020043, 'l1_sigma': 0.17048860011988257, 'l2_sigma': 0.04103564350243658, 'l1_alpha': 0.0, 'l2_alpha': 0.0, 'batch_size': 100, 'n_segments': 5, 'n_members_segment': 1, 'lr': 0.004365397091387514, 'patience': 30, 'epochs': 500, 'verbose': 0, 'pdf': 'normal', 'activation': 'relu', 'name': 'dem_de08v4_mu28v4', 'n_members': 5}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##################################################################\n",
      "Lead time: 15 month\n",
      "##################################################################\n",
      "\n",
      "Test period: 1953-01-01 till 1961-12-01\n",
      "--------------------------------------\n",
      "Search iteration Nr 1/1\n",
      "build\n",
      "Train member Nr 1/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00047: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.1220 - nll_gaussian: 0.1476\n",
      "build\n",
      "Train member Nr 2/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00052: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -0.1445 - nll_gaussian: -0.3300\n",
      "build\n",
      "Train member Nr 3/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00073: early stopping\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.3860 - nll_gaussian: 0.1095\n",
      "build\n",
      "Train member Nr 4/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00079: early stopping\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 0.5179 - nll_gaussian: 0.1615\n",
      "build\n",
      "Train member Nr 5/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00031: early stopping\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -0.0109 - nll_gaussian: -0.1971\n",
      "Loss: -0.021703940629959107\n",
      "Computation time: 34.7s\n",
      "New best hyperparameters\n",
      "Mean loss: -0.021703940629959107\n",
      "{'layers': 1, 'neurons': 16, 'dropout': 0.3861047481623242, 'noise_in': 0.39177210537898477, 'noise_mu': 0.4187339089427934, 'noise_sigma': 0.27904989278943804, 'noise_alpha': 0.0, 'l1_hidden': 0.04918815865707041, 'l2_hidden': 0.03233151562446295, 'l1_mu': 0.09907026436900078, 'l2_mu': 0.0186957228676637, 'l1_sigma': 0.05416324322926114, 'l2_sigma': 0.052657791262514825, 'l1_alpha': 0.0, 'l2_alpha': 0.0, 'batch_size': 100, 'n_segments': 5, 'n_members_segment': 1, 'lr': 0.0029700852439598657, 'patience': 30, 'epochs': 500, 'verbose': 0, 'pdf': 'normal', 'activation': 'relu', 'name': 'dem_de08v4_mu28v4', 'n_members': 5}\n",
      "Test period: 1962-01-01 till 1971-12-01\n",
      "--------------------------------------\n",
      "Search iteration Nr 1/1\n",
      "build\n",
      "Train member Nr 1/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00068: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2034 - nll_gaussian: 0.0233\n",
      "build\n",
      "Train member Nr 2/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00031: early stopping\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 0.3100 - nll_gaussian: 0.0553\n",
      "build\n",
      "Train member Nr 3/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00207: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2317 - nll_gaussian: -0.0569\n",
      "build\n",
      "Train member Nr 4/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00374: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0578 - nll_gaussian: -0.5841\n",
      "build\n",
      "Train member Nr 5/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00031: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 8.1253e-04 - nll_gaussian: -0.2103\n",
      "Loss: -0.15453056581318378\n",
      "Computation time: 70.0s\n",
      "New best hyperparameters\n",
      "Mean loss: -0.15453056581318378\n",
      "{'layers': 1, 'neurons': 16, 'dropout': 0.33720783505115876, 'noise_in': 0.42887089791440547, 'noise_mu': 0.11485743152909347, 'noise_sigma': 0.20330910132489777, 'noise_alpha': 0.0, 'l1_hidden': 0.07298304713545771, 'l2_hidden': 0.024954341010330606, 'l1_mu': 0.052727647662916245, 'l2_mu': 0.1540064739411211, 'l1_sigma': 0.1662275961301494, 'l2_sigma': 0.13114341185272657, 'l1_alpha': 0.0, 'l2_alpha': 0.0, 'batch_size': 100, 'n_segments': 5, 'n_members_segment': 1, 'lr': 0.004601771915781346, 'patience': 30, 'epochs': 500, 'verbose': 0, 'pdf': 'normal', 'activation': 'relu', 'name': 'dem_de08v4_mu28v4', 'n_members': 5}\n",
      "Test period: 1972-01-01 till 1981-12-01\n",
      "--------------------------------------\n",
      "Search iteration Nr 1/1\n",
      "build\n",
      "Train member Nr 1/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00060: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.5109 - nll_gaussian: 0.0024\n",
      "build\n",
      "Train member Nr 2/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00063: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.9360 - nll_gaussian: 0.1399\n",
      "build\n",
      "Train member Nr 3/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00031: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.3014 - nll_gaussian: -0.2019\n",
      "build\n",
      "Train member Nr 4/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00070: early stopping\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.2224 - nll_gaussian: 0.0572\n",
      "build\n",
      "Train member Nr 5/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00037: early stopping\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2784 - nll_gaussian: -0.2238\n",
      "Loss: -0.04524854025803506\n",
      "Computation time: 28.5s\n",
      "New best hyperparameters\n",
      "Mean loss: -0.04524854025803506\n",
      "{'layers': 1, 'neurons': 16, 'dropout': 0.12329455737169895, 'noise_in': 0.22041024448856428, 'noise_mu': 0.2042710310596274, 'noise_sigma': 0.37392374503999704, 'noise_alpha': 0.0, 'l1_hidden': 0.12347411303447631, 'l2_hidden': 0.1504108922302811, 'l1_mu': 0.029468392060844152, 'l2_mu': 0.1908478724555869, 'l1_sigma': 0.198421885776908, 'l2_sigma': 0.12779470415304012, 'l1_alpha': 0.0, 'l2_alpha': 0.0, 'batch_size': 100, 'n_segments': 5, 'n_members_segment': 1, 'lr': 0.006604623737345204, 'patience': 30, 'epochs': 500, 'verbose': 0, 'pdf': 'normal', 'activation': 'relu', 'name': 'dem_de08v4_mu28v4', 'n_members': 5}\n",
      "Test period: 1982-01-01 till 1991-12-01\n",
      "--------------------------------------\n",
      "Search iteration Nr 1/1\n",
      "build\n",
      "Train member Nr 1/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00093: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.3164 - nll_gaussian: 0.1074\n",
      "build\n",
      "Train member Nr 2/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00062: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.3198 - nll_gaussian: 0.1266\n",
      "build\n",
      "Train member Nr 3/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00055: early stopping\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -0.0278 - nll_gaussian: -0.1895\n",
      "build\n",
      "Train member Nr 4/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00052: early stopping\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -0.0953 - nll_gaussian: 0.0826\n",
      "build\n",
      "Train member Nr 5/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00046: early stopping\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.2731 - nll_gaussian: 0.0459\n",
      "Loss: 0.034594430774450305\n",
      "Computation time: 31.3s\n",
      "New best hyperparameters\n",
      "Mean loss: 0.034594430774450305\n",
      "{'layers': 1, 'neurons': 16, 'dropout': 0.12278249791166847, 'noise_in': 0.10333054638622233, 'noise_mu': 0.3587209043065267, 'noise_sigma': 0.4527808978550073, 'noise_alpha': 0.0, 'l1_hidden': 0.010232915713489766, 'l2_hidden': 0.06912013297624973, 'l1_mu': 0.005673919033058961, 'l2_mu': 0.19631587606077047, 'l1_sigma': 0.14886458661999144, 'l2_sigma': 0.13377201771999864, 'l1_alpha': 0.0, 'l2_alpha': 0.0, 'batch_size': 100, 'n_segments': 5, 'n_members_segment': 1, 'lr': 0.0002721022186311017, 'patience': 30, 'epochs': 500, 'verbose': 0, 'pdf': 'normal', 'activation': 'relu', 'name': 'dem_de08v4_mu28v4', 'n_members': 5}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##################################################################\n",
      "Lead time: 18 month\n",
      "##################################################################\n",
      "\n",
      "Test period: 1953-01-01 till 1961-12-01\n",
      "--------------------------------------\n",
      "Search iteration Nr 1/1\n",
      "build\n",
      "Train member Nr 1/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00031: early stopping\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.0752 - nll_gaussian: 0.1261\n",
      "build\n",
      "Train member Nr 2/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00031: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -0.1655 - nll_gaussian: -0.3049\n",
      "build\n",
      "Train member Nr 3/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00033: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2189 - nll_gaussian: 0.1142\n",
      "build\n",
      "Train member Nr 4/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00041: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2525 - nll_gaussian: 0.1787\n",
      "build\n",
      "Train member Nr 5/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00031: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -0.0343 - nll_gaussian: -0.1936\n",
      "Loss: -0.015898670256137847\n",
      "Computation time: 17.7s\n",
      "New best hyperparameters\n",
      "Mean loss: -0.015898670256137847\n",
      "{'layers': 1, 'neurons': 16, 'dropout': 0.21197767573503576, 'noise_in': 0.38258936432835666, 'noise_mu': 0.4671789214375178, 'noise_sigma': 0.15910103494513528, 'noise_alpha': 0.0, 'l1_hidden': 0.09033032898654919, 'l2_hidden': 0.07217649495030275, 'l1_mu': 0.15306642414959526, 'l2_mu': 0.09479536071301159, 'l1_sigma': 0.015280693159858628, 'l2_sigma': 0.10977355986698632, 'l1_alpha': 0.0, 'l2_alpha': 0.0, 'batch_size': 100, 'n_segments': 5, 'n_members_segment': 1, 'lr': 0.006386860547105838, 'patience': 30, 'epochs': 500, 'verbose': 0, 'pdf': 'normal', 'activation': 'relu', 'name': 'dem_de08v4_mu28v4', 'n_members': 5}\n",
      "Test period: 1962-01-01 till 1971-12-01\n",
      "--------------------------------------\n",
      "Search iteration Nr 1/1\n",
      "build\n",
      "Train member Nr 1/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00238: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4282 - nll_gaussian: 0.0668\n",
      "build\n",
      "Train member Nr 2/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00144: early stopping\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.3690 - nll_gaussian: 0.0386\n",
      "build\n",
      "Train member Nr 3/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00033: early stopping\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.3064 - nll_gaussian: 0.1901\n",
      "build\n",
      "Train member Nr 4/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00055: early stopping\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.3575 - nll_gaussian: 0.1377\n",
      "build\n",
      "Train member Nr 5/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00053: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: -0.0494 - nll_gaussian: -0.2257\n",
      "Loss: 0.04151611477136612\n",
      "Computation time: 42.3s\n",
      "New best hyperparameters\n",
      "Mean loss: 0.04151611477136612\n",
      "{'layers': 1, 'neurons': 16, 'dropout': 0.10771140998461669, 'noise_in': 0.39895477692076675, 'noise_mu': 0.42034368571147296, 'noise_sigma': 0.4596432812305947, 'noise_alpha': 0.0, 'l1_hidden': 0.020846868911135675, 'l2_hidden': 0.14023447845503942, 'l1_mu': 0.08049055176974221, 'l2_mu': 0.05143521311733954, 'l1_sigma': 0.011538559635645186, 'l2_sigma': 0.007999948098224819, 'l1_alpha': 0.0, 'l2_alpha': 0.0, 'batch_size': 100, 'n_segments': 5, 'n_members_segment': 1, 'lr': 0.002896170068075296, 'patience': 30, 'epochs': 500, 'verbose': 0, 'pdf': 'normal', 'activation': 'relu', 'name': 'dem_de08v4_mu28v4', 'n_members': 5}\n",
      "Test period: 1972-01-01 till 1981-12-01\n",
      "--------------------------------------\n",
      "Search iteration Nr 1/1\n",
      "build\n",
      "Train member Nr 1/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00032: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.3934 - nll_gaussian: 0.1073\n",
      "build\n",
      "Train member Nr 2/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00031: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4776 - nll_gaussian: 0.1374\n",
      "build\n",
      "Train member Nr 3/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00031: early stopping\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.1792 - nll_gaussian: -0.1842\n",
      "build\n",
      "Train member Nr 4/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00031: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4141 - nll_gaussian: 0.0778\n",
      "build\n",
      "Train member Nr 5/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00031: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0921 - nll_gaussian: -0.2106\n",
      "Loss: -0.014481280744075776\n",
      "Computation time: 17.3s\n",
      "New best hyperparameters\n",
      "Mean loss: -0.014481280744075776\n",
      "{'layers': 1, 'neurons': 16, 'dropout': 0.27030480491578246, 'noise_in': 0.11956232747213519, 'noise_mu': 0.17357573688599393, 'noise_sigma': 0.12189722730318762, 'noise_alpha': 0.0, 'l1_hidden': 0.16498555514197807, 'l2_hidden': 0.03919990762468761, 'l1_mu': 0.08982207643788105, 'l2_mu': 0.09336255745138276, 'l1_sigma': 0.013197579638141256, 'l2_sigma': 0.15349729231329137, 'l1_alpha': 0.0, 'l2_alpha': 0.0, 'batch_size': 100, 'n_segments': 5, 'n_members_segment': 1, 'lr': 0.004170699656300957, 'patience': 30, 'epochs': 500, 'verbose': 0, 'pdf': 'normal', 'activation': 'relu', 'name': 'dem_de08v4_mu28v4', 'n_members': 5}\n",
      "Test period: 1982-01-01 till 1991-12-01\n",
      "--------------------------------------\n",
      "Search iteration Nr 1/1\n",
      "build\n",
      "Train member Nr 1/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00031: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4987 - nll_gaussian: 0.1112\n",
      "build\n",
      "Train member Nr 2/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00035: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4989 - nll_gaussian: 0.1321\n",
      "build\n",
      "Train member Nr 3/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00031: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.1640 - nll_gaussian: -0.1917\n",
      "build\n",
      "Train member Nr 4/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00036: early stopping\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.1188 - nll_gaussian: 0.0619\n",
      "build\n",
      "Train member Nr 5/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00092: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6899 - nll_gaussian: 0.0588\n",
      "Loss: 0.034482046216726306\n",
      "Computation time: 22.5s\n",
      "New best hyperparameters\n",
      "Mean loss: 0.034482046216726306\n",
      "{'layers': 1, 'neurons': 16, 'dropout': 0.35089972078401077, 'noise_in': 0.4965243306463155, 'noise_mu': 0.40162655254924207, 'noise_sigma': 0.30310609726011184, 'noise_alpha': 0.0, 'l1_hidden': 0.059650281576207866, 'l2_hidden': 0.09916323212104426, 'l1_mu': 0.16446539974869182, 'l2_mu': 0.19682779242355802, 'l1_sigma': 0.19557656567047005, 'l2_sigma': 0.06631826362931548, 'l1_alpha': 0.0, 'l2_alpha': 0.0, 'batch_size': 100, 'n_segments': 5, 'n_members_segment': 1, 'lr': 0.004142400932050619, 'patience': 30, 'epochs': 500, 'verbose': 0, 'pdf': 'normal', 'activation': 'relu', 'name': 'dem_de08v4_mu28v4', 'n_members': 5}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##################################################################\n",
      "Lead time: 21 month\n",
      "##################################################################\n",
      "\n",
      "Test period: 1953-01-01 till 1961-12-01\n",
      "--------------------------------------\n",
      "Search iteration Nr 1/1\n",
      "build\n",
      "Train member Nr 1/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00062: early stopping\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.5736 - nll_gaussian: 0.0331\n",
      "build\n",
      "Train member Nr 2/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00034: early stopping\n",
      "3/3 [==============================] - 0s 3ms/step - loss: -0.0431 - nll_gaussian: -0.3177\n",
      "build\n",
      "Train member Nr 3/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00045: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4534 - nll_gaussian: 0.1076\n",
      "build\n",
      "Train member Nr 4/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00046: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.7715 - nll_gaussian: 0.1579\n",
      "build\n",
      "Train member Nr 5/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00031: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0541 - nll_gaussian: -0.1921\n",
      "Loss: -0.04225505962967872\n",
      "Computation time: 22.4s\n",
      "New best hyperparameters\n",
      "Mean loss: -0.04225505962967872\n",
      "{'layers': 1, 'neurons': 16, 'dropout': 0.45054050948672364, 'noise_in': 0.15113914070317788, 'noise_mu': 0.4118829988301026, 'noise_sigma': 0.3060396391038124, 'noise_alpha': 0.0, 'l1_hidden': 0.08747227488580432, 'l2_hidden': 0.1514484333618903, 'l1_mu': 0.06479985858396045, 'l2_mu': 0.10756139858551879, 'l1_sigma': 0.10672035916234722, 'l2_sigma': 0.14336358900199492, 'l1_alpha': 0.0, 'l2_alpha': 0.0, 'batch_size': 100, 'n_segments': 5, 'n_members_segment': 1, 'lr': 0.007742238722228719, 'patience': 30, 'epochs': 500, 'verbose': 0, 'pdf': 'normal', 'activation': 'relu', 'name': 'dem_de08v4_mu28v4', 'n_members': 5}\n",
      "Test period: 1962-01-01 till 1971-12-01\n",
      "--------------------------------------\n",
      "Search iteration Nr 1/1\n",
      "build\n",
      "Train member Nr 1/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00111: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2249 - nll_gaussian: 0.1204\n",
      "build\n",
      "Train member Nr 2/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00036: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.5819 - nll_gaussian: 0.0568\n",
      "build\n",
      "Train member Nr 3/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00099: early stopping\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.1990 - nll_gaussian: 0.1916\n",
      "build\n",
      "Train member Nr 4/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00085: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2377 - nll_gaussian: 0.1655\n",
      "build\n",
      "Train member Nr 5/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00031: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.3684 - nll_gaussian: -0.2141\n",
      "Loss: 0.06404589936137199\n",
      "Computation time: 32.6s\n",
      "New best hyperparameters\n",
      "Mean loss: 0.06404589936137199\n",
      "{'layers': 1, 'neurons': 16, 'dropout': 0.10301342021036551, 'noise_in': 0.19926038868685358, 'noise_mu': 0.334863990857428, 'noise_sigma': 0.10678351221682361, 'noise_alpha': 0.0, 'l1_hidden': 0.1905184247565781, 'l2_hidden': 0.07429009424330948, 'l1_mu': 0.09984935968236397, 'l2_mu': 0.03583992525055684, 'l1_sigma': 0.15585514801151454, 'l2_sigma': 0.13694460295813993, 'l1_alpha': 0.0, 'l2_alpha': 0.0, 'batch_size': 100, 'n_segments': 5, 'n_members_segment': 1, 'lr': 0.0006250811429207652, 'patience': 30, 'epochs': 500, 'verbose': 0, 'pdf': 'normal', 'activation': 'relu', 'name': 'dem_de08v4_mu28v4', 'n_members': 5}\n",
      "Test period: 1972-01-01 till 1981-12-01\n",
      "--------------------------------------\n",
      "Search iteration Nr 1/1\n",
      "build\n",
      "Train member Nr 1/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00055: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.0170 - nll_gaussian: 0.0451\n",
      "build\n",
      "Train member Nr 2/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00062: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.4307 - nll_gaussian: 0.1223\n",
      "build\n",
      "Train member Nr 3/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00031: early stopping\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.3427 - nll_gaussian: -0.1815\n",
      "build\n",
      "Train member Nr 4/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00102: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 2.2621 - nll_gaussian: -0.0862\n",
      "build\n",
      "Train member Nr 5/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00109: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.4901 - nll_gaussian: -0.3454\n",
      "Loss: -0.0891260601580143\n",
      "Computation time: 31.9s\n",
      "New best hyperparameters\n",
      "Mean loss: -0.0891260601580143\n",
      "{'layers': 1, 'neurons': 16, 'dropout': 0.43227401192125814, 'noise_in': 0.4205518151450862, 'noise_mu': 0.125044805981292, 'noise_sigma': 0.35085394576147977, 'noise_alpha': 0.0, 'l1_hidden': 0.17977583500339384, 'l2_hidden': 0.10404152141230621, 'l1_mu': 0.046620843570088846, 'l2_mu': 0.11315461052544554, 'l1_sigma': 0.19227927826510116, 'l2_sigma': 0.14484080880515063, 'l1_alpha': 0.0, 'l2_alpha': 0.0, 'batch_size': 100, 'n_segments': 5, 'n_members_segment': 1, 'lr': 0.007015927429509301, 'patience': 30, 'epochs': 500, 'verbose': 0, 'pdf': 'normal', 'activation': 'relu', 'name': 'dem_de08v4_mu28v4', 'n_members': 5}\n",
      "Test period: 1982-01-01 till 1991-12-01\n",
      "--------------------------------------\n",
      "Search iteration Nr 1/1\n",
      "build\n",
      "Train member Nr 1/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00060: early stopping\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.3270 - nll_gaussian: 0.1050\n",
      "build\n",
      "Train member Nr 2/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00058: early stopping\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.3173 - nll_gaussian: 0.1250\n",
      "build\n",
      "Train member Nr 3/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00031: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.1592 - nll_gaussian: -0.1869\n",
      "build\n",
      "Train member Nr 4/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00031: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.1095 - nll_gaussian: 0.0863\n",
      "build\n",
      "Train member Nr 5/5\n",
      "--------------------------------------\n",
      "compile\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00031: early stopping\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4951 - nll_gaussian: 0.0451\n",
      "Loss: 0.03490376099944115\n",
      "Computation time: 22.8s\n",
      "New best hyperparameters\n",
      "Mean loss: 0.03490376099944115\n",
      "{'layers': 1, 'neurons': 16, 'dropout': 0.4665983313873856, 'noise_in': 0.232514942326516, 'noise_mu': 0.11940326111699379, 'noise_sigma': 0.22456580162587755, 'noise_alpha': 0.0, 'l1_hidden': 0.10480349026398328, 'l2_hidden': 0.057930499433150144, 'l1_mu': 0.10469010711472593, 'l2_mu': 0.1424879026876188, 'l1_sigma': 0.14089851878428666, 'l2_sigma': 0.12381551858373106, 'l1_alpha': 0.0, 'l2_alpha': 0.0, 'batch_size': 100, 'n_segments': 5, 'n_members_segment': 1, 'lr': 0.002610227904104945, 'patience': 30, 'epochs': 500, 'verbose': 0, 'pdf': 'normal', 'activation': 'relu', 'name': 'dem_de08v4_mu28v4', 'n_members': 5}\n"
     ]
    }
   ],
   "source": [
    "cross_training(DEM, train_pipeline, n_iter = 1 , modelname = name, layers=1, neurons=16, dropout=[0.1, 0.5], noise_in=[0.1,0.5], noise_sigma=[0.1,0.5],\n",
    "                     noise_mu=[0.1,0.5], l1_hidden=[0.0, 0.2], l2_hidden=[0., 0.2],\n",
    "                     l1_mu=[0.0, 0.2], l2_mu=[0.0, 0.2], l1_sigma=[0.0, 0.2],\n",
    "                     l2_sigma=[0.0, 0.2], lr=[0.0001,0.01], batch_size=100, epochs = 500, n_segments = 5,\n",
    "                    n_members_segment =1, patience=30, verbose = 0, pdf='normal', activation='relu')\n",
    "# cross_training(DEM, pipeline, n_iter = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decades: [1953, 1962, 1972, 1982, 1992]\n",
      "\n",
      "##################################################################\n",
      "Lead time: 0 months\n",
      "##################################################################\n",
      "\n",
      "Predict: 1953-01-01 till 1961-12-01\n",
      "--------------------------------------\n",
      "Predict: 1962-01-01 till 1971-12-01\n",
      "--------------------------------------\n",
      "Predict: 1972-01-01 till 1981-12-01\n",
      "--------------------------------------\n",
      "Predict: 1982-01-01 till 1991-12-01\n",
      "--------------------------------------\n",
      "\n",
      "##################################################################\n",
      "Lead time: 3 months\n",
      "##################################################################\n",
      "\n",
      "Predict: 1953-01-01 till 1961-12-01\n",
      "--------------------------------------\n",
      "Predict: 1962-01-01 till 1971-12-01\n",
      "--------------------------------------\n",
      "Predict: 1972-01-01 till 1981-12-01\n",
      "--------------------------------------\n",
      "Predict: 1982-01-01 till 1991-12-01\n",
      "--------------------------------------\n",
      "\n",
      "##################################################################\n",
      "Lead time: 6 months\n",
      "##################################################################\n",
      "\n",
      "Predict: 1953-01-01 till 1961-12-01\n",
      "--------------------------------------\n",
      "Predict: 1962-01-01 till 1971-12-01\n",
      "--------------------------------------\n",
      "Predict: 1972-01-01 till 1981-12-01\n",
      "--------------------------------------\n",
      "Predict: 1982-01-01 till 1991-12-01\n",
      "--------------------------------------\n",
      "\n",
      "##################################################################\n",
      "Lead time: 9 months\n",
      "##################################################################\n",
      "\n",
      "Predict: 1953-01-01 till 1961-12-01\n",
      "--------------------------------------\n",
      "Predict: 1962-01-01 till 1971-12-01\n",
      "--------------------------------------\n",
      "Predict: 1972-01-01 till 1981-12-01\n",
      "--------------------------------------\n",
      "Predict: 1982-01-01 till 1991-12-01\n",
      "--------------------------------------\n",
      "\n",
      "##################################################################\n",
      "Lead time: 12 months\n",
      "##################################################################\n",
      "\n",
      "Predict: 1953-01-01 till 1961-12-01\n",
      "--------------------------------------\n",
      "Predict: 1962-01-01 till 1971-12-01\n",
      "--------------------------------------\n",
      "Predict: 1972-01-01 till 1981-12-01\n",
      "--------------------------------------\n",
      "Predict: 1982-01-01 till 1991-12-01\n",
      "--------------------------------------\n",
      "\n",
      "##################################################################\n",
      "Lead time: 15 months\n",
      "##################################################################\n",
      "\n",
      "Predict: 1953-01-01 till 1961-12-01\n",
      "--------------------------------------\n",
      "Predict: 1962-01-01 till 1971-12-01\n",
      "--------------------------------------\n",
      "Predict: 1972-01-01 till 1981-12-01\n",
      "--------------------------------------\n",
      "Predict: 1982-01-01 till 1991-12-01\n",
      "--------------------------------------\n",
      "\n",
      "##################################################################\n",
      "Lead time: 18 months\n",
      "##################################################################\n",
      "\n",
      "Predict: 1953-01-01 till 1961-12-01\n",
      "--------------------------------------\n",
      "Predict: 1962-01-01 till 1971-12-01\n",
      "--------------------------------------\n",
      "Predict: 1972-01-01 till 1981-12-01\n",
      "--------------------------------------\n",
      "Predict: 1982-01-01 till 1991-12-01\n",
      "--------------------------------------\n",
      "\n",
      "##################################################################\n",
      "Lead time: 21 months\n",
      "##################################################################\n",
      "\n",
      "Predict: 1953-01-01 till 1961-12-01\n",
      "--------------------------------------\n",
      "Predict: 1962-01-01 till 1971-12-01\n",
      "--------------------------------------\n",
      "Predict: 1972-01-01 till 1981-12-01\n",
      "--------------------------------------\n",
      "Predict: 1982-01-01 till 1991-12-01\n",
      "--------------------------------------\n",
      "decades: [1953, 1962, 1972, 1982, 1992]\n",
      "\n",
      "##################################################################\n",
      "Lead time: 0 months\n",
      "##################################################################\n",
      "\n",
      "Predict: 1953-01-01 till 1961-12-01\n",
      "--------------------------------------\n",
      "Predict: 1962-01-01 till 1971-12-01\n",
      "--------------------------------------\n",
      "Predict: 1972-01-01 till 1981-12-01\n",
      "--------------------------------------\n",
      "Predict: 1982-01-01 till 1991-12-01\n",
      "--------------------------------------\n",
      "\n",
      "##################################################################\n",
      "Lead time: 3 months\n",
      "##################################################################\n",
      "\n",
      "Predict: 1953-01-01 till 1961-12-01\n",
      "--------------------------------------\n",
      "Predict: 1962-01-01 till 1971-12-01\n",
      "--------------------------------------\n",
      "Predict: 1972-01-01 till 1981-12-01\n",
      "--------------------------------------\n",
      "Predict: 1982-01-01 till 1991-12-01\n",
      "--------------------------------------\n",
      "\n",
      "##################################################################\n",
      "Lead time: 6 months\n",
      "##################################################################\n",
      "\n",
      "Predict: 1953-01-01 till 1961-12-01\n",
      "--------------------------------------\n",
      "Predict: 1962-01-01 till 1971-12-01\n",
      "--------------------------------------\n",
      "Predict: 1972-01-01 till 1981-12-01\n",
      "--------------------------------------\n",
      "Predict: 1982-01-01 till 1991-12-01\n",
      "--------------------------------------\n",
      "\n",
      "##################################################################\n",
      "Lead time: 9 months\n",
      "##################################################################\n",
      "\n",
      "Predict: 1953-01-01 till 1961-12-01\n",
      "--------------------------------------\n",
      "Predict: 1962-01-01 till 1971-12-01\n",
      "--------------------------------------\n",
      "Predict: 1972-01-01 till 1981-12-01\n",
      "--------------------------------------\n",
      "Predict: 1982-01-01 till 1991-12-01\n",
      "--------------------------------------\n",
      "\n",
      "##################################################################\n",
      "Lead time: 12 months\n",
      "##################################################################\n",
      "\n",
      "Predict: 1953-01-01 till 1961-12-01\n",
      "--------------------------------------\n",
      "Predict: 1962-01-01 till 1971-12-01\n",
      "--------------------------------------\n",
      "Predict: 1972-01-01 till 1981-12-01\n",
      "--------------------------------------\n",
      "Predict: 1982-01-01 till 1991-12-01\n",
      "--------------------------------------\n",
      "\n",
      "##################################################################\n",
      "Lead time: 15 months\n",
      "##################################################################\n",
      "\n",
      "Predict: 1953-01-01 till 1961-12-01\n",
      "--------------------------------------\n",
      "Predict: 1962-01-01 till 1971-12-01\n",
      "--------------------------------------\n",
      "Predict: 1972-01-01 till 1981-12-01\n",
      "--------------------------------------\n",
      "Predict: 1982-01-01 till 1991-12-01\n",
      "--------------------------------------\n",
      "\n",
      "##################################################################\n",
      "Lead time: 18 months\n",
      "##################################################################\n",
      "\n",
      "Predict: 1953-01-01 till 1961-12-01\n",
      "--------------------------------------\n",
      "Predict: 1962-01-01 till 1971-12-01\n",
      "--------------------------------------\n",
      "Predict: 1972-01-01 till 1981-12-01\n",
      "--------------------------------------\n",
      "Predict: 1982-01-01 till 1991-12-01\n",
      "--------------------------------------\n",
      "\n",
      "##################################################################\n",
      "Lead time: 21 months\n",
      "##################################################################\n",
      "\n",
      "Predict: 1953-01-01 till 1961-12-01\n",
      "--------------------------------------\n",
      "Predict: 1962-01-01 till 1971-12-01\n",
      "--------------------------------------\n",
      "Predict: 1972-01-01 till 1981-12-01\n",
      "--------------------------------------\n",
      "Predict: 1982-01-01 till 1991-12-01\n",
      "--------------------------------------\n"
     ]
    }
   ],
   "source": [
    "cross_hindcast_dem(DEM, test_pipeline, name) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = train_version + '_' + test_version\n",
    "r, p  = evaluation_decadal_correlation_ZC(name, variable_name='mean', ZC_version=test_version)\n",
    "rref, pref = evaluation_decadal_correlation_ZC('dem_mu28v4_mu28v4', variable_name='mean', ZC_version=test_version)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.93506264 0.97666818 0.77966779 0.95438912]\n",
      " [0.93524251 0.8833865  0.7870554  0.81020132]\n",
      " [0.92914449 0.98607278 0.97905836 0.97723571]\n",
      " [0.95339267 0.90501434 0.7687947  0.93992808]\n",
      " [0.73361218 0.93512523 0.75171901 0.91213508]\n",
      " [0.99189464 0.89444215 0.76812571 0.98277538]\n",
      " [0.91903114 0.99995801 0.66645377 0.99378581]\n",
      " [0.98045767 0.91298618 0.98839928 0.91373122]]\n"
     ]
    }
   ],
   "source": [
    "print(rref)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The array r and p contain correlation and p values for each decade for lead times [0,3,6,9,12,15,18,21] as defined in lead_times. index [1,1] is the 3 month lead time prediction for the second decade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x252 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from os.path import join\n",
    "from ninolearn.private import plotdir\n",
    "plot_seasonal_skill_ZC(lead_times, r,  vmin=-1, vmax=1)\n",
    "# plt.contour(np.arange(1,5),lead_times, p, [0.9, 0.95, 0.99], linestyles=['solid', 'dashed', 'dotted'], colors='k')\n",
    "plt.title('Correlation skill')\n",
    "# plt.tight_layout()\n",
    "plt.savefig(join(plotdir, 'TL_r_skill_' + train_version + '_' + test_version))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we also want to compare the skill of the reference case AI to that of the Distorted physics AI. This can be done by plotting the ACC skill of both DEM instances together as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ninolearn.plot.evaluation import ACC_skill_comparison_ZC\n",
    "\n",
    "ACC_skill_comparison_ZC(r, rref, lead_times, train_version, test_version, plot_individual = False, plot_avg = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make predictions for the test data set\n",
    "Now we can use the trained models to make predicitons on the test data set to evaluate how good the model perfoms on a data set that it never saw before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-79f7c372ada1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpred_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_std\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "pred_mean, pred_std = model.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ninolearn.learn.fit import cross_hindcast_dem, cross_hindcast\n",
    "# cross_hindcast(model, pipeline, 'DEM')\n",
    "# # cross_hindcast_dem(model, pipeline, 'DEM')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the prediction\n",
    "Let's see how the predicion is looking like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from ninolearn.plot.prediction import plot_prediction\n",
    "import pandas as pd\n",
    "from ninolearn.pathes import plotdir\n",
    "\n",
    "from os.path import join\n",
    "\n",
    "\n",
    "plt.subplots(figsize=(15,3.5))\n",
    "plt.axhspan(-0.5,\n",
    "            -6,\n",
    "            facecolor='blue',\n",
    "            alpha=0.1,zorder=0)\n",
    "\n",
    "plt.axhspan(0.5,\n",
    "            6,\n",
    "            facecolor='red',\n",
    "            alpha=0.1,zorder=0)\n",
    "\n",
    "plt.xlim(testtimey[0], testtimey[-1])\n",
    "plt.ylim(-3,3)\n",
    "\n",
    "# plot the prediction\n",
    "plot_prediction(testtimey, pred_mean, std=pred_std, facecolor='royalblue', line_color='navy')\n",
    "\n",
    "# plot the observation\n",
    "plt.plot(timey, y, \"r\", label = 'observation')\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(join(plotdir, f'predicVSobs_{version}_{lead_time}lead'))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model\n",
    "\n",
    "We can evaluate the model a bit more quantitatively using the loss function that was used to train the model, namely the negative-log-likelihood of the Gaussian and the correlation between the predicted mean and the observed ONI index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ninolearn.plot.evaluation import plot_correlation, plot_confMat, plot_seasonal_skill\n",
    "\n",
    "# loss = model.evaluate(testy, pred_mean, pred_std)\n",
    "# print(f\"Loss (Negative-Log-Likelihood): {loss}\")\n",
    "\n",
    "# # make a plot of the seasonal correaltion\n",
    "# # note: - pd.tseries.offsets.MonthBegin(1) appears to ensure that the correlations are plotted\n",
    "# # agains the correct season\n",
    "# plot_correlation(testy, pred_mean, testtimey - pd.tseries.offsets.MonthBegin(1), title=\"\")\n",
    "\n",
    "# # plot_seasonal_skill(leadtime, r_seas)\n",
    "\n",
    "# # plt.savefig(join(plotdir, f'correlation_{version}_{lead_time}lead'))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_seasonal_skill_ZC(lead_times, r,  vmin=0, vmax=1)\n",
    "plt.contour(np.arange(1,5),lead_times, p, linestyles=['solid', 'dashed', 'dotted'], colors='k')\n",
    "plt.title('Correlation skill')\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
